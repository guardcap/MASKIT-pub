"""
ì •ì±… ê´€ë¦¬ ë¼ìš°í„°
- ì •ì±… ì¶”ê°€/ìˆ˜ì •/ì‚­ì œ
- ë©€í‹°ëª¨ë‹¬ íŒŒì¼ ì—…ë¡œë“œ (PDF, ì´ë¯¸ì§€)
- ì„ë² ë”© ìƒì„± ë° VectorDB ì €ì¥
"""

from fastapi import APIRouter, UploadFile, File, Form, HTTPException, Depends, status, Request
from fastapi.responses import JSONResponse
from typing import List, Optional
import os
import json
import asyncio
from pathlib import Path
from datetime import datetime
import hashlib
import fitz  # PyMuPDF
from dotenv import load_dotenv
from app.auth.auth_utils import get_current_policy_admin
from app.audit.logger import AuditLogger
from app.audit.models import AuditEventType, AuditSeverity
from app.database.mongodb import get_db
from fastapi.background import BackgroundTasks

# OpenAI imports
try:
    from openai import AsyncOpenAI
    from pyzerox import zerox
    OPENAI_AVAILABLE = True
except ImportError:
    OPENAI_AVAILABLE = False

# Database imports
from app.database.mongodb import get_db
from app.policy.models import PolicyDocument, PolicyMetadata, PolicyResponse

# Background tasks
from app.policy.background_tasks import process_policy_background, get_task_status, clear_old_tasks
from fastapi import BackgroundTasks

load_dotenv()

router = APIRouter(prefix="/api/policies", tags=["Policy Management"])

# ì„¤ì •
# ì ˆëŒ€ ê²½ë¡œ ì‚¬ìš©
BASE_DIR = Path(__file__).parent.parent.parent.parent  # enterprise-guardcap ë£¨íŠ¸
UPLOAD_DIR = BASE_DIR / "backend" / "app" / "uploads" / "policies"
TEMP_DIR = BASE_DIR / "backend" / "app" / "uploads" / "temp"
PROCESSED_DIR = BASE_DIR / "backend" / "app" / "uploads" / "processed"
STAGING_DIR = BASE_DIR / "backend" / "app" / "rag" / "data" / "staging"

UPLOAD_DIR.mkdir(parents=True, exist_ok=True)
TEMP_DIR.mkdir(parents=True, exist_ok=True)
PROCESSED_DIR.mkdir(parents=True, exist_ok=True)

# ì •ì±… ìŠ¤í‚¤ë§ˆ ìºì‹œ
_policy_schemas_cache = None
_cache_timestamp = None
CACHE_EXPIRY_SECONDS = 3600  # 1ì‹œê°„

# OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
if OPENAI_AVAILABLE:
    openai_api_key = os.getenv("OPENAI_API_KEY")
    if openai_api_key:
        openai_client = AsyncOpenAI(api_key=openai_api_key)
    else:
        openai_client = None
else:
    openai_client = None


class PolicyProcessor:
    """ì •ì±… ë¬¸ì„œ ì²˜ë¦¬ í´ë˜ìŠ¤"""

    def __init__(self):
        self.model = os.getenv("OPENAI_MODEL", "gpt-4o")
        self.vision_model = os.getenv("OPENAI_VISION_MODEL", "gpt-4o")

    async def process_pdf(self, file_path: str) -> dict:
        """PDF íŒŒì¼ì„ ì²˜ë¦¬í•˜ì—¬ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
        try:
            # PDF ì •ë³´ í™•ì¸
            doc = fitz.open(file_path)
            page_count = len(doc)
            file_size_mb = Path(file_path).stat().st_size / (1024 * 1024)
            doc.close()

            # ì‘ì€ PDFëŠ” Zerox ì‚¬ìš© (OCR + Vision)
            if page_count <= 50 and file_size_mb <= 20:
                if OPENAI_AVAILABLE and openai_client:
                    try:
                        result = await zerox(
                            file_path=file_path,
                            model=self.vision_model,
                            output_dir=str(TEMP_DIR),
                            cleanup=True,
                        )
                        markdown = result.get("content", "") if isinstance(result, dict) else str(result)
                        return {"text": markdown, "method": "zerox_ocr"}
                    except Exception as e:
                        print(f"Zerox failed: {e}, falling back to PyMuPDF")

            # Fallback: PyMuPDFë¡œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
            doc = fitz.open(file_path)
            text = ""
            for page in doc:
                text += page.get_text()
            doc.close()

            return {"text": text, "method": "pymupdf"}

        except Exception as e:
            raise HTTPException(status_code=500, detail=f"PDF ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}")

    async def process_image(self, file_path: str) -> dict:
        """ì´ë¯¸ì§€ íŒŒì¼ì„ OCR ì²˜ë¦¬"""
        if not OPENAI_AVAILABLE or not openai_client:
            raise HTTPException(status_code=400, detail="OpenAI APIê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")

        try:
            # Vision APIë¡œ ì´ë¯¸ì§€ ë¶„ì„
            with open(file_path, "rb") as image_file:
                import base64
                image_data = base64.b64encode(image_file.read()).decode('utf-8')

            response = await openai_client.chat.completions.create(
                model=self.vision_model,
                messages=[
                    {
                        "role": "user",
                        "content": [
                            {
                                "type": "text",
                                "text": "ì´ë¯¸ì§€ì—ì„œ ëª¨ë“  í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ê³  ì •ì±… ë‚´ìš©ì„ êµ¬ì¡°í™”í•˜ì—¬ ë§ˆí¬ë‹¤ìš´ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”."
                            },
                            {
                                "type": "image_url",
                                "image_url": {
                                    "url": f"data:image/jpeg;base64,{image_data}"
                                }
                            }
                        ]
                    }
                ],
                max_tokens=4000
            )

            text = response.choices[0].message.content
            return {"text": text, "method": "vision_api"}

        except Exception as e:
            raise HTTPException(status_code=500, detail=f"ì´ë¯¸ì§€ ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}")

    async def extract_policy_metadata(self, text: str, title: str, authority: str) -> dict:
        """ì •ì±… í…ìŠ¤íŠ¸ì—ì„œ ë©”íƒ€ë°ì´í„° ì¶”ì¶œ"""
        if not OPENAI_AVAILABLE or not openai_client:
            # OpenAI ì—†ì´ ê¸°ë³¸ ë©”íƒ€ë°ì´í„°ë§Œ ë°˜í™˜
            return {
                "title": title,
                "authority": authority,
                "summary": text[:500],
                "keywords": [],
                "entity_types": []
            }

        prompt = f"""
ë‹¤ìŒ ì •ì±… ë¬¸ì„œì—ì„œ ë©”íƒ€ë°ì´í„°ë¥¼ ì¶”ì¶œí•˜ì„¸ìš”.

ì •ì±… ì œëª©: {title}
ë°œí–‰ ê¸°ê´€: {authority}

ë¬¸ì„œ ë‚´ìš©:
{text[:4000]}

ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ë°˜í™˜í•˜ì„¸ìš”:
{{
    "summary": "ì •ì±… ìš”ì•½ (200ì ì´ë‚´)",
    "keywords": ["í‚¤ì›Œë“œ1", "í‚¤ì›Œë“œ2", ...],
    "entity_types": ["ê°œì¸ì •ë³´ ìœ í˜•1", "ê°œì¸ì •ë³´ ìœ í˜•2", ...],
    "scenarios": ["ì ìš© ì‹œë‚˜ë¦¬ì˜¤1", "ì ìš© ì‹œë‚˜ë¦¬ì˜¤2", ...],
    "directives": ["ì‹¤í–‰ ì§€ì¹¨1", "ì‹¤í–‰ ì§€ì¹¨2", ...]
}}

ë°˜ë“œì‹œ ìœ íš¨í•œ JSONë§Œ ë°˜í™˜í•˜ì„¸ìš”.
"""

        try:
            response = await openai_client.chat.completions.create(
                model=self.model,
                messages=[{"role": "user", "content": prompt}],
                temperature=0.3,
            )

            content = response.choices[0].message.content.strip()
            # JSON ì¶”ì¶œ
            import re
            content = re.sub(r'^```json\s*', '', content)
            content = re.sub(r'\s*```$', '', content)

            metadata = json.loads(content)
            metadata["title"] = title
            metadata["authority"] = authority

            return metadata

        except Exception as e:
            print(f"ë©”íƒ€ë°ì´í„° ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return {
                "title": title,
                "authority": authority,
                "summary": text[:500],
                "keywords": [],
                "entity_types": []
            }



@router.post("/upload")
async def upload_policy_file(
    background_tasks: BackgroundTasks,
    request: Request,
    file: UploadFile = File(...),
    title: str = Form(...),
    authority: str = Form(default="ë‚´ë¶€"),
    description: str = Form(default=""),
        db = Depends(get_db),
    current_user = Depends(get_current_policy_admin)
):
    """
    ì •ì±… íŒŒì¼ ì—…ë¡œë“œ (PDF, ì´ë¯¸ì§€ ë“±)
    ë©€í‹°ëª¨ë‹¬ ì²˜ë¦¬ ë° ì„ë² ë”© ìƒì„±
    """

    # íŒŒì¼ í™•ì¥ì í™•ì¸
    file_ext = os.path.splitext(file.filename)[1].lower()
    supported_exts = ['.pdf', '.png', '.jpg', '.jpeg', '.bmp', '.tiff']

    if file_ext not in supported_exts:
        raise HTTPException(
            status_code=400,
            detail=f"ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤. ì§€ì› í˜•ì‹: {', '.join(supported_exts)}"
        )

    # íŒŒì¼ ì €ì¥
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    safe_filename = f"{timestamp}_{file.filename}"
    file_path = UPLOAD_DIR / safe_filename

    try:
        # íŒŒì¼ ì €ì¥
        with open(file_path, "wb") as f:
            content = await file.read()
            f.write(content)

        # íŒŒì¼ ì²˜ë¦¬
        processor = PolicyProcessor()

        if file_ext == '.pdf':
            result = await processor.process_pdf(str(file_path))
        else:
            result = await processor.process_image(str(file_path))

        extracted_text = result["text"]
        processing_method = result["method"]

        # ë©”íƒ€ë°ì´í„° ì¶”ì¶œ
        metadata_dict = await processor.extract_policy_metadata(
            extracted_text,
            title,
            authority
        )

        # PolicyMetadata ëª¨ë¸ë¡œ ë³€í™˜
        metadata = PolicyMetadata(**metadata_dict)

        # ì •ì±… ID ìƒì„±
        policy_id = hashlib.md5(f"{title}_{timestamp}".encode()).hexdigest()[:12]

        # PolicyDocument ëª¨ë¸ ìƒì„±
        policy_doc = PolicyDocument(
            policy_id=policy_id,
            title=title,
            authority=authority,
            description=description,
            original_filename=file.filename,
            saved_filename=safe_filename,
            file_type=file_ext,
            file_size_mb=len(content) / (1024 * 1024),
            processing_method=processing_method,
            extracted_text=extracted_text,
            metadata=metadata,
            created_by=None  # TODO: í˜„ì¬ ì‚¬ìš©ì ì´ë©”ì¼
        )

        # MongoDBì— ì €ì¥
        await db["policies"].insert_one(policy_doc.model_dump(mode='json'))

        # âœ… ê°ì‚¬ ë¡œê·¸ ê¸°ë¡
        await AuditLogger.log(
            event_type=AuditEventType.POLICY_UPLOAD,
            user_email=current_user["email"],
            user_role=current_user.get("role", "policy_admin"),
            action=f"ì •ì±… ì—…ë¡œë“œ: {title}",
            resource_type="policy",
            resource_id=policy_id,
            details={
                "title": title,
                "authority": authority,
                "file_type": file_ext,
                "file_size_mb": len(content) / (1024 * 1024)
            },
            request=request,
            severity=AuditSeverity.INFO
        )

        # ë°±ì—…ìš©ìœ¼ë¡œ íŒŒì¼ì—ë„ ì €ì¥
        processed_file = PROCESSED_DIR / f"policy_{policy_id}.json"
        with open(processed_file, "w", encoding="utf-8") as f:
            json.dump(policy_doc.model_dump(mode='json'), f, ensure_ascii=False, indent=2)

        # ë°±ê·¸ë¼ìš´ë“œì—ì„œ ê°€ì´ë“œë¼ì¸ ì¶”ì¶œ ë° VectorDB ì„ë² ë”© ì‹¤í–‰
        background_tasks.add_task(
            process_policy_background,
            policy_id,
            policy_doc.model_dump(mode='json'),
            db
        )

        return JSONResponse({
            "success": True,
            "message": "ì •ì±… íŒŒì¼ì´ ì„±ê³µì ìœ¼ë¡œ ì—…ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤. ë°±ê·¸ë¼ìš´ë“œì—ì„œ ê°€ì´ë“œë¼ì¸ ì¶”ì¶œ ì¤‘ì…ë‹ˆë‹¤.",
            "data": {
                "policy_id": policy_id,
                "title": title,
                "authority": authority,
                "file_type": file_ext,
                "processing_method": processing_method,
                "metadata": metadata_dict,
                "text_length": len(extracted_text),
                "created_at": policy_doc.created_at.isoformat(),
                "task_id": f"policy_{policy_id}"
            }
        })

    except Exception as e:
        # ì˜¤ë¥˜ ë°œìƒ ì‹œ ì—…ë¡œë“œëœ íŒŒì¼ ì‚­ì œ
        if file_path.exists():
            file_path.unlink()
        # âœ… ì‹¤íŒ¨ ë¡œê·¸
        await AuditLogger.log(
            event_type=AuditEventType.POLICY_UPLOAD,
            user_email=current_user["email"],
            user_role=current_user.get("role", "policy_admin"),
            action=f"ì •ì±… ì—…ë¡œë“œ ì‹¤íŒ¨: {title}",
            resource_type="policy",
            request=request,
            success=False,
            error_message=str(e),
        )
        raise HTTPException(status_code=500, detail=f"íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")


@router.get("/list")
async def list_policies(
    skip: int = 0,
    limit: int = 50,
    authority: str = None,
    db = Depends(get_db)
):
    """ì •ì±… ëª©ë¡ ì¡°íšŒ"""
    try:
        print(f"\n[Policy List] ===== ì •ì±… ëª©ë¡ ì¡°íšŒ ì‹œì‘ =====")
        print(f"[Policy List] skip={skip}, limit={limit}, authority={authority}")
        
        # í•„í„° ì¡°ê±´
        query = {}
        if authority and authority != 'all':
            query["authority"] = authority
            print(f"[Policy List] í•„í„° ì¡°ê±´: {query}")

        # ì´ ê°œìˆ˜ ì¡°íšŒ
        total = await db["policies"].count_documents(query)
        print(f"[Policy List] ì´ ê°œìˆ˜: {total}")

        # ì •ì±… ëª©ë¡ ì¡°íšŒ (ì „ì²´ í…ìŠ¤íŠ¸ ì œì™¸)
        cursor = db["policies"].find(
            query,
            {
                "extracted_text": 0  # ì „ì²´ í…ìŠ¤íŠ¸ëŠ” ì œì™¸
            }
        ).sort("created_at", -1).skip(skip).limit(limit)

        policies = []
        async for doc in cursor:
            try:
                # _idë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜
                doc["_id"] = str(doc["_id"])

                # datetime í•„ë“œë¥¼ ISO ë¬¸ìì—´ë¡œ ë³€í™˜
                for key in ["created_at", "updated_at", "processed_at", "vector_store_synced_at"]:
                    if key in doc and doc[key] is not None:
                        if hasattr(doc[key], 'isoformat'):
                            doc[key] = doc[key].isoformat()

                policies.append(doc)
                print(f"[Policy List] ì •ì±… ì¶”ê°€: {doc.get('title', 'Unknown')}")
            except Exception as e:
                print(f"[Policy List] âš ï¸ ì •ì±… ë³€í™˜ ì˜¤ë¥˜: {e}")
                continue

        print(f"[Policy List] âœ… {len(policies)}ê°œ ì •ì±… ì¡°íšŒ ì™„ë£Œ")
        print(f"[Policy List] ===== ì •ì±… ëª©ë¡ ì¡°íšŒ ë =====\n")

        return JSONResponse({
            "success": True,
            "data": {
                "policies": policies,
                "total": total,
                "skip": skip,
                "limit": limit
            }
        })

    except Exception as e:
        print(f"[Policy List] âŒ ì •ì±… ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"ì •ì±… ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}"
        )


# ===== ì •ì±… ìŠ¤í‚¤ë§ˆ ë¡œë”© ë° ìºì‹± =====

async def load_policy_schemas_from_staging():
    """staging ë””ë ‰í† ë¦¬ì—ì„œ ì •ì±… ìŠ¤í‚¤ë§ˆ ë¡œë“œ"""
    global _policy_schemas_cache, _cache_timestamp

    # ìºì‹œ ìœ íš¨ì„± í™•ì¸
    if _policy_schemas_cache and _cache_timestamp:
        elapsed = (datetime.now() - _cache_timestamp).total_seconds()
        if elapsed < CACHE_EXPIRY_SECONDS:
            print(f"âœ… ìºì‹œëœ ì •ì±… ìŠ¤í‚¤ë§ˆ ë°˜í™˜ (ìºì‹œ ìœ íš¨ ì‹œê°„: {CACHE_EXPIRY_SECONDS - elapsed:.0f}ì´ˆ ë‚¨ìŒ)")
            return _policy_schemas_cache

    print(f"ğŸ“‚ Staging ë””ë ‰í† ë¦¬ì—ì„œ ì •ì±… ìŠ¤í‚¤ë§ˆ ë¡œë”© ì¤‘... ({STAGING_DIR})")

    if not STAGING_DIR.exists():
        print(f"âš ï¸ Staging ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {STAGING_DIR}")
        return []

    schemas = []
    jsonl_files = list(STAGING_DIR.glob("*.jsonl"))

    if not jsonl_files:
        print(f"âš ï¸ JSONL íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {STAGING_DIR}")
        return []

    print(f"ğŸ“„ {len(jsonl_files)}ê°œì˜ JSONL íŒŒì¼ ë°œê²¬")

    for jsonl_file in jsonl_files:
        try:
            with open(jsonl_file, 'r', encoding='utf-8') as f:
                for line_num, line in enumerate(f, 1):
                    line = line.strip()
                    if not line:
                        continue
                    try:
                        schema = json.loads(line)
                        schemas.append({
                            "source_file": jsonl_file.name,
                            "line_number": line_num,
                            **schema
                        })
                    except json.JSONDecodeError as e:
                        print(f"âš ï¸ JSON íŒŒì‹± ì˜¤ë¥˜ ({jsonl_file.name}:{line_num}): {e}")
        except Exception as e:
            print(f"âš ï¸ íŒŒì¼ ì½ê¸° ì˜¤ë¥˜ ({jsonl_file.name}): {e}")

    # ìºì‹œ ì—…ë°ì´íŠ¸
    _policy_schemas_cache = schemas
    _cache_timestamp = datetime.now()

    print(f"âœ… {len(schemas)}ê°œì˜ ì •ì±… ìŠ¤í‚¤ë§ˆ ë¡œë“œ ì™„ë£Œ (ìºì‹œë¨)")
    return schemas


@router.get("/schemas")
async def get_policy_schemas(
    skip: int = 0,
    limit: int = 50,
    refresh_cache: bool = False
):
    """
    ì •ì±… ìŠ¤í‚¤ë§ˆ ëª©ë¡ ì¡°íšŒ (staging ë””ë ‰í† ë¦¬ì—ì„œ ë¡œë“œ)
    - skip: ê±´ë„ˆë›¸ ê°œìˆ˜
    - limit: ë°˜í™˜í•  ìµœëŒ€ ê°œìˆ˜  
    - refresh_cache: Trueë©´ ìºì‹œ ë¬´ì‹œí•˜ê³  ì¬ë¡œë“œ
    """
    global _policy_schemas_cache, _cache_timestamp

    # ìºì‹œ ê°•ì œ ìƒˆë¡œê³ ì¹¨
    if refresh_cache:
        _policy_schemas_cache = None
        _cache_timestamp = None

    schemas = await load_policy_schemas_from_staging()

    total = len(schemas)
    schemas_page = schemas[skip:skip + limit]

    cache_expires_in = 0
    if _cache_timestamp:
        cache_expires_in = CACHE_EXPIRY_SECONDS - (datetime.now() - _cache_timestamp).total_seconds()

    return JSONResponse({
        "success": True,
        "data": {
            "total": total,
            "skip": skip,
            "limit": limit,
            "cached": _cache_timestamp is not None,
            "cache_expires_in": max(0, cache_expires_in),
            "schemas": schemas_page
        }
    })

@router.get("/{policy_id}")
async def get_policy_detail(
    policy_id: str,
    db = Depends(get_db)
):
    """ì •ì±… ìƒì„¸ ì¡°íšŒ"""
    try:
        print(f"\n[Policy Detail] ===== ì •ì±… ìƒì„¸ ì¡°íšŒ ì‹œì‘ =====")
        print(f"[Policy Detail] Policy ID: {policy_id}")
        
        policy = await db["policies"].find_one({"policy_id": policy_id})

        if not policy:
            print(f"[Policy Detail] âŒ ì •ì±…ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {policy_id}")
            raise HTTPException(
                status_code=404, 
                detail="ì •ì±…ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"
            )

        # _idë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜
        policy["_id"] = str(policy["_id"])

        # âœ… datetime ê°ì²´ë¥¼ ISO ë¬¸ìì—´ë¡œ ë³€í™˜
        datetime_fields = ["created_at", "updated_at", "vector_store_synced_at"]
        for field in datetime_fields:
            if field in policy and hasattr(policy[field], "isoformat"):
                policy[field] = policy[field].isoformat()

        # âœ… guidelines ë‚´ë¶€ì˜ datetime í•„ë“œë„ ë³€í™˜
        if "guidelines" in policy and policy["guidelines"]:
            for guide in policy["guidelines"]:
                if isinstance(guide, dict):
                    for key, value in guide.items():
                        if hasattr(value, "isoformat"):
                            guide[key] = value.isoformat()

        print(f"[Policy Detail] âœ… ì •ì±… ì¡°íšŒ ì„±ê³µ: {policy.get('title')}")
        print(f"[Policy Detail] ===== ì •ì±… ìƒì„¸ ì¡°íšŒ ë =====\n")

        return JSONResponse({
            "success": True,
            "data": policy
        })

    except HTTPException:
        raise
    except Exception as e:
        print(f"[Policy Detail] âŒ ì •ì±… ì¡°íšŒ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        raise HTTPException(
            status_code=500, 
            detail=f"ì •ì±… ì¡°íšŒ ì‹¤íŒ¨: {str(e)}"
        )

@router.delete("/{policy_id}")
async def delete_policy(
    policy_id: str,
    request: Request,  # âœ… Request ì¶”ê°€
    db = Depends(get_db),
    current_user = Depends(get_current_policy_admin)
):
    """ì •ì±… ì‚­ì œ"""
    try:
        # ì •ì±… ì¡°íšŒ
        policy = await db["policies"].find_one({"policy_id": policy_id})

        if not policy:
            raise HTTPException(status_code=404, detail="ì •ì±…ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")

        policy_title = policy.get("title", policy_id)

        # ì›ë³¸ íŒŒì¼ ì‚­ì œ
        original_file = UPLOAD_DIR / policy["saved_filename"]
        if original_file.exists():
            original_file.unlink()

        # ë°±ì—… íŒŒì¼ ì‚­ì œ
        backup_file = PROCESSED_DIR / f"policy_{policy_id}.json"
        if backup_file.exists():
            backup_file.unlink()

        # MongoDBì—ì„œ ì‚­ì œ
        delete_result = await db["policies"].delete_one({"policy_id": policy_id})
        print(f"[Policy Delete] MongoDB ì‚­ì œ ê²°ê³¼: {delete_result.deleted_count}ê°œ")

        if delete_result.deleted_count == 0:
            print(f"[Policy Delete] âš ï¸ MongoDBì—ì„œ ì‚­ì œ ì‹¤íŒ¨")
            raise HTTPException(status_code=500, detail="ì •ì±… ì‚­ì œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤")

        # âœ… ê°ì‚¬ ë¡œê·¸ ê¸°ë¡
        await AuditLogger.log(
            event_type=AuditEventType.POLICY_DELETE,
            user_email=current_user["email"],
            user_role=current_user.get("role", "policy_admin"),
            action=f"ì •ì±… ì‚­ì œ: {policy_title}",
            resource_type="policy",
            resource_id=policy_id,
            details={"title": policy_title},
            request=request,
            severity=AuditSeverity.WARNING
        )

        return JSONResponse({
            "success": True,
            "message": "ì •ì±…ì´ ì„±ê³µì ìœ¼ë¡œ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤"
        })

    except HTTPException:
        raise
    except Exception as e:
        # âœ… ì‹¤íŒ¨ ë¡œê·¸
        await AuditLogger.log(
            event_type=AuditEventType.POLICY_DELETE,
            user_email=current_user["email"],
            user_role=current_user.get("role", "policy_admin"),
            action=f"ì •ì±… ì‚­ì œ ì‹¤íŒ¨: {policy_id}",
            resource_type="policy",
            resource_id=policy_id,
            request=request,
            success=False,
            error_message=str(e),
            severity=AuditSeverity.ERROR
        )
        raise HTTPException(status_code=500, detail=f"ì •ì±… ì‚­ì œ ì‹¤íŒ¨: {str(e)}")

@router.patch("/{policy_id}/text")
async def update_policy_text(
    policy_id: str,
    text_data: dict,
    request: Request,  # âœ… Request ì¶”ê°€
    current_user = Depends(get_current_policy_admin),
    db = Depends(get_db)
):
    """
    ì •ì±… ì¶”ì¶œ í…ìŠ¤íŠ¸ ìˆ˜ì •
    """
    try:
        print(f"\n[Policy] ===== í…ìŠ¤íŠ¸ ìˆ˜ì • ì‹œì‘ =====")
        print(f"[Policy] Policy ID: {policy_id}")
        
        # ìƒˆ í…ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°
        new_text = text_data.get("extracted_text")
        
        if not new_text:
            raise HTTPException(
                status_code=status.HTTP_400_BAD_REQUEST,
                detail="extracted_text í•„ë“œê°€ í•„ìš”í•©ë‹ˆë‹¤"
            )
        
        print(f"[Policy] ìƒˆ í…ìŠ¤íŠ¸ ê¸¸ì´: {len(new_text)} ì")
        
        # ì •ì±… ì¡´ì¬ í™•ì¸
        policy = await db["policies"].find_one({"policy_id": policy_id})
        policy_title = policy.get("title", policy_id)

        if not policy:
            print(f"[Policy] âŒ ì •ì±…ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {policy_id}")
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail="ì •ì±…ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"
            )
        
        # í…ìŠ¤íŠ¸ ì—…ë°ì´íŠ¸
        result = await db["policies"].update_one(
            {"policy_id": policy_id},
            {
                "$set": {
                    "extracted_text": new_text,
                    "updated_at": datetime.utcnow()
                }
            }
        )
        
        print(f"[Policy] matched_count: {result.matched_count}")
        print(f"[Policy] modified_count: {result.modified_count}")
        
        if result.modified_count == 0 and result.matched_count == 0:
            print(f"[Policy] âŒ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨")
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail="ì •ì±… ì—…ë°ì´íŠ¸ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤"
            )
        
        print(f"[Policy] âœ… í…ìŠ¤íŠ¸ ìˆ˜ì • ì™„ë£Œ")
        print(f"[Policy] ===== í…ìŠ¤íŠ¸ ìˆ˜ì • ë =====\n")


        # âœ… ê°ì‚¬ ë¡œê·¸ ê¸°ë¡
        await AuditLogger.log(
            event_type=AuditEventType.POLICY_UPDATE,  # âœ… ìƒˆ ì´ë²¤íŠ¸ íƒ€ì…
            user_email=current_user["email"],
            user_role=current_user.get("role", "policy_admin"),
            action=f"ì •ì±… í…ìŠ¤íŠ¸ ìˆ˜ì •: {policy_title}",
            resource_type="policy",
            resource_id=policy_id,
            details={
                "title": policy_title,
                "text_length": len(new_text)
            },
            request=request,
            severity=AuditSeverity.INFO
        )

        return JSONResponse({
            "success": True,
            "message": "í…ìŠ¤íŠ¸ê°€ ì„±ê³µì ìœ¼ë¡œ ìˆ˜ì •ë˜ì—ˆìŠµë‹ˆë‹¤",
            "data": {
                "policy_id": policy_id,
                "text_length": len(new_text),
                "updated_at": datetime.utcnow().isoformat()
            }
        })
        
    except HTTPException:
        raise
    except Exception as e:
        print(f"[Policy] âŒ í…ìŠ¤íŠ¸ ìˆ˜ì • ì˜¤ë¥˜: {e}")
        # âœ… ì‹¤íŒ¨ ë¡œê·¸
        await AuditLogger.log(
            event_type=AuditEventType.POLICY_UPDATE,
            user_email=current_user["email"],
            user_role=current_user.get("role", "policy_admin"),
            action=f"ì •ì±… í…ìŠ¤íŠ¸ ìˆ˜ì • ì‹¤íŒ¨: {policy_id}",
            resource_type="policy",
            resource_id=policy_id,
            request=request,
            success=False,
            error_message=str(e),
            severity=AuditSeverity.ERROR
        )
        import traceback
        traceback.print_exc()
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"í…ìŠ¤íŠ¸ ìˆ˜ì • ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        )

@router.patch("/{policy_id}/guidelines")
async def update_policy_guidelines(
    policy_id: str,
    guidelines_data: dict,
    request: Request,
    current_user = Depends(get_current_policy_admin),
    db = Depends(get_db)
):
    """
    ì •ì±… ê°€ì´ë“œë¼ì¸ ìˆ˜ì • - ë™ê¸°í™” ìƒíƒœ ì´ˆê¸°í™”ë¨
    """
    try:
        print(f"\n[Policy] ===== ê°€ì´ë“œë¼ì¸ ìˆ˜ì • ì‹œì‘ =====")
        print(f"[Policy] Policy ID: {policy_id}")

        # ìƒˆ ê°€ì´ë“œë¼ì¸ ê°€ì ¸ì˜¤ê¸°
        new_guidelines = guidelines_data.get("guidelines")

        if new_guidelines is None:
            raise HTTPException(
                status_code=status.HTTP_400_BAD_REQUEST,
                detail="guidelines í•„ë“œê°€ í•„ìš”í•©ë‹ˆë‹¤"
            )

        print(f"[Policy] ìƒˆ ê°€ì´ë“œë¼ì¸ ê°œìˆ˜: {len(new_guidelines)} ê°œ")

        # ì •ì±… ì¡´ì¬ í™•ì¸
        policy = await db["policies"].find_one({"policy_id": policy_id})
        policy_title = policy.get("title", policy_id)


        if not policy:
            print(f"[Policy] âŒ ì •ì±…ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {policy_id}")
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail="ì •ì±…ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"
            )

        # ê°€ì´ë“œë¼ì¸ ì—…ë°ì´íŠ¸ ë° ë™ê¸°í™” ìƒíƒœ ì´ˆê¸°í™”
        result = await db["policies"].update_one(
            {"policy_id": policy_id},
            {
                "$set": {
                    "guidelines": new_guidelines,
                    "guidelines_count": len(new_guidelines),
                    "updated_at": datetime.utcnow(),
                    # ë™ê¸°í™” ìƒíƒœ ì´ˆê¸°í™” - ë‹¤ì‹œ ë™ê¸°í™” í•„ìš”
                    "vector_store_file_id": None,
                    "vector_store_synced_at": None
                }
            }
        )

        print(f"[Policy] matched_count: {result.matched_count}")
        print(f"[Policy] modified_count: {result.modified_count}")

        if result.modified_count == 0 and result.matched_count == 0:
            print(f"[Policy] âŒ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨")
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail="ì •ì±… ì—…ë°ì´íŠ¸ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤"
            )

        print(f"[Policy] âœ… ê°€ì´ë“œë¼ì¸ ìˆ˜ì • ì™„ë£Œ (ë™ê¸°í™” ìƒíƒœ ì´ˆê¸°í™”ë¨)")
        print(f"[Policy] ===== ê°€ì´ë“œë¼ì¸ ìˆ˜ì • ë =====\n")

        # âœ… ê°ì‚¬ ë¡œê·¸ ê¸°ë¡
        await AuditLogger.log(
            event_type=AuditEventType.POLICY_UPDATE,
            user_email=current_user["email"],
            user_role=current_user.get("role", "policy_admin"),
            action=f"ì •ì±… ê°€ì´ë“œë¼ì¸ ìˆ˜ì •: {policy_title}",
            resource_type="policy",
            resource_id=policy_id,
            details={
                "title": policy_title,
                "guidelines_count": len(new_guidelines)
            },
            request=request,
            severity=AuditSeverity.WARNING  # ë™ê¸°í™” í•„ìš”
        )

        return JSONResponse({
            "success": True,
            "message": "ê°€ì´ë“œë¼ì¸ì´ ì„±ê³µì ìœ¼ë¡œ ìˆ˜ì •ë˜ì—ˆìŠµë‹ˆë‹¤. Vector Storeì— ë‹¤ì‹œ ë™ê¸°í™”ê°€ í•„ìš”í•©ë‹ˆë‹¤.",
            "data": {
                "policy_id": policy_id,
                "guidelines_count": len(new_guidelines),
                "updated_at": datetime.utcnow().isoformat(),
                "sync_required": True
            }
        })

    except HTTPException:
        raise
    except Exception as e:
        print(f"[Policy] âŒ ê°€ì´ë“œë¼ì¸ ìˆ˜ì • ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"ê°€ì´ë“œë¼ì¸ ìˆ˜ì • ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        )

@router.get("/stats/summary")
async def get_policy_stats(db = Depends(get_db)):
    """ì •ì±… í†µê³„ ì¡°íšŒ"""
    try:
        # ì´ ì •ì±… ìˆ˜
        total_policies = await db["policies"].count_documents({})

        # ì´ ì—”í‹°í‹° ìˆ˜ (entities ì»¬ë ‰ì…˜ì—ì„œ ì¡°íšŒ)
        total_entities = await db.get_collection("entities").count_documents({})

        # ê¸°ê´€ë³„ ì§‘ê³„
        authority_pipeline = [
            {"$group": {"_id": "$authority", "count": {"$sum": 1}}}
        ]
        authority_cursor = db["policies"].aggregate(authority_pipeline)
        authority_count = {}
        async for doc in authority_cursor:
            authority_count[doc["_id"]] = doc["count"]

        # íŒŒì¼ íƒ€ì…ë³„ ì§‘ê³„
        file_type_pipeline = [
            {"$group": {"_id": "$file_type", "count": {"$sum": 1}}}
        ]
        file_type_cursor = db["policies"].aggregate(file_type_pipeline)
        file_type_count = {}
        async for doc in file_type_cursor:
            file_type_count[doc["_id"]] = doc["count"]

        return JSONResponse({
            "success": True,
            "data": {
                "total_policies": total_policies,
                "total_entities": total_entities,
                "by_authority": authority_count,
                "by_file_type": file_type_count
            }
        })

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"í†µê³„ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")


@router.get("/tasks/{task_id}/status")
async def get_background_task_status(task_id: str):
    """ë°±ê·¸ë¼ìš´ë“œ ì‘ì—… ìƒíƒœ ì¡°íšŒ"""
    # ì˜¤ë˜ëœ ì‘ì—… ì •ë¦¬
    clear_old_tasks()

    status = get_task_status(task_id)

    if not status:
        raise HTTPException(status_code=404, detail="ì‘ì—…ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")

    return JSONResponse({
        "success": True,
        "data": status
    })


@router.post("/batch/process")
async def batch_process_policies(
    policy_ids: List[str],
    background_tasks: BackgroundTasks,
    db = Depends(get_db)
):
    """
    ì—¬ëŸ¬ ì •ì±…ì„ ë°°ì¹˜ë¡œ ë°±ê·¸ë¼ìš´ë“œ ì²˜ë¦¬
    - í˜ì´ì§€ë¥¼ ë‚˜ê°€ë„ ë°±ì—”ë“œì—ì„œ ê³„ì† ì²˜ë¦¬ë¨
    """
    try:
        batch_task_id = f"batch_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        processed = []
        failed = []

        for policy_id in policy_ids:
            # ì •ì±… ì¡°íšŒ
            policy = await db["policies"].find_one({"policy_id": policy_id})
            if not policy:
                failed.append({"policy_id": policy_id, "reason": "ì •ì±…ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ"})
                continue

            # ObjectId ë³€í™˜
            policy["_id"] = str(policy["_id"])

            # datetime ë³€í™˜
            for key in ["created_at", "updated_at", "processed_at"]:
                if key in policy and policy[key] is not None:
                    if hasattr(policy[key], 'isoformat'):
                        policy[key] = policy[key].isoformat()

            # ë°±ê·¸ë¼ìš´ë“œ ì‘ì—… ì¶”ê°€
            background_tasks.add_task(
                process_policy_background,
                policy_id,
                policy,
                db
            )
            processed.append({
                "policy_id": policy_id,
                "task_id": f"policy_{policy_id}",
                "title": policy.get("title", "")
            })

        return JSONResponse({
            "success": True,
            "message": f"{len(processed)}ê°œ ì •ì±…ì´ ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì²˜ë¦¬ ì¤‘ì…ë‹ˆë‹¤. í˜ì´ì§€ë¥¼ ë‚˜ê°€ë„ ì²˜ë¦¬ê°€ ê³„ì†ë©ë‹ˆë‹¤.",
            "data": {
                "batch_task_id": batch_task_id,
                "processed": processed,
                "failed": failed,
                "total_queued": len(processed)
            }
        })

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ë°°ì¹˜ ì²˜ë¦¬ ì‹œì‘ ì‹¤íŒ¨: {str(e)}")


@router.get("/tasks/all")
async def get_all_task_status():
    """ëª¨ë“  ë°±ê·¸ë¼ìš´ë“œ ì‘ì—… ìƒíƒœ ì¡°íšŒ"""
    from app.policy.background_tasks import task_status

    # ì˜¤ë˜ëœ ì‘ì—… ì •ë¦¬
    clear_old_tasks()

    return JSONResponse({
        "success": True,
        "data": {
            "tasks": list(task_status.values()),
            "total": len(task_status)
        }
    })


# ===== OpenAI Vector Store ë™ê¸°í™” =====

from openai import OpenAI
import tempfile

# OpenAI ë™ê¸° í´ë¼ì´ì–¸íŠ¸ (Vector Store ê´€ë¦¬ìš©)
_openai_sync_client = None

def get_openai_sync_client():
    """OpenAI ë™ê¸° í´ë¼ì´ì–¸íŠ¸ ë°˜í™˜"""
    global _openai_sync_client
    if _openai_sync_client is None:
        api_key = os.getenv("OPENAI_API_KEY")
        if api_key:
            _openai_sync_client = OpenAI(api_key=api_key)
    return _openai_sync_client


@router.post("/sync/vector-store")
async def sync_policies_to_vector_store(
    db = Depends(get_db),
    current_user = Depends(get_current_policy_admin)
):
    """
    MongoDBì˜ ëª¨ë“  ì •ì±…ì„ OpenAI Vector Storeì™€ ë™ê¸°í™”
    - MongoDBì— ìˆì§€ë§Œ Vector Storeì— ì—†ëŠ” ì •ì±… ì¶”ê°€
    - ë™ê¸°í™” ìƒíƒœ ë°˜í™˜
    """
    try:
        client = get_openai_sync_client()
        if not client:
            raise HTTPException(status_code=500, detail="OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")

        vector_store_id = os.getenv("OPENAI_VECTOR_STORE_ID")
        if not vector_store_id:
            raise HTTPException(status_code=500, detail="OPENAI_VECTOR_STORE_IDê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")

        print(f"\n[Sync] ===== Vector Store ë™ê¸°í™” ì‹œì‘ =====")
        print(f"[Sync] Vector Store ID: {vector_store_id}")

        # 1. Vector Storeì˜ ê¸°ì¡´ íŒŒì¼ ëª©ë¡ ì¡°íšŒ
        existing_files = {}
        try:
            vs_files = client.vector_stores.files.list(vector_store_id=vector_store_id)
            for f in vs_files.data:
                # íŒŒì¼ ì •ë³´ì—ì„œ policy_id ì¶”ì¶œ ì‹œë„
                try:
                    file_info = client.files.retrieve(f.id)
                    existing_files[file_info.filename] = f.id
                except:
                    pass
            print(f"[Sync] Vector Store ê¸°ì¡´ íŒŒì¼: {len(existing_files)}ê°œ")
        except Exception as e:
            print(f"[Sync] âš ï¸ Vector Store íŒŒì¼ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {e}")

        # 2. MongoDBì—ì„œ ëª¨ë“  ì •ì±… ì¡°íšŒ
        cursor = db["policies"].find({})
        policies = []
        async for doc in cursor:
            doc["_id"] = str(doc["_id"])
            policies.append(doc)

        print(f"[Sync] MongoDB ì •ì±…: {len(policies)}ê°œ")

        # 3. ë™ê¸°í™” ì‹¤í–‰
        synced = []
        skipped = []
        failed = []

        for policy in policies:
            policy_id = policy.get("policy_id", "")
            title = policy.get("title", "Unknown")
            filename = f"policy_{policy_id}.txt"

            # ì´ë¯¸ Vector Storeì— ìˆìœ¼ë©´ ìŠ¤í‚µ
            if filename in existing_files:
                skipped.append({
                    "policy_id": policy_id,
                    "title": title,
                    "reason": "ì´ë¯¸ ë™ê¸°í™”ë¨",
                    "file_id": existing_files[filename]
                })
                continue

            # í…ìŠ¤íŠ¸ ì¤€ë¹„
            extracted_text = policy.get("extracted_text", "")
            if not extracted_text:
                failed.append({
                    "policy_id": policy_id,
                    "title": title,
                    "reason": "ì¶”ì¶œëœ í…ìŠ¤íŠ¸ ì—†ìŒ"
                })
                continue

            # ë©”íƒ€ë°ì´í„°ì™€ í•¨ê»˜ í…ìŠ¤íŠ¸ êµ¬ì„±
            policy_content = f"""ì •ì±… ì œëª©: {title}
ë°œí–‰ ê¸°ê´€: {policy.get('authority', 'Unknown')}
ì •ì±… ID: {policy_id}

=== ì •ì±… ë‚´ìš© ===
{extracted_text[:50000]}
"""

            try:
                # ì„ì‹œ íŒŒì¼ ìƒì„± ë° ì—…ë¡œë“œ
                with tempfile.NamedTemporaryFile(mode='w', suffix='.txt', delete=False, encoding='utf-8') as tmp:
                    tmp.write(policy_content)
                    tmp_path = tmp.name

                # OpenAIì— íŒŒì¼ ì—…ë¡œë“œ
                with open(tmp_path, 'rb') as f:
                    uploaded_file = client.files.create(
                        file=f,
                        purpose="assistants"
                    )

                # Vector Storeì— íŒŒì¼ ì¶”ê°€
                client.vector_stores.files.create(
                    vector_store_id=vector_store_id,
                    file_id=uploaded_file.id
                )

                # ì„ì‹œ íŒŒì¼ ì‚­ì œ
                os.unlink(tmp_path)

                # MongoDBì— ë™ê¸°í™” ìƒíƒœ ì—…ë°ì´íŠ¸
                await db["policies"].update_one(
                    {"policy_id": policy_id},
                    {"$set": {
                        "vector_store_file_id": uploaded_file.id,
                        "vector_store_synced_at": datetime.utcnow()
                    }}
                )

                synced.append({
                    "policy_id": policy_id,
                    "title": title,
                    "file_id": uploaded_file.id
                })
                print(f"[Sync] âœ… ë™ê¸°í™” ì™„ë£Œ: {title}")

            except Exception as e:
                failed.append({
                    "policy_id": policy_id,
                    "title": title,
                    "reason": str(e)
                })
                print(f"[Sync] âŒ ë™ê¸°í™” ì‹¤íŒ¨: {title} - {e}")

        print(f"[Sync] ===== ë™ê¸°í™” ì™„ë£Œ =====")
        print(f"[Sync] ë™ê¸°í™”: {len(synced)}ê°œ, ìŠ¤í‚µ: {len(skipped)}ê°œ, ì‹¤íŒ¨: {len(failed)}ê°œ\n")

        return JSONResponse({
            "success": True,
            "message": f"ë™ê¸°í™” ì™„ë£Œ: {len(synced)}ê°œ ì¶”ê°€, {len(skipped)}ê°œ ìŠ¤í‚µ, {len(failed)}ê°œ ì‹¤íŒ¨",
            "data": {
                "synced": synced,
                "skipped": skipped,
                "failed": failed,
                "total_in_mongodb": len(policies),
                "total_in_vector_store": len(existing_files) + len(synced),
                "vector_store_id": vector_store_id
            }
        })

    except HTTPException:
        raise
    except Exception as e:
        print(f"[Sync] âŒ ë™ê¸°í™” ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"ë™ê¸°í™” ì‹¤íŒ¨: {str(e)}")


@router.get("/sync/status")
async def get_sync_status(db = Depends(get_db)):
    """
    MongoDBì™€ OpenAI Vector Store ë™ê¸°í™” ìƒíƒœ í™•ì¸
    """
    try:
        client = get_openai_sync_client()
        vector_store_id = os.getenv("OPENAI_VECTOR_STORE_ID")

        # MongoDB ì •ì±… ìˆ˜
        mongo_count = await db["policies"].count_documents({})
        mongo_synced = await db["policies"].count_documents({"vector_store_file_id": {"$exists": True}})

        # Vector Store ì •ë³´
        vs_info = None
        vs_file_count = 0
        if client and vector_store_id:
            try:
                vs = client.vector_stores.retrieve(vector_store_id)
                vs_info = {
                    "id": vs.id,
                    "name": vs.name,
                    "status": vs.status,
                    "file_counts": {
                        "total": vs.file_counts.total if hasattr(vs.file_counts, 'total') else 0,
                        "completed": vs.file_counts.completed if hasattr(vs.file_counts, 'completed') else 0,
                        "in_progress": vs.file_counts.in_progress if hasattr(vs.file_counts, 'in_progress') else 0,
                        "failed": vs.file_counts.failed if hasattr(vs.file_counts, 'failed') else 0
                    }
                }
                vs_file_count = vs.file_counts.total if hasattr(vs.file_counts, 'total') else 0
            except Exception as e:
                print(f"Vector Store ì¡°íšŒ ì‹¤íŒ¨: {e}")

        return JSONResponse({
            "success": True,
            "data": {
                "mongodb": {
                    "total_policies": mongo_count,
                    "synced_to_vector_store": mongo_synced,
                    "not_synced": mongo_count - mongo_synced
                },
                "vector_store": vs_info,
                "sync_needed": mongo_count - mongo_synced > 0
            }
        })

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ë™ê¸°í™” ìƒíƒœ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")


@router.delete("/sync/vector-store/{policy_id}")
async def remove_policy_from_vector_store(
    policy_id: str,
    db = Depends(get_db),
    current_user = Depends(get_current_policy_admin)
):
    """
    íŠ¹ì • ì •ì±…ì„ Vector Storeì—ì„œ ì œê±°
    """
    try:
        client = get_openai_sync_client()
        if not client:
            raise HTTPException(status_code=500, detail="OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")

        vector_store_id = os.getenv("OPENAI_VECTOR_STORE_ID")

        # MongoDBì—ì„œ ì •ì±… ì¡°íšŒ
        policy = await db["policies"].find_one({"policy_id": policy_id})
        if not policy:
            raise HTTPException(status_code=404, detail="ì •ì±…ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")

        file_id = policy.get("vector_store_file_id")
        if not file_id:
            return JSONResponse({
                "success": True,
                "message": "ì´ ì •ì±…ì€ Vector Storeì— ë™ê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤"
            })

        # Vector Storeì—ì„œ íŒŒì¼ ì œê±°
        try:
            client.vector_stores.files.delete(
                vector_store_id=vector_store_id,
                file_id=file_id
            )
            # OpenAI íŒŒì¼ë„ ì‚­ì œ
            client.files.delete(file_id)
        except Exception as e:
            print(f"Vector Store íŒŒì¼ ì‚­ì œ ì˜¤ë¥˜: {e}")

        # MongoDB ì—…ë°ì´íŠ¸
        await db["policies"].update_one(
            {"policy_id": policy_id},
            {"$unset": {"vector_store_file_id": "", "vector_store_synced_at": ""}}
        )

        return JSONResponse({
            "success": True,
            "message": f"ì •ì±… '{policy.get('title')}'ì´(ê°€) Vector Storeì—ì„œ ì œê±°ë˜ì—ˆìŠµë‹ˆë‹¤"
        })

    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Vector Store ì œê±° ì‹¤íŒ¨: {str(e)}")