"""
ì •ì±… ê´€ë¦¬ ë¼ìš°í„°
- ì •ì±… ì¶”ê°€/ìˆ˜ì •/ì‚­ì œ
- ë©€í‹°ëª¨ë‹¬ íŒŒì¼ ì—…ë¡œë“œ (PDF, ì´ë¯¸ì§€)
- ì„ë² ë”© ìƒì„± ë° VectorDB ì €ì¥
"""

from fastapi import APIRouter, UploadFile, File, Form, HTTPException, Depends
from fastapi.responses import JSONResponse
from typing import List, Optional
import os
import json
import asyncio
from pathlib import Path
from datetime import datetime
import hashlib
import fitz  # PyMuPDF
from dotenv import load_dotenv

# OpenAI imports
try:
    from openai import AsyncOpenAI
    from pyzerox import zerox
    OPENAI_AVAILABLE = True
except ImportError:
    OPENAI_AVAILABLE = False

# Database imports
from app.database.mongodb import get_db
from app.policy.models import PolicyDocument, PolicyMetadata, PolicyResponse

# Background tasks
from app.policy.background_tasks import process_policy_background, get_task_status, clear_old_tasks
from fastapi import BackgroundTasks

load_dotenv()

router = APIRouter(prefix="/api/policies", tags=["Policy Management"])

# ì„¤ì •
UPLOAD_DIR = Path("backend/app/uploads/policies")
TEMP_DIR = Path("backend/app/uploads/temp")
PROCESSED_DIR = Path("backend/app/uploads/processed")
STAGING_DIR = Path("backend/app/rag/data/staging")  # backend/app/rag/dataë¡œ í†µì¼

UPLOAD_DIR.mkdir(parents=True, exist_ok=True)
TEMP_DIR.mkdir(parents=True, exist_ok=True)
PROCESSED_DIR.mkdir(parents=True, exist_ok=True)

# ì •ì±… ìŠ¤í‚¤ë§ˆ ìºì‹œ
_policy_schemas_cache = None
_cache_timestamp = None
CACHE_EXPIRY_SECONDS = 3600  # 1ì‹œê°„

# OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
if OPENAI_AVAILABLE:
    openai_api_key = os.getenv("OPENAI_API_KEY")
    if openai_api_key:
        openai_client = AsyncOpenAI(api_key=openai_api_key)
    else:
        openai_client = None
else:
    openai_client = None


class PolicyProcessor:
    """ì •ì±… ë¬¸ì„œ ì²˜ë¦¬ í´ë˜ìŠ¤"""

    def __init__(self):
        self.model = os.getenv("OPENAI_MODEL", "gpt-4o")
        self.vision_model = os.getenv("OPENAI_VISION_MODEL", "gpt-4o")

    async def process_pdf(self, file_path: str) -> dict:
        """PDF íŒŒì¼ì„ ì²˜ë¦¬í•˜ì—¬ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
        try:
            # PDF ì •ë³´ í™•ì¸
            doc = fitz.open(file_path)
            page_count = len(doc)
            file_size_mb = Path(file_path).stat().st_size / (1024 * 1024)
            doc.close()

            # ì‘ì€ PDFëŠ” Zerox ì‚¬ìš© (OCR + Vision)
            if page_count <= 50 and file_size_mb <= 20:
                if OPENAI_AVAILABLE and openai_client:
                    try:
                        result = await zerox(
                            file_path=file_path,
                            model=self.vision_model,
                            output_dir=str(TEMP_DIR),
                            cleanup=True,
                        )
                        markdown = result.get("content", "") if isinstance(result, dict) else str(result)
                        return {"text": markdown, "method": "zerox_ocr"}
                    except Exception as e:
                        print(f"Zerox failed: {e}, falling back to PyMuPDF")

            # Fallback: PyMuPDFë¡œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
            doc = fitz.open(file_path)
            text = ""
            for page in doc:
                text += page.get_text()
            doc.close()

            return {"text": text, "method": "pymupdf"}

        except Exception as e:
            raise HTTPException(status_code=500, detail=f"PDF ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}")

    async def process_image(self, file_path: str) -> dict:
        """ì´ë¯¸ì§€ íŒŒì¼ì„ OCR ì²˜ë¦¬"""
        if not OPENAI_AVAILABLE or not openai_client:
            raise HTTPException(status_code=400, detail="OpenAI APIê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")

        try:
            # Vision APIë¡œ ì´ë¯¸ì§€ ë¶„ì„
            with open(file_path, "rb") as image_file:
                import base64
                image_data = base64.b64encode(image_file.read()).decode('utf-8')

            response = await openai_client.chat.completions.create(
                model=self.vision_model,
                messages=[
                    {
                        "role": "user",
                        "content": [
                            {
                                "type": "text",
                                "text": "ì´ë¯¸ì§€ì—ì„œ ëª¨ë“  í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ê³  ì •ì±… ë‚´ìš©ì„ êµ¬ì¡°í™”í•˜ì—¬ ë§ˆí¬ë‹¤ìš´ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”."
                            },
                            {
                                "type": "image_url",
                                "image_url": {
                                    "url": f"data:image/jpeg;base64,{image_data}"
                                }
                            }
                        ]
                    }
                ],
                max_tokens=4000
            )

            text = response.choices[0].message.content
            return {"text": text, "method": "vision_api"}

        except Exception as e:
            raise HTTPException(status_code=500, detail=f"ì´ë¯¸ì§€ ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}")

    async def extract_policy_metadata(self, text: str, title: str, authority: str) -> dict:
        """ì •ì±… í…ìŠ¤íŠ¸ì—ì„œ ë©”íƒ€ë°ì´í„° ì¶”ì¶œ"""
        if not OPENAI_AVAILABLE or not openai_client:
            # OpenAI ì—†ì´ ê¸°ë³¸ ë©”íƒ€ë°ì´í„°ë§Œ ë°˜í™˜
            return {
                "title": title,
                "authority": authority,
                "summary": text[:500],
                "keywords": [],
                "entity_types": []
            }

        prompt = f"""
ë‹¤ìŒ ì •ì±… ë¬¸ì„œì—ì„œ ë©”íƒ€ë°ì´í„°ë¥¼ ì¶”ì¶œí•˜ì„¸ìš”.

ì •ì±… ì œëª©: {title}
ë°œí–‰ ê¸°ê´€: {authority}

ë¬¸ì„œ ë‚´ìš©:
{text[:4000]}

ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ë°˜í™˜í•˜ì„¸ìš”:
{{
    "summary": "ì •ì±… ìš”ì•½ (200ì ì´ë‚´)",
    "keywords": ["í‚¤ì›Œë“œ1", "í‚¤ì›Œë“œ2", ...],
    "entity_types": ["ê°œì¸ì •ë³´ ìœ í˜•1", "ê°œì¸ì •ë³´ ìœ í˜•2", ...],
    "scenarios": ["ì ìš© ì‹œë‚˜ë¦¬ì˜¤1", "ì ìš© ì‹œë‚˜ë¦¬ì˜¤2", ...],
    "directives": ["ì‹¤í–‰ ì§€ì¹¨1", "ì‹¤í–‰ ì§€ì¹¨2", ...]
}}

ë°˜ë“œì‹œ ìœ íš¨í•œ JSONë§Œ ë°˜í™˜í•˜ì„¸ìš”.
"""

        try:
            response = await openai_client.chat.completions.create(
                model=self.model,
                messages=[{"role": "user", "content": prompt}],
                temperature=0.3,
            )

            content = response.choices[0].message.content.strip()
            # JSON ì¶”ì¶œ
            import re
            content = re.sub(r'^```json\s*', '', content)
            content = re.sub(r'\s*```$', '', content)

            metadata = json.loads(content)
            metadata["title"] = title
            metadata["authority"] = authority

            return metadata

        except Exception as e:
            print(f"ë©”íƒ€ë°ì´í„° ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return {
                "title": title,
                "authority": authority,
                "summary": text[:500],
                "keywords": [],
                "entity_types": []
            }


# í˜„ì¬ ì‚¬ìš©ì í™•ì¸ (ì •ì±… ê´€ë¦¬ì ê¶Œí•œ)
async def get_current_policy_admin(db = Depends(get_db)):
    """ì •ì±… ê´€ë¦¬ì ê¶Œí•œ í™•ì¸"""
    # TODO: JWT í† í° ê²€ì¦ ë¡œì§ ì¶”ê°€
    # ì„ì‹œë¡œ ëª¨ë“  ìš”ì²­ í—ˆìš©
    return None


@router.post("/upload")
async def upload_policy_file(
    background_tasks: BackgroundTasks,
    file: UploadFile = File(...),
    title: str = Form(...),
    authority: str = Form(default="ë‚´ë¶€"),
    description: str = Form(default=""),
    db = Depends(get_db),
    current_user = Depends(get_current_policy_admin)
):
    """
    ì •ì±… íŒŒì¼ ì—…ë¡œë“œ (PDF, ì´ë¯¸ì§€ ë“±)
    ë©€í‹°ëª¨ë‹¬ ì²˜ë¦¬ ë° ì„ë² ë”© ìƒì„±
    """

    # íŒŒì¼ í™•ì¥ì í™•ì¸
    file_ext = os.path.splitext(file.filename)[1].lower()
    supported_exts = ['.pdf', '.png', '.jpg', '.jpeg', '.bmp', '.tiff']

    if file_ext not in supported_exts:
        raise HTTPException(
            status_code=400,
            detail=f"ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤. ì§€ì› í˜•ì‹: {', '.join(supported_exts)}"
        )

    # íŒŒì¼ ì €ì¥
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    safe_filename = f"{timestamp}_{file.filename}"
    file_path = UPLOAD_DIR / safe_filename

    try:
        # íŒŒì¼ ì €ì¥
        with open(file_path, "wb") as f:
            content = await file.read()
            f.write(content)

        # íŒŒì¼ ì²˜ë¦¬
        processor = PolicyProcessor()

        if file_ext == '.pdf':
            result = await processor.process_pdf(str(file_path))
        else:
            result = await processor.process_image(str(file_path))

        extracted_text = result["text"]
        processing_method = result["method"]

        # ë©”íƒ€ë°ì´í„° ì¶”ì¶œ
        metadata_dict = await processor.extract_policy_metadata(
            extracted_text,
            title,
            authority
        )

        # PolicyMetadata ëª¨ë¸ë¡œ ë³€í™˜
        metadata = PolicyMetadata(**metadata_dict)

        # ì •ì±… ID ìƒì„±
        policy_id = hashlib.md5(f"{title}_{timestamp}".encode()).hexdigest()[:12]

        # PolicyDocument ëª¨ë¸ ìƒì„±
        policy_doc = PolicyDocument(
            policy_id=policy_id,
            title=title,
            authority=authority,
            description=description,
            original_filename=file.filename,
            saved_filename=safe_filename,
            file_type=file_ext,
            file_size_mb=len(content) / (1024 * 1024),
            processing_method=processing_method,
            extracted_text=extracted_text,
            metadata=metadata,
            created_by=None  # TODO: í˜„ì¬ ì‚¬ìš©ì ì´ë©”ì¼
        )

        # MongoDBì— ì €ì¥
        await db["policies"].insert_one(policy_doc.model_dump(mode='json'))

        # ë°±ì—…ìš©ìœ¼ë¡œ íŒŒì¼ì—ë„ ì €ì¥
        processed_file = PROCESSED_DIR / f"policy_{policy_id}.json"
        with open(processed_file, "w", encoding="utf-8") as f:
            json.dump(policy_doc.model_dump(mode='json'), f, ensure_ascii=False, indent=2)

        # ë°±ê·¸ë¼ìš´ë“œì—ì„œ ê°€ì´ë“œë¼ì¸ ì¶”ì¶œ ë° VectorDB ì„ë² ë”© ì‹¤í–‰
        background_tasks.add_task(
            process_policy_background,
            policy_id,
            policy_doc.model_dump(mode='json'),
            db
        )

        return JSONResponse({
            "success": True,
            "message": "ì •ì±… íŒŒì¼ì´ ì„±ê³µì ìœ¼ë¡œ ì—…ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤. ë°±ê·¸ë¼ìš´ë“œì—ì„œ ê°€ì´ë“œë¼ì¸ ì¶”ì¶œ ì¤‘ì…ë‹ˆë‹¤.",
            "data": {
                "policy_id": policy_id,
                "title": title,
                "authority": authority,
                "file_type": file_ext,
                "processing_method": processing_method,
                "metadata": metadata_dict,
                "text_length": len(extracted_text),
                "created_at": policy_doc.created_at.isoformat(),
                "task_id": f"policy_{policy_id}"
            }
        })

    except Exception as e:
        # ì˜¤ë¥˜ ë°œìƒ ì‹œ ì—…ë¡œë“œëœ íŒŒì¼ ì‚­ì œ
        if file_path.exists():
            file_path.unlink()
        raise HTTPException(status_code=500, detail=f"íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")


@router.get("/list")
async def list_policies(
    skip: int = 0,
    limit: int = 50,
    authority: str = None,
    db = Depends(get_db)
):
    """ì •ì±… ëª©ë¡ ì¡°íšŒ"""
    try:
        # í•„í„° ì¡°ê±´
        query = {}
        if authority:
            query["authority"] = authority

        # ì´ ê°œìˆ˜ ì¡°íšŒ
        total = await db["policies"].count_documents(query)

        # ì •ì±… ëª©ë¡ ì¡°íšŒ (ì „ì²´ í…ìŠ¤íŠ¸ ì œì™¸)
        cursor = db["policies"].find(
            query,
            {
                "extracted_text": 0  # ì „ì²´ í…ìŠ¤íŠ¸ëŠ” ì œì™¸
            }
        ).sort("created_at", -1).skip(skip).limit(limit)

        policies = []
        async for doc in cursor:
            # _idë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜
            doc["_id"] = str(doc["_id"])
            policies.append(doc)

        return JSONResponse({
            "success": True,
            "data": {
                "policies": policies,
                "total": total,
                "skip": skip,
                "limit": limit
            }
        })

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ì •ì±… ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")



# ===== ì •ì±… ìŠ¤í‚¤ë§ˆ ë¡œë”© ë° ìºì‹± =====

async def load_policy_schemas_from_staging():
    """staging ë””ë ‰í† ë¦¬ì—ì„œ ì •ì±… ìŠ¤í‚¤ë§ˆ ë¡œë“œ"""
    global _policy_schemas_cache, _cache_timestamp

    # ìºì‹œ ìœ íš¨ì„± í™•ì¸
    if _policy_schemas_cache and _cache_timestamp:
        elapsed = (datetime.now() - _cache_timestamp).total_seconds()
        if elapsed < CACHE_EXPIRY_SECONDS:
            print(f"âœ… ìºì‹œëœ ì •ì±… ìŠ¤í‚¤ë§ˆ ë°˜í™˜ (ìºì‹œ ìœ íš¨ ì‹œê°„: {CACHE_EXPIRY_SECONDS - elapsed:.0f}ì´ˆ ë‚¨ìŒ)")
            return _policy_schemas_cache

    print(f"ğŸ“‚ Staging ë””ë ‰í† ë¦¬ì—ì„œ ì •ì±… ìŠ¤í‚¤ë§ˆ ë¡œë”© ì¤‘... ({STAGING_DIR})")

    if not STAGING_DIR.exists():
        print(f"âš ï¸ Staging ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {STAGING_DIR}")
        return []

    schemas = []
    jsonl_files = list(STAGING_DIR.glob("*.jsonl"))

    if not jsonl_files:
        print(f"âš ï¸ JSONL íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {STAGING_DIR}")
        return []

    print(f"ğŸ“„ {len(jsonl_files)}ê°œì˜ JSONL íŒŒì¼ ë°œê²¬")

    for jsonl_file in jsonl_files:
        try:
            with open(jsonl_file, 'r', encoding='utf-8') as f:
                for line_num, line in enumerate(f, 1):
                    line = line.strip()
                    if not line:
                        continue
                    try:
                        schema = json.loads(line)
                        schemas.append({
                            "source_file": jsonl_file.name,
                            "line_number": line_num,
                            **schema
                        })
                    except json.JSONDecodeError as e:
                        print(f"âš ï¸ JSON íŒŒì‹± ì˜¤ë¥˜ ({jsonl_file.name}:{line_num}): {e}")
        except Exception as e:
            print(f"âš ï¸ íŒŒì¼ ì½ê¸° ì˜¤ë¥˜ ({jsonl_file.name}): {e}")

    # ìºì‹œ ì—…ë°ì´íŠ¸
    _policy_schemas_cache = schemas
    _cache_timestamp = datetime.now()

    print(f"âœ… {len(schemas)}ê°œì˜ ì •ì±… ìŠ¤í‚¤ë§ˆ ë¡œë“œ ì™„ë£Œ (ìºì‹œë¨)")
    return schemas


@router.get("/schemas")
async def get_policy_schemas(
    skip: int = 0,
    limit: int = 50,
    refresh_cache: bool = False
):
    """
    ì •ì±… ìŠ¤í‚¤ë§ˆ ëª©ë¡ ì¡°íšŒ (staging ë””ë ‰í† ë¦¬ì—ì„œ ë¡œë“œ)
    - skip: ê±´ë„ˆë›¸ ê°œìˆ˜
    - limit: ë°˜í™˜í•  ìµœëŒ€ ê°œìˆ˜  
    - refresh_cache: Trueë©´ ìºì‹œ ë¬´ì‹œí•˜ê³  ì¬ë¡œë“œ
    """
    global _policy_schemas_cache, _cache_timestamp

    # ìºì‹œ ê°•ì œ ìƒˆë¡œê³ ì¹¨
    if refresh_cache:
        _policy_schemas_cache = None
        _cache_timestamp = None

    schemas = await load_policy_schemas_from_staging()

    total = len(schemas)
    schemas_page = schemas[skip:skip + limit]

    cache_expires_in = 0
    if _cache_timestamp:
        cache_expires_in = CACHE_EXPIRY_SECONDS - (datetime.now() - _cache_timestamp).total_seconds()

    return JSONResponse({
        "success": True,
        "data": {
            "total": total,
            "skip": skip,
            "limit": limit,
            "cached": _cache_timestamp is not None,
            "cache_expires_in": max(0, cache_expires_in),
            "schemas": schemas_page
        }
    })

@router.get("/{policy_id}")
async def get_policy_detail(
    policy_id: str,
    db = Depends(get_db)
):
    """ì •ì±… ìƒì„¸ ì¡°íšŒ"""
    try:
        policy = await db["policies"].find_one({"policy_id": policy_id})

        if not policy:
            raise HTTPException(status_code=404, detail="ì •ì±…ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")

        # _idë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜
        policy["_id"] = str(policy["_id"])

        return JSONResponse({
            "success": True,
            "data": policy
        })

    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ì •ì±… ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")


@router.delete("/{policy_id}")
async def delete_policy(
    policy_id: str,
    db = Depends(get_db),
    current_user = Depends(get_current_policy_admin)
):
    """ì •ì±… ì‚­ì œ"""
    try:
        # ì •ì±… ì¡°íšŒ
        policy = await db["policies"].find_one({"policy_id": policy_id})

        if not policy:
            raise HTTPException(status_code=404, detail="ì •ì±…ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")

        # ì›ë³¸ íŒŒì¼ ì‚­ì œ
        original_file = UPLOAD_DIR / policy["saved_filename"]
        if original_file.exists():
            original_file.unlink()

        # ë°±ì—… íŒŒì¼ ì‚­ì œ
        backup_file = PROCESSED_DIR / f"policy_{policy_id}.json"
        if backup_file.exists():
            backup_file.unlink()

        # MongoDBì—ì„œ ì‚­ì œ
        await db["policies"].delete_one({"policy_id": policy_id})

        return JSONResponse({
            "success": True,
            "message": "ì •ì±…ì´ ì„±ê³µì ìœ¼ë¡œ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤"
        })

    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ì •ì±… ì‚­ì œ ì‹¤íŒ¨: {str(e)}")


@router.get("/stats/summary")
async def get_policy_stats(db = Depends(get_db)):
    """ì •ì±… í†µê³„ ì¡°íšŒ"""
    try:
        # ì´ ì •ì±… ìˆ˜
        total_policies = await db["policies"].count_documents({})

        # ì´ ì—”í‹°í‹° ìˆ˜ (entities ì»¬ë ‰ì…˜ì—ì„œ ì¡°íšŒ)
        total_entities = await db.get_collection("entities").count_documents({})

        # ê¸°ê´€ë³„ ì§‘ê³„
        authority_pipeline = [
            {"$group": {"_id": "$authority", "count": {"$sum": 1}}}
        ]
        authority_cursor = db["policies"].aggregate(authority_pipeline)
        authority_count = {}
        async for doc in authority_cursor:
            authority_count[doc["_id"]] = doc["count"]

        # íŒŒì¼ íƒ€ì…ë³„ ì§‘ê³„
        file_type_pipeline = [
            {"$group": {"_id": "$file_type", "count": {"$sum": 1}}}
        ]
        file_type_cursor = db["policies"].aggregate(file_type_pipeline)
        file_type_count = {}
        async for doc in file_type_cursor:
            file_type_count[doc["_id"]] = doc["count"]

        return JSONResponse({
            "success": True,
            "data": {
                "total_policies": total_policies,
                "total_entities": total_entities,
                "by_authority": authority_count,
                "by_file_type": file_type_count
            }
        })

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"í†µê³„ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")


@router.get("/tasks/{task_id}/status")
async def get_background_task_status(task_id: str):
    """ë°±ê·¸ë¼ìš´ë“œ ì‘ì—… ìƒíƒœ ì¡°íšŒ"""
    # ì˜¤ë˜ëœ ì‘ì—… ì •ë¦¬
    clear_old_tasks()

    status = get_task_status(task_id)

    if not status:
        raise HTTPException(status_code=404, detail="ì‘ì—…ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")

    return JSONResponse({
        "success": True,
        "data": status
    })


