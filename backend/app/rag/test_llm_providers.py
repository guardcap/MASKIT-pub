"""
LLM Provider í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
Ollamaì™€ OpenAI ëª¨ë¸ì„ í…ŒìŠ¤íŠ¸í•˜ëŠ” ê°„ë‹¨í•œ ìŠ¤í¬ë¦½íŠ¸
"""
import os
import sys

sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from agent.llm_factory import get_llm, list_supported_models


def test_llm(model_name: str):
    """LLM ëª¨ë¸ í…ŒìŠ¤íŠ¸"""
    print(f"\n{'=' * 80}")
    print(f" í…ŒìŠ¤íŠ¸: {model_name} ".center(80, '='))
    print(f"{'=' * 80}\n")

    try:
        # LLM ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
        llm = get_llm(model=model_name, temperature=0.0)
        print(f"âœ… LLM ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ì„±ê³µ")
        print(f"   - íƒ€ì…: {type(llm).__name__}")

        # ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬
        from langchain_core.messages import HumanMessage

        test_message = "ì•ˆë…•í•˜ì„¸ìš”. ê°„ë‹¨í•˜ê²Œ 'í…ŒìŠ¤íŠ¸ ì„±ê³µ'ì´ë¼ê³ ë§Œ ë‹µë³€í•´ì£¼ì„¸ìš”."
        print(f"\nğŸ“ í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬: {test_message[:50]}...")

        response = llm.invoke([HumanMessage(content=test_message)])
        print(f"âœ… ì‘ë‹µ ìˆ˜ì‹  ì„±ê³µ")
        print(f"\nğŸ’¬ ì‘ë‹µ ë‚´ìš©:")
        print(f"   {response.content}\n")

        return True

    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
        return False


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print("\n" + "=" * 80)
    print(" Guardcap LLM Provider í…ŒìŠ¤íŠ¸ ".center(80, "="))
    print("=" * 80)

    # ì§€ì› ëª¨ë¸ ëª©ë¡ ì¶œë ¥
    list_supported_models()

    # í…ŒìŠ¤íŠ¸í•  ëª¨ë¸ ì„ íƒ
    print("\ní…ŒìŠ¤íŠ¸ ì˜µì…˜:")
    print("  1. Ollama (llama3)")
    print("  2. OpenAI (gpt-3.5-turbo) - OPENAI_API_KEY í•„ìš”")
    print("  3. ì‚¬ìš©ì ì§€ì • ëª¨ë¸")
    print("  4. ëª¨ë‘ ê±´ë„ˆë›°ê¸°\n")

    choice = input("ì„ íƒ (1-4): ").strip()

    if choice == "1":
        test_llm("llama3")

    elif choice == "2":
        if not os.getenv("OPENAI_API_KEY"):
            print("\nâš ï¸  ê²½ê³ : OPENAI_API_KEY í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            print("   export OPENAI_API_KEY=sk-...")
            return

        test_llm("gpt-3.5-turbo")

    elif choice == "3":
        model = input("ëª¨ë¸ëª… ì…ë ¥: ").strip()
        test_llm(model)

    else:
        print("\ní…ŒìŠ¤íŠ¸ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")

    print("\n" + "=" * 80)
    print(" í…ŒìŠ¤íŠ¸ ì™„ë£Œ ".center(80, "="))
    print("=" * 80)
    print("\nğŸ’¡ Tip: í™˜ê²½ ë³€ìˆ˜ë¡œ ëª¨ë¸ì„ ì„¤ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:")
    print("   export LLM_MODEL=gpt-4")
    print("   export OPENAI_API_KEY=sk-...")
    print("   python main_agent.py\n")


if __name__ == "__main__":
    main()
