"""
ìµœì í™” ë²„ì „ - ë³‘ë ¬ ë°°ì¹˜ ì²˜ë¦¬
ì›ë³¸ íŒŒì¼ ë°±ì—…ìš©ìœ¼ë¡œ ë³„ë„ ì €ì¥
"""

# ê¸°ì¡´ process_guidelines.pyì˜ _process_large_pdf ë©”ì„œë“œë¥¼
# ë‹¤ìŒê³¼ ê°™ì´ ìˆ˜ì •í•˜ë©´ ë³‘ë ¬ ì²˜ë¦¬ ê°€ëŠ¥:

async def _process_large_pdf_parallel(
    self,
    pdf_path: str,
    pdf_path_obj: Path,
    authority: str,
    max_concurrent: int = 3  # ë™ì‹œ ì²˜ë¦¬ ë°°ì¹˜ ìˆ˜
) -> List[ApplicationGuide]:
    """ëŒ€ìš©ëŸ‰ PDF ë³‘ë ¬ ë°°ì¹˜ ì²˜ë¦¬"""
    print("ğŸ”ª Splitting PDF into smaller batches...")

    batch_dir = self.temp_dir / f"batches_{pdf_path_obj.stem}"
    batch_files = self.pdf_processor.split_pdf_by_pages(pdf_path, batch_dir)

    print(f"âœ… Created {len(batch_files)} batches")

    all_guides = []

    # ì„¸ë§ˆí¬ì–´ë¡œ ë™ì‹œ ì‹¤í–‰ ì œí•œ
    semaphore = asyncio.Semaphore(max_concurrent)

    async def process_single_batch(i: int, batch_file: Path):
        async with semaphore:
            try:
                result = await zerox(
                    file_path=str(batch_file),
                    model=self.vision_model,
                    output_dir=str(self.temp_dir / f"batch_{i}"),
                    cleanup=True,
                )

                markdown = result.get("content", "") if isinstance(result, dict) else str(result)

                guides = await self._structure_document(
                    markdown,
                    source_document=f"{pdf_path_obj.name} (batch {i+1}/{len(batch_files)})",
                    authority=authority
                )

                return guides

            except Exception as e:
                print(f"âš ï¸  Batch {i+1} failed: {e}")
                return []

    # ëª¨ë“  ë°°ì¹˜ë¥¼ ë™ì‹œì— ì²˜ë¦¬
    tasks = [process_single_batch(i, batch_file) for i, batch_file in enumerate(batch_files)]
    results = await asyncio.gather(*tasks)

    # ê²°ê³¼ ë³‘í•©
    for guides in results:
        all_guides.extend(guides)

    # ì„ì‹œ íŒŒì¼ ì •ë¦¬
    import shutil
    shutil.rmtree(batch_dir, ignore_errors=True)

    return all_guides


# ì‚¬ìš©ë²•: process_guidelines.py íŒŒì¼ì˜ _process_large_pdf ë©”ì„œë“œë¥¼ ìœ„ ì½”ë“œë¡œ êµì²´
# ê·¸ë¦¬ê³  .envì— ì¶”ê°€:
# MAX_CONCURRENT_BATCHES=3  # ë™ì‹œ ì²˜ë¦¬í•  ë°°ì¹˜ ìˆ˜ (OpenAI rate limit ê³ ë ¤)
