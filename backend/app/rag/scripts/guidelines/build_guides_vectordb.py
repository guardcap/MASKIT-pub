"""
Application Guides VectorDB ë¹Œë“œ
ChromaDB + OpenAI Embeddings
"""

import json
from pathlib import Path
from typing import List, Dict
import chromadb
from chromadb.config import Settings
from openai import OpenAI
import os
from tqdm import tqdm
from dotenv import load_dotenv

# .env íŒŒì¼ ë¡œë“œ
load_dotenv()


class GuidesVectorDBBuilder:
    """Application Guides VectorDB ë¹Œë”"""

    def __init__(
        self,
        openai_api_key: str = None,
        db_path: str = "data/chromadb/application_guides",
        collection_name: str = "application_guides"
    ):
        api_key = openai_api_key or os.getenv("OPENAI_API_KEY")
        if not api_key:
            raise ValueError("OPENAI_API_KEY not found in environment or .env file")

        self.client = OpenAI(api_key=api_key)
        self.embedding_model = os.getenv("OPENAI_EMBEDDING_MODEL", "text-embedding-3-small")
        self.db_path = Path(db_path)
        self.collection_name = collection_name

        # ChromaDB ì´ˆê¸°í™”
        self.db_path.mkdir(parents=True, exist_ok=True)
        self.chroma_client = chromadb.PersistentClient(
            path=str(self.db_path)
        )

        # ê¸°ì¡´ ì»¬ë ‰ì…˜ ì‚­ì œ í›„ ì¬ìƒì„±
        try:
            self.chroma_client.delete_collection(name=collection_name)
            print(f"ğŸ—‘ï¸  Deleted existing collection: {collection_name}")
        except:
            pass

        self.collection = self.chroma_client.create_collection(
            name=collection_name,
            metadata={"hnsw:space": "cosine"}
        )

    def load_guides(self, jsonl_path: str) -> List[Dict]:
        """ë‹¨ì¼ JSONL íŒŒì¼ ë¡œë“œ"""
        guides = []
        with open(jsonl_path, "r", encoding="utf-8") as f:
            for line in f:
                if line.strip():  # ë¹ˆ ì¤„ ë¬´ì‹œ
                    guides.append(json.loads(line))
        return guides

    def load_all_guides_from_directory(self, directory: str, pattern: str = "application_guides_*_unique.jsonl") -> List[Dict]:
        """
        ë””ë ‰í† ë¦¬ì—ì„œ íŒ¨í„´ì— ë§ëŠ” ëª¨ë“  JSONL íŒŒì¼ ë¡œë“œ

        Args:
            directory: ê²€ìƒ‰í•  ë””ë ‰í† ë¦¬
            pattern: íŒŒì¼ëª… íŒ¨í„´ (glob)

        Returns:
            ëª¨ë“  íŒŒì¼ì˜ ê°€ì´ë“œë¥¼ í•©ì¹œ ë¦¬ìŠ¤íŠ¸
        """
        dir_path = Path(directory)
        if not dir_path.exists():
            return []

        all_guides = []
        jsonl_files = sorted(dir_path.glob(pattern))

        if not jsonl_files:
            # Fallback: ëª¨ë“  application_guides_*.jsonl íŒŒì¼ (review ì œì™¸)
            jsonl_files = [
                f for f in sorted(dir_path.glob("application_guides_*.jsonl"))
                if "review" not in f.name.lower()
            ]

        print(f"ğŸ“‚ Found {len(jsonl_files)} guide files in {directory}")

        for jsonl_file in jsonl_files:
            print(f"  - Loading: {jsonl_file.name}")
            guides = self.load_guides(str(jsonl_file))
            all_guides.extend(guides)
            print(f"    â†’ {len(guides)} guides")

        return all_guides

    def get_embedding(self, text: str) -> List[float]:
        """OpenAI Embedding ìƒì„±"""
        response = self.client.embeddings.create(
            model=self.embedding_model,
            input=text
        )
        return response.data[0].embedding

    def build_search_text(self, guide: Dict) -> str:
        """ê²€ìƒ‰ìš© í…ìŠ¤íŠ¸ êµ¬ì„±"""
        parts = [
            f"Scenario: {guide.get('scenario', '')}",
            f"Directive: {guide.get('actionable_directive', '')}",
            f"Interpretation: {guide.get('interpretation', '')}",
            f"Keywords: {', '.join(guide.get('keywords', []))}",
        ]

        # ì˜ˆì‹œ ì¶”ê°€
        for example in guide.get('examples', []):
            parts.append(f"Example: {example.get('case_description', '')}")

        return "\n".join(parts)

    def build_metadata(self, guide: Dict) -> Dict:
        """ë©”íƒ€ë°ì´í„° êµ¬ì„±"""
        context = guide.get('context', {}) or {}

        return {
            "guide_id": guide.get("guide_id", ""),
            "authority": guide.get("source_authority", ""),
            "source_document": guide.get("source_document", ""),
            "scenario": guide.get("scenario", "")[:500],  # ê¸¸ì´ ì œí•œ
            "sender_type": context.get("sender_type", ""),
            "receiver_type": context.get("receiver_type", ""),
            "email_purpose": context.get("email_purpose", ""),
            "pii_types": ",".join(context.get("pii_types", [])),
            "publish_date": guide.get("publish_date", ""),
            "confidence_score": str(guide.get("confidence_score", 0.8)),
            "reviewed": str(guide.get("reviewed", False)),
        }

    def add_guides_to_db(self, guides: List[Dict], batch_size: int = 100):
        """ê°€ì´ë“œë¥¼ VectorDBì— ì¶”ê°€"""
        print(f"\nğŸ“Š Adding {len(guides)} guides to ChromaDB...")

        # ë°°ì¹˜ ì²˜ë¦¬
        for i in tqdm(range(0, len(guides), batch_size), desc="Building VectorDB"):
            batch = guides[i:i + batch_size]

            ids = []
            documents = []
            embeddings = []
            metadatas = []

            for guide in batch:
                guide_id = guide.get("guide_id")
                if not guide_id:
                    continue

                # ê²€ìƒ‰ í…ìŠ¤íŠ¸
                search_text = self.build_search_text(guide)

                # Embedding ìƒì„±
                embedding = self.get_embedding(search_text)

                # ë©”íƒ€ë°ì´í„°
                metadata = self.build_metadata(guide)

                ids.append(guide_id)
                documents.append(search_text)
                embeddings.append(embedding)
                metadatas.append(metadata)

            # ChromaDBì— ì¶”ê°€
            if ids:
                self.collection.add(
                    ids=ids,
                    documents=documents,
                    embeddings=embeddings,
                    metadatas=metadatas
                )

        print(f"âœ… Successfully added {len(guides)} guides to VectorDB")

    def test_search(self, query: str, top_k: int = 3):
        """ê²€ìƒ‰ í…ŒìŠ¤íŠ¸"""
        print(f"\nğŸ” Testing search: '{query}'")

        # ì¿¼ë¦¬ ì„ë² ë”©
        query_embedding = self.get_embedding(query)

        # ê²€ìƒ‰
        results = self.collection.query(
            query_embeddings=[query_embedding],
            n_results=top_k,
            include=["documents", "metadatas", "distances"]
        )

        # ê²°ê³¼ ì¶œë ¥
        for i, (doc, meta, dist) in enumerate(zip(
            results['documents'][0],
            results['metadatas'][0],
            results['distances'][0]
        )):
            print(f"\n--- Result {i+1} (distance: {dist:.4f}) ---")
            print(f"Guide ID: {meta.get('guide_id')}")
            print(f"Scenario: {meta.get('scenario')}")
            print(f"Authority: {meta.get('authority')}")
            print(f"Document: {doc[:200]}...")

    def get_stats(self) -> Dict:
        """VectorDB í†µê³„"""
        count = self.collection.count()

        return {
            "total_guides": count,
            "collection_name": self.collection_name,
            "db_path": str(self.db_path),
        }


def main():
    """ë©”ì¸ ì‹¤í–‰"""

    # ë¹Œë” ì´ˆê¸°í™” (.envì—ì„œ ìë™ ë¡œë“œ)
    try:
        builder = GuidesVectorDBBuilder(
            db_path="guardcap-rag/data/chromadb/application_guides",
            collection_name="application_guides"
        )
        print(f"âœ… Using embedding model: {builder.embedding_model}")
    except ValueError as e:
        print(f"âŒ Configuration error: {e}")
        print("\nPlease ensure:")
        print("1. .env file exists in the project root")
        print("2. OPENAI_API_KEY is set in .env")
        return

    # staging ë””ë ‰í† ë¦¬ì˜ ëª¨ë“  unique ê°€ì´ë“œ ë¡œë“œ
    staging_dirs = [
        "guardcap-rag/data/staging",
        "data/staging"
    ]

    guides = []
    for staging_dir in staging_dirs:
        if Path(staging_dir).exists():
            guides = builder.load_all_guides_from_directory(
                staging_dir,
                pattern="application_guides_*_unique.jsonl"
            )
            if guides:
                print(f"\nğŸ“Š Total loaded: {len(guides)} guides")
                break

    if not guides:
        print("âŒ No guide files found in staging directory!")
        print("\nPlease run:")
        print("  1. process_guidelines.py - to generate guides")
        print("  2. validate_and_dedup.py - to create unique guides")
        return

    # VectorDB ë¹Œë“œ
    builder.add_guides_to_db(guides, batch_size=50)

    # í†µê³„
    stats = builder.get_stats()
    print(f"\nğŸ“Š VectorDB Stats:")
    for key, value in stats.items():
        print(f"  {key}: {value}")

    # ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
    test_queries = [
        "ê³ ê°ì´ ë¨¼ì € ë¬¸ì˜í•œ ê²½ìš° ê°œì¸ì •ë³´ ë§ˆìŠ¤í‚¹",
        "ì´ë©”ì¼ ì£¼ì†Œ ìˆ˜ì§‘ ë™ì˜",
        "ë§ˆì¼€íŒ… ëª©ì  ê°œì¸ì •ë³´ í™œìš©",
    ]

    for query in test_queries:
        builder.test_search(query, top_k=2)

    print("\nâœ¨ VectorDB build complete!")
    print(f"ğŸ“ Location: {builder.db_path}")


if __name__ == "__main__":
    main()
