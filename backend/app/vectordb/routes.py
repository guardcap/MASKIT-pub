"""
VectorDB ë° ì •ì±… ìŠ¤í‚¤ë§ˆ ê´€ë¦¬ ë¼ìš°í„°
- JSONL íŒŒì¼ ê´€ë¦¬ (CRUD)
- OpenAI Vector Store ë™ê¸°í™”
- source_document ê¸°ë°˜ ê·¸ë£¹í™”
"""

from fastapi import APIRouter, HTTPException, Depends, Request
from fastapi.responses import JSONResponse
from typing import List, Optional, Dict, Any
from pathlib import Path
from datetime import datetime
import json
from openai import OpenAI
import os
from dotenv import load_dotenv
import hashlib
from pydantic import BaseModel

from app.audit.logger import AuditLogger
from app.auth.auth_utils import get_current_user

load_dotenv()

router = APIRouter(prefix="/api/vectordb", tags=["VectorDB Management"])

# ê²½ë¡œ ì„¤ì • - ì ˆëŒ€ ê²½ë¡œë¡œ ë³€í™˜
BASE_DIR = Path(__file__).resolve().parent.parent.parent.parent
STAGING_DIR = BASE_DIR / "app" / "rag" / "data" / "staging"

# ë””ë ‰í† ë¦¬ ìƒì„±
STAGING_DIR.mkdir(parents=True, exist_ok=True)

# OpenAI í´ë¼ì´ì–¸íŠ¸
openai_client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# OpenAI Vector Store ì„¤ì •
VECTOR_STORE_ID = os.getenv("OPENAI_VECTOR_STORE_ID")


# Pydantic ëª¨ë¸
class PolicyGuide(BaseModel):
    guide_id: str
    source_authority: str
    source_document: str
    scenario: str
    context: Dict[str, Any]
    interpretation: str
    actionable_directive: str
    keywords: List[str]
    related_law_ids: List[str]
    examples: List[Dict[str, Any]]
    confidence_score: float
    reviewed: bool


class PolicyGuideCreate(BaseModel):
    source_authority: str
    source_document: str
    scenario: str
    context: Dict[str, Any]
    interpretation: str
    actionable_directive: str
    keywords: List[str]
    related_law_ids: List[str]
    examples: List[Dict[str, Any]]
    confidence_score: Optional[float] = 0.8
    reviewed: Optional[bool] = False


class PolicyGuideUpdate(BaseModel):
    source_authority: Optional[str] = None
    scenario: Optional[str] = None
    context: Optional[Dict[str, Any]] = None
    interpretation: Optional[str] = None
    actionable_directive: Optional[str] = None
    keywords: Optional[List[str]] = None
    related_law_ids: Optional[List[str]] = None
    examples: Optional[List[Dict[str, Any]]] = None
    confidence_score: Optional[float] = None
    reviewed: Optional[bool] = None


def build_search_text(guide: Dict) -> str:
    """ê²€ìƒ‰ìš© í…ìŠ¤íŠ¸ êµ¬ì„±"""
    parts = [
        f"Scenario: {guide.get('scenario', '')}",
        f"Directive: {guide.get('actionable_directive', '')}",
        f"Interpretation: {guide.get('interpretation', '')}",
        f"Keywords: {', '.join(guide.get('keywords', []))}",
    ]

    for example in guide.get('examples', []):
        parts.append(f"Example: {example.get('case_description', '')}")

    return "\n".join(parts)


def load_all_guides() -> Dict[str, List[Dict]]:
    """
    ëª¨ë“  JSONL íŒŒì¼ì„ ë¡œë“œí•˜ê³  source_documentë¡œ ê·¸ë£¹í™”
    Returns: {source_document: [guides...]}
    """
    if not STAGING_DIR.exists():
        return {}

    grouped_guides = {}
    jsonl_files = list(STAGING_DIR.glob("*.jsonl"))

    for jsonl_file in jsonl_files:
        try:
            with open(jsonl_file, "r", encoding="utf-8") as f:
                for line in f:
                    if line.strip():
                        guide = json.loads(line)
                        source_doc = guide.get("source_document", "Unknown")

                        if source_doc not in grouped_guides:
                            grouped_guides[source_doc] = []

                        guide["_jsonl_file"] = jsonl_file.name
                        grouped_guides[source_doc].append(guide)
        except Exception as e:
            print(f"íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨ {jsonl_file.name}: {e}")

    return grouped_guides


def load_guides_from_file(filename: str) -> List[Dict]:
    """íŠ¹ì • JSONL íŒŒì¼ì—ì„œ ê°€ì´ë“œ ë¡œë“œ"""
    file_path = STAGING_DIR / filename
    if not file_path.exists():
        return []

    guides = []
    with open(file_path, "r", encoding="utf-8") as f:
        for line in f:
            if line.strip():
                guides.append(json.loads(line))

    return guides


def save_guides_to_file(filename: str, guides: List[Dict]) -> bool:
    """ê°€ì´ë“œë¥¼ JSONL íŒŒì¼ì— ì €ì¥"""
    try:
        file_path = STAGING_DIR / filename
        with open(file_path, "w", encoding="utf-8") as f:
            for guide in guides:
                # _jsonl_file í•„ë“œ ì œê±°
                guide_copy = guide.copy()
                guide_copy.pop("_jsonl_file", None)
                f.write(json.dumps(guide_copy, ensure_ascii=False) + "\n")
        return True
    except Exception as e:
        print(f"íŒŒì¼ ì €ì¥ ì‹¤íŒ¨: {e}")
        return False


def search_openai_vector_store(query: str, top_k: int = 5) -> List[Dict]:
    """
    OpenAI Vector Storeì—ì„œ ê²€ìƒ‰
    """
    try:
        # File Searchë¥¼ ì‚¬ìš©í•˜ì—¬ Vector Store ê²€ìƒ‰
        response = openai_client.responses.create(
            model="gpt-4o-mini",
            input=query,
            tools=[{
                "type": "file_search",
                "vector_store_ids": [VECTOR_STORE_ID]
            }],
            tool_choice={"type": "file_search"}
        )

        # ê²€ìƒ‰ ê²°ê³¼ ì¶”ì¶œ
        results = []
        if hasattr(response, 'output') and response.output:
            for item in response.output:
                if hasattr(item, 'content'):
                    for content in item.content:
                        if hasattr(content, 'text'):
                            results.append({
                                'content': content.text,
                                'score': 0.9
                            })

        return results[:top_k]

    except Exception as e:
        print(f"OpenAI Vector Store ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
        return []


async def search_with_assistant(query: str, context: Dict = None) -> List[Dict]:
    """
    OpenAI Assistants APIì˜ File Search ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ì—¬ Vector Store ê²€ìƒ‰
    """
    try:
        # ì»¨í…ìŠ¤íŠ¸ ì •ë³´ë¥¼ ì¿¼ë¦¬ì— ì¶”ê°€
        receiver_type = context.get('receiver_type', 'external') if context else 'external'
        enhanced_query = f"ì´ë©”ì¼ {receiver_type} ì „ì†¡ ì‹œ ê°œì¸ì •ë³´ ë§ˆìŠ¤í‚¹ ê°€ì´ë“œë¼ì¸: {query}"

        # Responses APIë¡œ File Search ìˆ˜í–‰
        response = openai_client.responses.create(
            model="gpt-4o-mini",
            input=enhanced_query,
            tools=[{
                "type": "file_search",
                "vector_store_ids": [VECTOR_STORE_ID]
            }]
        )

        # ê²€ìƒ‰ ê²°ê³¼ íŒŒì‹±
        results = []

        # outputì—ì„œ file_search ê²°ê³¼ ì¶”ì¶œ
        if hasattr(response, 'output'):
            for output_item in response.output:
                # file_search_call íƒ€ì… ì²˜ë¦¬
                if hasattr(output_item, 'type') and output_item.type == 'file_search_call':
                    if hasattr(output_item, 'results') and output_item.results is not None:
                        for result in output_item.results:
                            results.append({
                                'content': result.get('text', ''),
                                'filename': result.get('filename', ''),
                                'score': result.get('score', 0.5)
                            })
                # message íƒ€ì… ì²˜ë¦¬ (í…ìŠ¤íŠ¸ ì‘ë‹µ)
                elif hasattr(output_item, 'content'):
                    for content in output_item.content:
                        if hasattr(content, 'text'):
                            # ì£¼ì„(annotations)ì—ì„œ íŒŒì¼ ì •ë³´ ì¶”ì¶œ
                            text = content.text
                            annotations = getattr(text, 'annotations', [])
                            for ann in annotations:
                                if hasattr(ann, 'file_citation'):
                                    results.append({
                                        'content': text.value if hasattr(text, 'value') else str(text),
                                        'file_id': ann.file_citation.file_id if hasattr(ann.file_citation, 'file_id') else '',
                                        'score': 0.8
                                    })

        # ê²°ê³¼ê°€ ì—†ìœ¼ë©´ ê¸°ë³¸ ì‘ë‹µ í…ìŠ¤íŠ¸ ì‚¬ìš©
        if not results and hasattr(response, 'output_text'):
            results.append({
                'content': response.output_text,
                'score': 0.7
            })

        print(f"âœ… OpenAI Vector Store ê²€ìƒ‰ ì™„ë£Œ: {len(results)}ê°œ ê²°ê³¼")
        return results

    except Exception as e:
        print(f"âš ï¸ OpenAI Vector Store ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return []


@router.get("/guides/grouped")
async def get_guides_grouped():
    """source_documentë¡œ ê·¸ë£¹í™”ëœ ëª¨ë“  ê°€ì´ë“œ ì¡°íšŒ"""
    try:
        grouped = load_all_guides()

        # í†µê³„ ì •ë³´ ì¶”ê°€
        result = []
        for source_doc, guides in grouped.items():
            result.append({
                "source_document": source_doc,
                "count": len(guides),
                "authorities": list(set(g.get("source_authority", "") for g in guides)),
                "jsonl_files": list(set(g.get("_jsonl_file", "") for g in guides)),
                "guides": guides
            })

        # source_document ì´ë¦„ìœ¼ë¡œ ì •ë ¬
        result.sort(key=lambda x: x["source_document"])

        return JSONResponse({
            "success": True,
            "data": {
                "total_source_documents": len(result),
                "total_guides": sum(item["count"] for item in result),
                "groups": result
            }
        })

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ê°€ì´ë“œ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")


@router.get("/guides/by-source/{source_document}")
async def get_guides_by_source(source_document: str):
    """íŠ¹ì • source_documentì˜ ê°€ì´ë“œ ì¡°íšŒ"""
    try:
        grouped = load_all_guides()
        guides = grouped.get(source_document, [])

        return JSONResponse({
            "success": True,
            "data": {
                "source_document": source_document,
                "count": len(guides),
                "guides": guides
            }
        })

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ê°€ì´ë“œ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")


@router.get("/guides/{guide_id}")
async def get_guide_by_id(guide_id: str):
    """íŠ¹ì • ê°€ì´ë“œ ì¡°íšŒ"""
    try:
        grouped = load_all_guides()

        for source_doc, guides in grouped.items():
            for guide in guides:
                if guide.get("guide_id") == guide_id:
                    return JSONResponse({
                        "success": True,
                        "data": guide
                    })

        raise HTTPException(status_code=404, detail="ê°€ì´ë“œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")

    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ê°€ì´ë“œ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")


@router.post("/guides")
async def create_guide(guide_data: PolicyGuideCreate):
    """ìƒˆ ê°€ì´ë“œ ìƒì„±"""
    try:
        # guide_id ìƒì„±
        timestamp = datetime.now().strftime("%Y%m")
        random_str = hashlib.md5(str(datetime.now().timestamp()).encode()).hexdigest()[:6]

        # í•´ë‹¹ source_documentì˜ ê¸°ì¡´ ê°€ì´ë“œ ê°œìˆ˜ í™•ì¸
        grouped = load_all_guides()
        existing_guides = grouped.get(guide_data.source_document, [])
        guide_index = len(existing_guides)

        authority_code = "UNK"
        if "ê°œì¸ì •ë³´ë³´í˜¸ìœ„ì›íšŒ" in guide_data.source_authority:
            authority_code = "PIPC"
        elif "ê¸ˆìœµë³´ì•ˆì›" in guide_data.source_authority:
            authority_code = "FSI"

        guide_id = f"GUIDE-{authority_code}-{timestamp}-{random_str}-{guide_index:03d}"

        # ìƒˆ ê°€ì´ë“œ ìƒì„±
        new_guide = {
            "guide_id": guide_id,
            **guide_data.model_dump()
        }

        # JSONL íŒŒì¼ëª… ê²°ì • (source_document ê¸°ë°˜)
        safe_filename = guide_data.source_document.replace(" ", "_").replace("/", "_")[:50]
        jsonl_filename = f"application_guides_{datetime.now().strftime('%Y%m%d_%H%M%S')}_{safe_filename}.jsonl"

        # ê¸°ì¡´ íŒŒì¼ì— ì¶”ê°€ ë˜ëŠ” ìƒˆ íŒŒì¼ ìƒì„±
        target_file = None
        if existing_guides:
            # ê¸°ì¡´ íŒŒì¼ ì¤‘ í•˜ë‚˜ ì„ íƒ
            target_file = existing_guides[0].get("_jsonl_file")

        if not target_file:
            target_file = jsonl_filename

        # íŒŒì¼ì—ì„œ ê¸°ì¡´ ê°€ì´ë“œ ë¡œë“œ
        all_guides = load_guides_from_file(target_file) if target_file else []
        all_guides.append(new_guide)

        # íŒŒì¼ ì €ì¥
        if not save_guides_to_file(target_file, all_guides):
            raise HTTPException(status_code=500, detail="íŒŒì¼ ì €ì¥ ì‹¤íŒ¨")

        return JSONResponse({
            "success": True,
            "message": "ê°€ì´ë“œê°€ ì„±ê³µì ìœ¼ë¡œ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤",
            "data": {
                "guide_id": guide_id,
                "jsonl_file": target_file
            }
        })

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ê°€ì´ë“œ ìƒì„± ì‹¤íŒ¨: {str(e)}")


@router.put("/guides/{guide_id}")
async def update_guide(guide_id: str, guide_data: PolicyGuideUpdate):
    """ê°€ì´ë“œ ì—…ë°ì´íŠ¸"""
    try:
        grouped = load_all_guides()

        target_file = None
        updated_guide = None

        # ê°€ì´ë“œ ì°¾ê¸°
        for source_doc, guides in grouped.items():
            for guide in guides:
                if guide.get("guide_id") == guide_id:
                    target_file = guide.get("_jsonl_file")
                    break
            if target_file:
                break

        if not target_file:
            raise HTTPException(status_code=404, detail="ê°€ì´ë“œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")

        # íŒŒì¼ì—ì„œ ëª¨ë“  ê°€ì´ë“œ ë¡œë“œ
        all_guides = load_guides_from_file(target_file)

        # ì—…ë°ì´íŠ¸ëœ ê°€ì´ë“œ ì°¾ì•„ì„œ ìˆ˜ì •
        for i, g in enumerate(all_guides):
            if g.get("guide_id") == guide_id:
                update_dict = guide_data.model_dump(exclude_unset=True)
                all_guides[i].update(update_dict)
                updated_guide = all_guides[i]
                break

        # íŒŒì¼ ì €ì¥
        if not save_guides_to_file(target_file, all_guides):
            raise HTTPException(status_code=500, detail="íŒŒì¼ ì €ì¥ ì‹¤íŒ¨")

        return JSONResponse({
            "success": True,
            "message": "ê°€ì´ë“œê°€ ì„±ê³µì ìœ¼ë¡œ ì—…ë°ì´íŠ¸ë˜ì—ˆìŠµë‹ˆë‹¤",
            "data": updated_guide
        })

    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ê°€ì´ë“œ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {str(e)}")


@router.delete("/guides/{guide_id}")
async def delete_guide(guide_id: str):
    """ê°€ì´ë“œ ì‚­ì œ"""
    try:
        grouped = load_all_guides()

        target_file = None

        # ê°€ì´ë“œ ì°¾ê¸°
        for source_doc, guides in grouped.items():
            for guide in guides:
                if guide.get("guide_id") == guide_id:
                    target_file = guide.get("_jsonl_file")
                    break
            if target_file:
                break

        if not target_file:
            raise HTTPException(status_code=404, detail="ê°€ì´ë“œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")

        # íŒŒì¼ì—ì„œ ê°€ì´ë“œ ì œê±°
        all_guides = load_guides_from_file(target_file)
        all_guides = [g for g in all_guides if g.get("guide_id") != guide_id]

        # íŒŒì¼ ì €ì¥
        if not save_guides_to_file(target_file, all_guides):
            raise HTTPException(status_code=500, detail="íŒŒì¼ ì €ì¥ ì‹¤íŒ¨")

        return JSONResponse({
            "success": True,
            "message": "ê°€ì´ë“œê°€ ì„±ê³µì ìœ¼ë¡œ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤"
        })

    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ê°€ì´ë“œ ì‚­ì œ ì‹¤íŒ¨: {str(e)}")


@router.get("/stats")
async def get_vectordb_stats():
    """VectorDB í†µê³„"""
    try:
        grouped = load_all_guides()

        total_guides = sum(len(guides) for guides in grouped.values())
        authorities = set()
        jsonl_files = set()

        for guides in grouped.values():
            for guide in guides:
                authorities.add(guide.get("source_authority", ""))
                jsonl_files.add(guide.get("_jsonl_file", ""))

        # OpenAI Vector Store ì •ë³´ í™•ì¸
        vector_store_status = "unknown"
        vector_store_file_count = 0
        try:
            vs = openai_client.vector_stores.retrieve(VECTOR_STORE_ID)
            vector_store_status = vs.status if hasattr(vs, 'status') else "active"
            vector_store_file_count = vs.file_counts.total if hasattr(vs, 'file_counts') else 0
        except Exception as e:
            print(f"Vector Store ì¡°íšŒ ì‹¤íŒ¨: {e}")
            vector_store_status = "error"

        return JSONResponse({
            "success": True,
            "data": {
                "total_guides": total_guides,
                "total_source_documents": len(grouped),
                "total_jsonl_files": len(jsonl_files),
                "authorities": list(authorities),
                "vector_store_id": VECTOR_STORE_ID,
                "vector_store_status": vector_store_status,
                "vector_store_file_count": vector_store_file_count,
                "sync_status": "openai_vector_store"
            }
        })

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"í†µê³„ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")


# ===== RAG ë¶„ì„ ì—”ë“œí¬ì¸íŠ¸ =====

class RAGAnalysisRequest(BaseModel):
    email_body: str
    email_subject: str
    context: Dict[str, Any]
    detected_pii: List[Dict[str, str]]
    query: str


@router.post("/analyze")
async def analyze_email_with_rag(
    request: RAGAnalysisRequest,
    http_request: Request,
    current_user: dict = Depends(get_current_user)
):
    """
    OpenAI Vector Store ê¸°ë°˜ ì´ë©”ì¼ ë¶„ì„ ë° ë§ˆìŠ¤í‚¹ ê²°ì •
    """
    try:
        # OpenAI Vector Storeì—ì„œ ê´€ë ¨ ê°€ì´ë“œë¼ì¸ ê²€ìƒ‰
        search_query = f"{request.context.get('receiver_type', 'external')} ì „ì†¡ ê°œì¸ì •ë³´ ë§ˆìŠ¤í‚¹"

        print(f"ğŸ“ OpenAI Vector Store ê²€ìƒ‰: {search_query}")

        relevant_guides = await search_with_assistant(search_query, request.context)

        if not relevant_guides:
            print("âš ï¸ Vector Store ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ, fallback ì‚¬ìš©")
            return fallback_analysis(request)

        print(f"âœ… {len(relevant_guides)}ê°œ ê°€ì´ë“œë¼ì¸ ê²€ìƒ‰ë¨")

        # LLMìœ¼ë¡œ ë§ˆìŠ¤í‚¹ ê²°ì •
        masking_decisions = await decide_masking_with_llm(
            request.email_body,
            request.detected_pii,
            request.context,
            relevant_guides
        )

        # AI ìš”ì•½ ìƒì„±
        summary = generate_summary(request.context, masking_decisions, relevant_guides)

        # ì‹¤ì œ ì¸ìš©ëœ ê°€ì´ë“œë¼ì¸ë§Œ ì¶”ì¶œ
        cited_guide_texts = set()
        for decision in masking_decisions.values():
            if decision.get('cited_guidelines'):
                cited_guide_texts.update(decision['cited_guidelines'])

        # ë§ˆìŠ¤í‚¹ëœ PII ê°œìˆ˜ ê³„ì‚°
        masked_count = sum(1 for d in masking_decisions.values() if d.get('should_mask', False))

        # ê°ì‚¬ ë¡œê·¸ ê¸°ë¡
        await AuditLogger.log_masking_decision(
            user_email=current_user["email"],
            user_role=current_user.get("role", "user"),
            pii_count=len(request.detected_pii),
            masked_count=masked_count,
            receiver_type=request.context.get('receiver_type', 'unknown'),
            cited_guidelines=list(cited_guide_texts),
            request=http_request,
        )

        return JSONResponse({
            "success": True,
            "data": {
                "masking_decisions": masking_decisions,
                "summary": summary,
                "relevant_guides": relevant_guides[:5],  # ìƒìœ„ 5ê°œ í‘œì‹œ
                "cited_guidelines": list(cited_guide_texts),  # ì‹¤ì œ ì¸ìš©ëœ ê·œì • ëª©ë¡
                "total_guides_found": len(relevant_guides),
                "total_cited": len(cited_guide_texts),
                "vector_store_id": VECTOR_STORE_ID
            }
        })

    except Exception as e:
        print(f"RAG ë¶„ì„ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
        return fallback_analysis(request)


async def decide_masking_with_llm(
    email_body: str,
    detected_pii: List[Dict[str, str]],
    context: Dict[str, Any],
    guides: List[Dict[str, Any]],
) -> Dict[str, Any]:
    """
    ê°€ì´ë“œë¼ì¸ ê¸°ë°˜ ë§ˆìŠ¤í‚¹ ê²°ì • (ê·œì¹™ ì—”ì§„)
    """
    decisions = {}
    receiver_type = context.get('receiver_type', 'unknown')

    # ê°€ì´ë“œë¼ì¸ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ (ìƒìœ„ 5ê°œ ì‚¬ìš©)
    guideline_keywords = set()
    guideline_texts = []
    guideline_sources = []  # ì¶œì²˜ ì •ë³´ ì €ì¥

    for guide in guides[:5]:  # 3ê°œ -> 5ê°œë¡œ ì¦ê°€
        content = guide.get('content', '')
        filename = guide.get('filename', 'ì •ì±… ë¬¸ì„œ')

        # íŒŒì¼ëª…ì—ì„œ ì •ì±…ëª… ì¶”ì¶œ
        policy_name = filename.replace('.pdf', '').replace('.jsonl', '')
        guideline_texts.append(content[:300])  # 200 -> 300ìë¡œ ì¦ê°€
        guideline_sources.append(policy_name)

        if 'ë§ˆìŠ¤í‚¹' in content or 'mask' in content.lower():
            guideline_keywords.add('mask_required')
        if 'ì™¸ë¶€' in content or 'external' in content.lower():
            guideline_keywords.add('external_sensitive')
        if 'ë‚´ë¶€' in content or 'internal' in content.lower():
            guideline_keywords.add('internal_allowed')
        if 'ì œ3ì' in content or 'ì œê³µ' in content:
            guideline_keywords.add('third_party')
        if 'ê³ ìœ ì‹ë³„' in content:
            guideline_keywords.add('unique_identifier')

    for i, pii in enumerate(detected_pii):
        pii_type = pii.get('type', '')
        should_mask = False
        reason = ""
        masking_method = "none"
        reasoning_steps = []
        cited_guidelines = []

        print(f"[DEBUG] PII #{i}: type={pii_type}, receiver={receiver_type}, keywords={guideline_keywords}")

        # PII ìœ í˜• í•œê¸€ëª…
        pii_type_kr = {
            'email': 'ì´ë©”ì¼ ì£¼ì†Œ',
            'phone': 'ì „í™”ë²ˆí˜¸',
            'jumin': 'ì£¼ë¯¼ë“±ë¡ë²ˆí˜¸',
            'account': 'ê³„ì¢Œë²ˆí˜¸',
            'passport': 'ì—¬ê¶Œë²ˆí˜¸',
            'driver_license': 'ìš´ì „ë©´í—ˆë²ˆí˜¸'
        }.get(pii_type, pii_type)

        # Step 1: ì»¨í…ìŠ¤íŠ¸ ë¶„ì„
        reasoning_steps.append(f"1. ì»¨í…ìŠ¤íŠ¸ í™•ì¸: {receiver_type} ì „ì†¡")
        reasoning_steps.append(f"2. PII ìœ í˜•: {pii_type_kr}")

        # Step 3: ê°€ì´ë“œë¼ì¸ ê²€í† 
        if guideline_texts:
            reasoning_steps.append(f"3. OpenAI Vector Storeì—ì„œ {len(guideline_texts)}ê°œ ê°€ì´ë“œë¼ì¸ ê²€í† :")
            for idx, (text, source) in enumerate(zip(guideline_texts[:3], guideline_sources[:3]), 1):
                reasoning_steps.append(f"   - [{source}]: {text[:80]}...")
                # ì‹¤ì œ ì •ì±…ëª…ì„ ì¸ìš© ëª©ë¡ì— ì¶”ê°€
                cited_guidelines.append(f"{source}")

        # ê·œì¹™ 1: ì™¸ë¶€ ì „ì†¡ì´ë©´ ëŒ€ë¶€ë¶„ ë§ˆìŠ¤í‚¹
        if receiver_type == 'external':
            should_mask = True
            reasoning_steps.append("4. íŒë‹¨ ê·¼ê±°:")

            if pii_type in ['jumin', 'account']:
                masking_method = "full"
                reasoning_steps.append(f"   - ê°œì¸ì •ë³´ë³´í˜¸ë²• ì œ24ì¡°: ê³ ìœ ì‹ë³„ì •ë³´({pii_type_kr})ëŠ” ì™¸ë¶€ ì „ì†¡ ì‹œ í•„ìˆ˜ ë§ˆìŠ¤í‚¹")
                reason = "ê³ ìœ ì‹ë³„ì •ë³´ ì™¸ë¶€ ì „ì†¡ ê¸ˆì§€ (ê°œì¸ì •ë³´ë³´í˜¸ë²• ì œ24ì¡°)"
                cited_guidelines.append("ê°œì¸ì •ë³´ë³´í˜¸ë²• ì œ24ì¡° (ê³ ìœ ì‹ë³„ì •ë³´ ì²˜ë¦¬ ì œí•œ)")
            elif pii_type == 'email':
                masking_method = "partial"
                reasoning_steps.append(f"   - ê°œì¸ì •ë³´ë³´í˜¸ë²• ì œ17ì¡°: ê°œì¸ì •ë³´ ì œ3ì ì œê³µ ì‹œ ìµœì†Œí™”")
                reason = "ê°œì¸ì •ë³´ ìµœì†Œí™” ì›ì¹™ (ê°œì¸ì •ë³´ë³´í˜¸ë²• ì œ17ì¡°)"
                cited_guidelines.append("ê°œì¸ì •ë³´ë³´í˜¸ë²• ì œ17ì¡° (ê°œì¸ì •ë³´ ì œ3ì ì œê³µ)")
            else:
                masking_method = "partial"
                reasoning_steps.append(f"   - ê°œì¸ì •ë³´ë³´í˜¸ë²• ì œ17ì¡°: ì™¸ë¶€ ì „ì†¡ ì‹œ {pii_type_kr} ìµœì†Œí™” í•„ìš”")

                # Vector Storeì—ì„œ ê´€ë ¨ ê°€ì´ë“œë¼ì¸ ì°¾ê¸°
                for idx, (text, source) in enumerate(zip(guideline_texts, guideline_sources)):
                    if pii_type in text.lower() or pii_type_kr in text:
                        reasoning_steps.append(f"   - [{source}]: ê´€ë ¨ ê·œì • í™•ì¸")
                        cited_guidelines.append(f"{source}")
                        break

                if not any('ì œ17ì¡°' in g for g in cited_guidelines):
                    cited_guidelines.append("ê°œì¸ì •ë³´ë³´í˜¸ë²• ì œ17ì¡° (ê°œì¸ì •ë³´ ì œ3ì ì œê³µ)")

                reason = f"ì™¸ë¶€ ì „ì†¡ ì‹œ {pii_type_kr} ë§ˆìŠ¤í‚¹ í•„ìˆ˜"

            reasoning_steps.append(f"5. ìµœì¢… ê²°ì •: {masking_method.upper()} ë§ˆìŠ¤í‚¹ ì ìš©")

        elif pii_type in ['jumin', 'account']:
            should_mask = True
            masking_method = "full"
            reasoning_steps.append("4. íŒë‹¨ ê·¼ê±°:")
            reasoning_steps.append(f"   - ê°œì¸ì •ë³´ë³´í˜¸ë²• ì œ24ì¡°: ê³ ìœ ì‹ë³„ì •ë³´ëŠ” ë‚´ë¶€ ì „ì†¡ì´ë¼ë„ ìµœì†Œ ì²˜ë¦¬")
            reasoning_steps.append(f"5. ìµœì¢… ê²°ì •: FULL ë§ˆìŠ¤í‚¹ ì ìš©")
            reason = "ê³ ìœ ì‹ë³„ì •ë³´ëŠ” ë‚´ë¶€ ì „ì†¡ì—ë„ ìµœì†Œ ì²˜ë¦¬ (ê°œì¸ì •ë³´ë³´í˜¸ë²• ì œ24ì¡°)"
            cited_guidelines.append("ê°œì¸ì •ë³´ë³´í˜¸ë²• ì œ24ì¡° (ê³ ìœ ì‹ë³„ì •ë³´ ì²˜ë¦¬ ì œí•œ)")

        elif 'mask_required' in guideline_keywords:
            should_mask = True
            masking_method = "partial"
            reasoning_steps.append("4. íŒë‹¨ ê·¼ê±°:")

            # ë§ˆìŠ¤í‚¹ì„ ìš”êµ¬í•˜ëŠ” ê°€ì´ë“œë¼ì¸ ì°¾ê¸°
            for idx, (text, source) in enumerate(zip(guideline_texts, guideline_sources)):
                if 'ë§ˆìŠ¤í‚¹' in text or 'mask' in text.lower():
                    reasoning_steps.append(f"   - [{source}]: {pii_type_kr} ë§ˆìŠ¤í‚¹ ê¶Œì¥")
                    cited_guidelines.append(f"{source}")
                    break

            if not cited_guidelines:
                # í‚¤ì›Œë“œë§Œ ìˆê³  êµ¬ì²´ì  ì¶œì²˜ê°€ ì—†ìœ¼ë©´ ê¸°ë³¸ ê·œì • ì ìš©
                reasoning_steps.append(f"   - ê°œì¸ì •ë³´ë³´í˜¸ë²• ì œ29ì¡°: ì•ˆì „ì¡°ì¹˜ ì˜ë¬´")
                cited_guidelines.append("ê°œì¸ì •ë³´ë³´í˜¸ë²• ì œ29ì¡° (ì•ˆì „ì¡°ì¹˜ ì˜ë¬´)")

            reasoning_steps.append(f"5. ìµœì¢… ê²°ì •: PARTIAL ë§ˆìŠ¤í‚¹ ì ìš©")
            reason = f"ì •ì±… ê°€ì´ë“œë¼ì¸ì— ë”°ë¼ {pii_type_kr} ë§ˆìŠ¤í‚¹ í•„ìš”"

        else:
            should_mask = False
            masking_method = "none"
            reasoning_steps.append("4. íŒë‹¨ ê·¼ê±°:")
            reasoning_steps.append(f"   - ë‚´ë¶€ ì „ì†¡ì´ë©° ë¯¼ê°ì •ë³´ê°€ ì•„ë‹˜")
            reasoning_steps.append(f"5. ìµœì¢… ê²°ì •: ë§ˆìŠ¤í‚¹ ë¯¸ì ìš©")
            reason = "ë‚´ë¶€ ì „ì†¡ìœ¼ë¡œ ë§ˆìŠ¤í‚¹ ë¶ˆí•„ìš”"

        # ë§ˆìŠ¤í‚¹ ë¯¸ë¦¬ë³´ê¸° ìƒì„±
        masked_value = None
        if should_mask:
            masked_value = _generate_masked_preview(pii.get('value', ''), pii_type, masking_method)

        reasoning_text = "\n".join(reasoning_steps)

        decisions[f"pii_{i}"] = {
            "pii_id": f"pii_{i}",
            "type": pii_type,
            "value": pii['value'],
            "should_mask": should_mask,
            "masking_method": masking_method,
            "masked_value": masked_value,
            "reason": reason,
            "reasoning": reasoning_text,
            "cited_guidelines": cited_guidelines,
            "guideline_matched": len(guideline_keywords) > 0,
            "confidence": 0.85,
            "risk_level": "high" if pii_type in ['jumin', 'account'] else "medium" if should_mask else "low"
        }

    return decisions


def _generate_masked_preview(value: str, pii_type: str, method: str) -> str:
    """ë§ˆìŠ¤í‚¹ ë¯¸ë¦¬ë³´ê¸° ìƒì„±"""
    if method == "full":
        return "***"
    elif method == "partial":
        if pii_type == "email":
            parts = value.split("@")
            if len(parts) == 2:
                return parts[0][:2] + "***@" + parts[1]
        elif pii_type == "phone":
            if "-" in value:
                return value[:3] + "-***-" + value[-4:]
            else:
                return value[:3] + "***" + value[-4:]
        elif pii_type == "jumin":
            return value[:6] + "-*******"
        elif pii_type == "account":
            parts = value.split("-")
            if len(parts) == 3:
                return parts[0] + "-***-" + parts[2]
        return value[:3] + "***"
    elif method == "redact":
        return "[REDACTED]"
    elif method == "hash":
        return "[HASHED]"
    else:
        return value


def generate_summary(context: Dict, decisions: Dict, guides: List[Dict]) -> str:
    """AI ë¶„ì„ ìš”ì•½ ìƒì„±"""

    masked_count = sum(1 for d in decisions.values() if d.get('should_mask', False))
    total_count = len(decisions)

    receiver_type = context.get('receiver_type', 'unknown')
    receiver_text = "ì™¸ë¶€" if receiver_type == "external" else "ë‚´ë¶€"

    summary = f"{receiver_text} ì „ì†¡ìœ¼ë¡œ ë¶„ë¥˜ë˜ì–´, "

    if masked_count > 0:
        summary += f"{total_count}ê°œ ê°œì¸ì •ë³´ ì¤‘ {masked_count}ê°œë¥¼ ë§ˆìŠ¤í‚¹í•˜ë„ë¡ ê¶Œì¥í•©ë‹ˆë‹¤. "
    else:
        summary += "ë§ˆìŠ¤í‚¹ì´ í•„ìš”í•œ ê°œì¸ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤. "

    if guides:
        summary += f"\n\nOpenAI Vector Storeì—ì„œ ê´€ë ¨ ê·œì • {len(guides)}ê°œë¥¼ ì°¸ê³ í–ˆìŠµë‹ˆë‹¤."

    return summary


def fallback_analysis(request: RAGAnalysisRequest) -> JSONResponse:
    """Vector Store ì‚¬ìš© ë¶ˆê°€ ì‹œ ê¸°ë³¸ ê·œì¹™ ê¸°ë°˜ ë¶„ì„"""

    decisions = {}
    context = request.context
    receiver_type = context.get('receiver_type', 'external')

    for i, pii in enumerate(request.detected_pii):
        pii_type = pii['type']
        pii_value = pii['value']
        masking_method = "none"
        reasoning_steps = []
        cited_guidelines = []

        pii_type_kr = {
            'email': 'ì´ë©”ì¼ ì£¼ì†Œ',
            'phone': 'ì „í™”ë²ˆí˜¸',
            'jumin': 'ì£¼ë¯¼ë“±ë¡ë²ˆí˜¸',
            'account': 'ê³„ì¢Œë²ˆí˜¸',
            'passport': 'ì—¬ê¶Œë²ˆí˜¸',
            'driver_license': 'ìš´ì „ë©´í—ˆë²ˆí˜¸'
        }.get(pii_type, pii_type)

        reasoning_steps.append(f"1. ì»¨í…ìŠ¤íŠ¸ í™•ì¸: {receiver_type} ì „ì†¡")
        reasoning_steps.append(f"2. PII ìœ í˜•: {pii_type_kr}")
        reasoning_steps.append("3. Vector Store ì‚¬ìš© ë¶ˆê°€ â†’ ê¸°ë³¸ ê·œì¹™ ì ìš©")

        if receiver_type == 'external':
            should_mask = True
            reasoning_steps.append("4. íŒë‹¨ ê·¼ê±°:")

            if pii_type in ['jumin', 'account']:
                masking_method = "full"
                reasoning_steps.append(f"   - ê°œì¸ì •ë³´ë³´í˜¸ë²• ì œ24ì¡°: ê³ ìœ ì‹ë³„ì •ë³´ëŠ” ì™¸ë¶€ ì „ì†¡ ì‹œ ì›ì¹™ì  ê¸ˆì§€")
                reason = "ê³ ìœ ì‹ë³„ì •ë³´ ì™¸ë¶€ ì „ì†¡ ê¸ˆì§€ (ê°œì¸ì •ë³´ë³´í˜¸ë²• ì œ24ì¡°)"
                cited_guidelines.append("ê°œì¸ì •ë³´ë³´í˜¸ë²• ì œ24ì¡° (ê³ ìœ ì‹ë³„ì •ë³´ ì²˜ë¦¬ ì œí•œ)")
            else:
                masking_method = "partial"
                reasoning_steps.append(f"   - ê°œì¸ì •ë³´ë³´í˜¸ë²• ì œ17ì¡°: ì œ3ì ì œê³µ ì‹œ ìµœì†Œí™”")
                reason = "ê°œì¸ì •ë³´ ìµœì†Œí™” ì›ì¹™ (ê°œì¸ì •ë³´ë³´í˜¸ë²• ì œ17ì¡°)"
                cited_guidelines.append("ê°œì¸ì •ë³´ë³´í˜¸ë²• ì œ17ì¡° (ê°œì¸ì •ë³´ ì œ3ì ì œê³µ)")

            reasoning_steps.append(f"5. ìµœì¢… ê²°ì •: {masking_method.upper()} ë§ˆìŠ¤í‚¹ ì ìš©")
        else:
            if pii_type in ['jumin', 'account']:
                should_mask = True
                masking_method = "full"
                reasoning_steps.append("4. íŒë‹¨ ê·¼ê±°:")
                reasoning_steps.append(f"   - ë‚´ë¶€ ì „ì†¡ì´ë‚˜ ê³ ìœ ì‹ë³„ì •ë³´ëŠ” ìµœì†Œ ì²˜ë¦¬")
                reasoning_steps.append(f"5. ìµœì¢… ê²°ì •: FULL ë§ˆìŠ¤í‚¹ ì ìš©")
                reason = "ë¯¼ê°ì •ë³´ ìµœì†Œ ì²˜ë¦¬ (ê°œì¸ì •ë³´ë³´í˜¸ë²• ì œ24ì¡°)"
                cited_guidelines.append("ê°œì¸ì •ë³´ë³´í˜¸ë²• ì œ24ì¡° (ê³ ìœ ì‹ë³„ì •ë³´ ìµœì†Œ ì²˜ë¦¬)")
            else:
                should_mask = False
                masking_method = "none"
                reasoning_steps.append("4. íŒë‹¨ ê·¼ê±°:")
                reasoning_steps.append(f"   - ë‚´ë¶€ ì „ì†¡ì´ë©° ì¼ë°˜ ê°œì¸ì •ë³´")
                reasoning_steps.append(f"5. ìµœì¢… ê²°ì •: ë§ˆìŠ¤í‚¹ ë¯¸ì ìš©")
                reason = "ë‚´ë¶€ ì „ì†¡ìœ¼ë¡œ ë§ˆìŠ¤í‚¹ ë¶ˆí•„ìš”"

        masked_value = None
        if should_mask:
            masked_value = _generate_masked_preview(pii_value, pii_type, masking_method)

        reasoning_text = "\n".join(reasoning_steps)

        decisions[f"pii_{i}"] = {
            "pii_id": f"pii_{i}",
            "type": pii_type,
            "value": pii_value,
            "should_mask": should_mask,
            "masking_method": masking_method,
            "masked_value": masked_value,
            "reason": reason,
            "reasoning": reasoning_text,
            "cited_guidelines": cited_guidelines,
            "confidence": 0.8,
            "risk_level": "high" if pii_type in ['jumin', 'account'] else "medium" if should_mask else "low"
        }

    masked_count = sum(1 for d in decisions.values() if d['should_mask'])

    summary = f"ê¸°ë³¸ ê·œì¹™ì— ë”°ë¼ {len(decisions)}ê°œ ê°œì¸ì •ë³´ ì¤‘ {masked_count}ê°œ ë§ˆìŠ¤í‚¹ì„ ê¶Œì¥í•©ë‹ˆë‹¤."

    return JSONResponse({
        "success": True,
        "data": {
            "masking_decisions": decisions,
            "summary": summary,
            "relevant_guides": [],
            "total_guides_found": 0,
            "fallback": True
        }
    })
