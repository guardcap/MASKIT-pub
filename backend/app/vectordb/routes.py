"""
VectorDB ë° ì •ì±… ìŠ¤í‚¤ë§ˆ ê´€ë¦¬ ë¼ìš°í„°
- JSONL íŒŒì¼ ê´€ë¦¬ (CRUD)
- VectorDB ë™ê¸°í™”
- source_document ê¸°ë°˜ ê·¸ë£¹í™”
"""

from fastapi import APIRouter, HTTPException, Depends
from fastapi.responses import JSONResponse
from typing import List, Optional, Dict, Any
from pathlib import Path
from datetime import datetime
import json
import chromadb
from chromadb.config import Settings
from openai import OpenAI
import os
from dotenv import load_dotenv
import hashlib
from pydantic import BaseModel

load_dotenv()

router = APIRouter(prefix="/api/vectordb", tags=["VectorDB Management"])

# ê²½ë¡œ ì„¤ì • - ì ˆëŒ€ ê²½ë¡œë¡œ ë³€í™˜
BASE_DIR = Path(__file__).resolve().parent.parent.parent.parent
STAGING_DIR = BASE_DIR / "app" / "rag" / "data" / "staging"
CHROMADB_PATH = BASE_DIR / "app" / "rag" / "data" / "chromadb" / "application_guides"
COLLECTION_NAME = "application_guides"

# ë””ë ‰í† ë¦¬ ìƒì„±
STAGING_DIR.mkdir(parents=True, exist_ok=True)
CHROMADB_PATH.mkdir(parents=True, exist_ok=True)

# OpenAI í´ë¼ì´ì–¸íŠ¸
openai_client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
EMBEDDING_MODEL = os.getenv("OPENAI_EMBEDDING_MODEL", "text-embedding-3-small")

# ChromaDB í´ë¼ì´ì–¸íŠ¸
chroma_client = chromadb.PersistentClient(path=str(CHROMADB_PATH))


# Pydantic ëª¨ë¸
class PolicyGuide(BaseModel):
    guide_id: str
    source_authority: str
    source_document: str
    scenario: str
    context: Dict[str, Any]
    interpretation: str
    actionable_directive: str
    keywords: List[str]
    related_law_ids: List[str]
    examples: List[Dict[str, Any]]
    confidence_score: float
    reviewed: bool


class PolicyGuideCreate(BaseModel):
    source_authority: str
    source_document: str
    scenario: str
    context: Dict[str, Any]
    interpretation: str
    actionable_directive: str
    keywords: List[str]
    related_law_ids: List[str]
    examples: List[Dict[str, Any]]
    confidence_score: Optional[float] = 0.8
    reviewed: Optional[bool] = False


class PolicyGuideUpdate(BaseModel):
    source_authority: Optional[str] = None
    scenario: Optional[str] = None
    context: Optional[Dict[str, Any]] = None
    interpretation: Optional[str] = None
    actionable_directive: Optional[str] = None
    keywords: Optional[List[str]] = None
    related_law_ids: Optional[List[str]] = None
    examples: Optional[List[Dict[str, Any]]] = None
    confidence_score: Optional[float] = None
    reviewed: Optional[bool] = None


def get_embedding(text: str) -> List[float]:
    """OpenAI Embedding ìƒì„±"""
    try:
        response = openai_client.embeddings.create(
            model=EMBEDDING_MODEL,
            input=text
        )
        return response.data[0].embedding
    except Exception as e:
        print(f"Embedding ìƒì„± ì‹¤íŒ¨: {e}")
        return None


def build_search_text(guide: Dict) -> str:
    """ê²€ìƒ‰ìš© í…ìŠ¤íŠ¸ êµ¬ì„±"""
    parts = [
        f"Scenario: {guide.get('scenario', '')}",
        f"Directive: {guide.get('actionable_directive', '')}",
        f"Interpretation: {guide.get('interpretation', '')}",
        f"Keywords: {', '.join(guide.get('keywords', []))}",
    ]

    for example in guide.get('examples', []):
        parts.append(f"Example: {example.get('case_description', '')}")

    return "\n".join(parts)


def load_all_guides() -> Dict[str, List[Dict]]:
    """
    ëª¨ë“  JSONL íŒŒì¼ì„ ë¡œë“œí•˜ê³  source_documentë¡œ ê·¸ë£¹í™”
    Returns: {source_document: [guides...]}
    """
    if not STAGING_DIR.exists():
        return {}

    grouped_guides = {}
    jsonl_files = list(STAGING_DIR.glob("*.jsonl"))

    for jsonl_file in jsonl_files:
        try:
            with open(jsonl_file, "r", encoding="utf-8") as f:
                for line in f:
                    if line.strip():
                        guide = json.loads(line)
                        source_doc = guide.get("source_document", "Unknown")

                        if source_doc not in grouped_guides:
                            grouped_guides[source_doc] = []

                        guide["_jsonl_file"] = jsonl_file.name
                        grouped_guides[source_doc].append(guide)
        except Exception as e:
            print(f"íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨ {jsonl_file.name}: {e}")

    return grouped_guides


def load_guides_from_file(filename: str) -> List[Dict]:
    """íŠ¹ì • JSONL íŒŒì¼ì—ì„œ ê°€ì´ë“œ ë¡œë“œ"""
    file_path = STAGING_DIR / filename
    if not file_path.exists():
        return []

    guides = []
    with open(file_path, "r", encoding="utf-8") as f:
        for line in f:
            if line.strip():
                guides.append(json.loads(line))

    return guides


def save_guides_to_file(filename: str, guides: List[Dict]) -> bool:
    """ê°€ì´ë“œë¥¼ JSONL íŒŒì¼ì— ì €ì¥"""
    try:
        file_path = STAGING_DIR / filename
        with open(file_path, "w", encoding="utf-8") as f:
            for guide in guides:
                # _jsonl_file í•„ë“œ ì œê±°
                guide_copy = guide.copy()
                guide_copy.pop("_jsonl_file", None)
                f.write(json.dumps(guide_copy, ensure_ascii=False) + "\n")
        return True
    except Exception as e:
        print(f"íŒŒì¼ ì €ì¥ ì‹¤íŒ¨: {e}")
        return False


def sync_to_vectordb(guide: Dict, operation: str = "upsert") -> bool:
    """
    VectorDBì— ê°€ì´ë“œ ë™ê¸°í™”
    operation: "upsert", "delete"
    """
    try:
        collection = chroma_client.get_or_create_collection(
            name=COLLECTION_NAME,
            metadata={"hnsw:space": "cosine"}
        )

        guide_id = guide.get("guide_id")

        if operation == "delete":
            collection.delete(ids=[guide_id])
            return True

        # Upsert
        search_text = build_search_text(guide)
        embedding = get_embedding(search_text)

        if not embedding:
            return False

        context = guide.get("context", {}) or {}
        metadata = {
            "guide_id": guide_id,
            "authority": guide.get("source_authority", ""),
            "source_document": guide.get("source_document", ""),
            "scenario": guide.get("scenario", "")[:500],
            "sender_type": context.get("sender_type", ""),
            "receiver_type": context.get("receiver_type", ""),
            "email_purpose": context.get("email_purpose", ""),
            "pii_types": ",".join(context.get("pii_types", [])),
            "confidence_score": str(guide.get("confidence_score", 0.8)),
            "reviewed": str(guide.get("reviewed", False)),
        }

        collection.upsert(
            ids=[guide_id],
            documents=[search_text],
            embeddings=[embedding],
            metadatas=[metadata]
        )

        return True

    except Exception as e:
        print(f"VectorDB ë™ê¸°í™” ì‹¤íŒ¨: {e}")
        return False


@router.get("/guides/grouped")
async def get_guides_grouped():
    """source_documentë¡œ ê·¸ë£¹í™”ëœ ëª¨ë“  ê°€ì´ë“œ ì¡°íšŒ"""
    try:
        grouped = load_all_guides()

        # í†µê³„ ì •ë³´ ì¶”ê°€
        result = []
        for source_doc, guides in grouped.items():
            result.append({
                "source_document": source_doc,
                "count": len(guides),
                "authorities": list(set(g.get("source_authority", "") for g in guides)),
                "jsonl_files": list(set(g.get("_jsonl_file", "") for g in guides)),
                "guides": guides
            })

        # source_document ì´ë¦„ìœ¼ë¡œ ì •ë ¬
        result.sort(key=lambda x: x["source_document"])

        return JSONResponse({
            "success": True,
            "data": {
                "total_source_documents": len(result),
                "total_guides": sum(item["count"] for item in result),
                "groups": result
            }
        })

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ê°€ì´ë“œ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")


@router.get("/guides/by-source/{source_document}")
async def get_guides_by_source(source_document: str):
    """íŠ¹ì • source_documentì˜ ê°€ì´ë“œ ì¡°íšŒ"""
    try:
        grouped = load_all_guides()
        guides = grouped.get(source_document, [])

        return JSONResponse({
            "success": True,
            "data": {
                "source_document": source_document,
                "count": len(guides),
                "guides": guides
            }
        })

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ê°€ì´ë“œ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")


@router.get("/guides/{guide_id}")
async def get_guide_by_id(guide_id: str):
    """íŠ¹ì • ê°€ì´ë“œ ì¡°íšŒ"""
    try:
        grouped = load_all_guides()

        for source_doc, guides in grouped.items():
            for guide in guides:
                if guide.get("guide_id") == guide_id:
                    return JSONResponse({
                        "success": True,
                        "data": guide
                    })

        raise HTTPException(status_code=404, detail="ê°€ì´ë“œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")

    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ê°€ì´ë“œ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")


@router.post("/guides")
async def create_guide(guide_data: PolicyGuideCreate):
    """ìƒˆ ê°€ì´ë“œ ìƒì„±"""
    try:
        # guide_id ìƒì„±
        timestamp = datetime.now().strftime("%Y%m")
        random_str = hashlib.md5(str(datetime.now().timestamp()).encode()).hexdigest()[:6]

        # í•´ë‹¹ source_documentì˜ ê¸°ì¡´ ê°€ì´ë“œ ê°œìˆ˜ í™•ì¸
        grouped = load_all_guides()
        existing_guides = grouped.get(guide_data.source_document, [])
        guide_index = len(existing_guides)

        authority_code = "UNK"
        if "ê°œì¸ì •ë³´ë³´í˜¸ìœ„ì›íšŒ" in guide_data.source_authority:
            authority_code = "PIPC"
        elif "ê¸ˆìœµë³´ì•ˆì›" in guide_data.source_authority:
            authority_code = "FSI"

        guide_id = f"GUIDE-{authority_code}-{timestamp}-{random_str}-{guide_index:03d}"

        # ìƒˆ ê°€ì´ë“œ ìƒì„±
        new_guide = {
            "guide_id": guide_id,
            **guide_data.model_dump()
        }

        # JSONL íŒŒì¼ëª… ê²°ì • (source_document ê¸°ë°˜)
        safe_filename = guide_data.source_document.replace(" ", "_").replace("/", "_")[:50]
        jsonl_filename = f"application_guides_{datetime.now().strftime('%Y%m%d_%H%M%S')}_{safe_filename}.jsonl"

        # ê¸°ì¡´ íŒŒì¼ì— ì¶”ê°€ ë˜ëŠ” ìƒˆ íŒŒì¼ ìƒì„±
        target_file = None
        if existing_guides:
            # ê¸°ì¡´ íŒŒì¼ ì¤‘ í•˜ë‚˜ ì„ íƒ
            target_file = existing_guides[0].get("_jsonl_file")

        if not target_file:
            target_file = jsonl_filename

        # íŒŒì¼ì—ì„œ ê¸°ì¡´ ê°€ì´ë“œ ë¡œë“œ
        all_guides = load_guides_from_file(target_file) if target_file else []
        all_guides.append(new_guide)

        # íŒŒì¼ ì €ì¥
        if not save_guides_to_file(target_file, all_guides):
            raise HTTPException(status_code=500, detail="íŒŒì¼ ì €ì¥ ì‹¤íŒ¨")

        # VectorDB ë™ê¸°í™”
        sync_to_vectordb(new_guide, "upsert")

        return JSONResponse({
            "success": True,
            "message": "ê°€ì´ë“œê°€ ì„±ê³µì ìœ¼ë¡œ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤",
            "data": {
                "guide_id": guide_id,
                "jsonl_file": target_file
            }
        })

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ê°€ì´ë“œ ìƒì„± ì‹¤íŒ¨: {str(e)}")


@router.put("/guides/{guide_id}")
async def update_guide(guide_id: str, guide_data: PolicyGuideUpdate):
    """ê°€ì´ë“œ ì—…ë°ì´íŠ¸"""
    try:
        grouped = load_all_guides()

        target_file = None
        target_guide_index = None

        # ê°€ì´ë“œ ì°¾ê¸°
        for source_doc, guides in grouped.items():
            for idx, guide in enumerate(guides):
                if guide.get("guide_id") == guide_id:
                    target_file = guide.get("_jsonl_file")
                    target_guide_index = idx

                    # ì—…ë°ì´íŠ¸ ì ìš©
                    update_dict = guide_data.model_dump(exclude_unset=True)
                    guide.update(update_dict)

                    break
            if target_file:
                break

        if not target_file:
            raise HTTPException(status_code=404, detail="ê°€ì´ë“œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")

        # íŒŒì¼ì—ì„œ ëª¨ë“  ê°€ì´ë“œ ë¡œë“œ
        all_guides = load_guides_from_file(target_file)

        # ì—…ë°ì´íŠ¸ëœ ê°€ì´ë“œ ì°¾ì•„ì„œ ìˆ˜ì •
        for i, g in enumerate(all_guides):
            if g.get("guide_id") == guide_id:
                update_dict = guide_data.model_dump(exclude_unset=True)
                all_guides[i].update(update_dict)
                updated_guide = all_guides[i]
                break

        # íŒŒì¼ ì €ì¥
        if not save_guides_to_file(target_file, all_guides):
            raise HTTPException(status_code=500, detail="íŒŒì¼ ì €ì¥ ì‹¤íŒ¨")

        # VectorDB ë™ê¸°í™”
        sync_to_vectordb(updated_guide, "upsert")

        return JSONResponse({
            "success": True,
            "message": "ê°€ì´ë“œê°€ ì„±ê³µì ìœ¼ë¡œ ì—…ë°ì´íŠ¸ë˜ì—ˆìŠµë‹ˆë‹¤",
            "data": updated_guide
        })

    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ê°€ì´ë“œ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {str(e)}")


@router.delete("/guides/{guide_id}")
async def delete_guide(guide_id: str):
    """ê°€ì´ë“œ ì‚­ì œ"""
    try:
        grouped = load_all_guides()

        target_file = None
        deleted_guide = None

        # ê°€ì´ë“œ ì°¾ê¸°
        for source_doc, guides in grouped.items():
            for guide in guides:
                if guide.get("guide_id") == guide_id:
                    target_file = guide.get("_jsonl_file")
                    deleted_guide = guide
                    break
            if target_file:
                break

        if not target_file:
            raise HTTPException(status_code=404, detail="ê°€ì´ë“œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")

        # íŒŒì¼ì—ì„œ ê°€ì´ë“œ ì œê±°
        all_guides = load_guides_from_file(target_file)
        all_guides = [g for g in all_guides if g.get("guide_id") != guide_id]

        # íŒŒì¼ ì €ì¥
        if not save_guides_to_file(target_file, all_guides):
            raise HTTPException(status_code=500, detail="íŒŒì¼ ì €ì¥ ì‹¤íŒ¨")

        # VectorDBì—ì„œ ì‚­ì œ
        sync_to_vectordb(deleted_guide, "delete")

        return JSONResponse({
            "success": True,
            "message": "ê°€ì´ë“œê°€ ì„±ê³µì ìœ¼ë¡œ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤"
        })

    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ê°€ì´ë“œ ì‚­ì œ ì‹¤íŒ¨: {str(e)}")


@router.post("/sync/rebuild")
async def rebuild_vectordb():
    """ì „ì²´ VectorDB ì¬êµ¬ì¶•"""
    try:
        # ê¸°ì¡´ ì»¬ë ‰ì…˜ ì‚­ì œ
        try:
            chroma_client.delete_collection(name=COLLECTION_NAME)
        except:
            pass

        # ìƒˆ ì»¬ë ‰ì…˜ ìƒì„±
        collection = chroma_client.create_collection(
            name=COLLECTION_NAME,
            metadata={"hnsw:space": "cosine"}
        )

        # ëª¨ë“  ê°€ì´ë“œ ë¡œë“œ
        grouped = load_all_guides()

        total_synced = 0
        for source_doc, guides in grouped.items():
            for guide in guides:
                if sync_to_vectordb(guide, "upsert"):
                    total_synced += 1

        return JSONResponse({
            "success": True,
            "message": f"VectorDB ì¬êµ¬ì¶• ì™„ë£Œ: {total_synced}ê°œ ê°€ì´ë“œ ë™ê¸°í™”"
        })

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"VectorDB ì¬êµ¬ì¶• ì‹¤íŒ¨: {str(e)}")


@router.get("/stats")
async def get_vectordb_stats():
    """VectorDB í†µê³„"""
    try:
        grouped = load_all_guides()

        total_guides = sum(len(guides) for guides in grouped.values())
        authorities = set()
        jsonl_files = set()

        for guides in grouped.values():
            for guide in guides:
                authorities.add(guide.get("source_authority", ""))
                jsonl_files.add(guide.get("_jsonl_file", ""))

        # ChromaDB í†µê³„
        try:
            collection = chroma_client.get_collection(name=COLLECTION_NAME)
            vectordb_count = collection.count()
        except:
            vectordb_count = 0

        return JSONResponse({
            "success": True,
            "data": {
                "total_guides": total_guides,
                "total_source_documents": len(grouped),
                "total_jsonl_files": len(jsonl_files),
                "authorities": list(authorities),
                "vectordb_count": vectordb_count,
                "sync_status": "synced" if vectordb_count == total_guides else "out_of_sync"
            }
        })

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"í†µê³„ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")


# ===== RAG ë¶„ì„ ì—”ë“œí¬ì¸íŠ¸ =====

class RAGAnalysisRequest(BaseModel):
    email_body: str
    email_subject: str
    context: Dict[str, Any]
    detected_pii: List[Dict[str, str]]
    query: str


# ì„ë² ë”© ìºì‹œ (ì§§ì€ ì¿¼ë¦¬ìš©)
embedding_cache = {}

# ì‚¬ì „ ì •ì˜ëœ ì§§ì€ ì¿¼ë¦¬ í…œí”Œë¦¿
QUERY_TEMPLATES = {
    'external': "ì™¸ë¶€ ì „ì†¡ ë§ˆìŠ¤í‚¹",
    'internal': "ë‚´ë¶€ ì „ì†¡ ë§ˆìŠ¤í‚¹",
    'mixed': "ì´ë©”ì¼ ë§ˆìŠ¤í‚¹"
}


@router.post("/analyze")
async def analyze_email_with_rag(request: RAGAnalysisRequest):
    """
    RAG ê¸°ë°˜ ì´ë©”ì¼ ë¶„ì„ ë° ë§ˆìŠ¤í‚¹ ê²°ì • (ë¹ ë¥¸ ì‘ë‹µ ëª¨ë“œ)
    - ì§§ì€ ì¿¼ë¦¬ í…œí”Œë¦¿ ì‚¬ìš©ìœ¼ë¡œ ì„ë² ë”© ì†ë„ í–¥ìƒ
    - ì„ë² ë”© ìºì‹±ìœ¼ë¡œ ë°˜ë³µ í˜¸ì¶œ ìµœì í™”
    - VectorDBëŠ” ì´ë¯¸ êµ¬ì„±ë˜ì–´ ìˆìœ¼ë¯€ë¡œ ê²€ìƒ‰ë§Œ ìˆ˜í–‰
    """
    import asyncio

    try:
        # ChromaDB ì»¬ë ‰ì…˜ ê°€ì ¸ì˜¤ê¸°
        try:
            collection = chroma_client.get_collection(name=COLLECTION_NAME)
        except:
            print("âš ï¸ ChromaDB ì»¬ë ‰ì…˜ ì—†ìŒ, fallback ì‚¬ìš©")
            return fallback_analysis(request)

        # ì»¨í…ìŠ¤íŠ¸ ê¸°ë°˜ìœ¼ë¡œ ë©”íƒ€ë°ì´í„° í•„í„° ì‚¬ìš© (ì„ë² ë”© ìƒì„± ë¶ˆí•„ìš”!)
        receiver_type = request.context.get('receiver_type', 'external')

        print(f"ğŸ“ ë©”íƒ€ë°ì´í„° í•„í„° ê¸°ë°˜ ê²€ìƒ‰: receiver_type={receiver_type}")
        print("âš¡ ì„ë² ë”© ìƒì„± SKIP - ë©”íƒ€ë°ì´í„° í•„í„°ë§Œ ì‚¬ìš©í•˜ì—¬ ë¹ ë¥¸ ì‘ë‹µ")

        # VectorDB ë©”íƒ€ë°ì´í„° í•„í„° ê²€ìƒ‰ (ì„ë² ë”© ì—†ì´ ì§ì ‘ ê°€ì ¸ì˜¤ê¸°)
        try:
            # ë©”íƒ€ë°ì´í„° ì¡°ê±´ ì—†ì´ ì „ì²´ì—ì„œ ì¼ë¶€ ê°€ì ¸ì˜¤ê¸° (ê°€ì¥ ë¹ ë¦„)
            results = collection.get(limit=5)

            # get() ê²°ê³¼ë¥¼ query() í˜•ì‹ìœ¼ë¡œ ë³€í™˜
            if results and results['documents']:
                formatted_results = {
                    'documents': [results['documents']],
                    'metadatas': [results['metadatas']] if results.get('metadatas') else [[{}] * len(results['documents'])],
                    'distances': [[0.5] * len(results['documents'])]  # ë”ë¯¸ distance (ì‹¤ì œë¡  ì‚¬ìš© ì•ˆí•¨)
                }
                results = formatted_results
                print(f"âœ… VectorDBì—ì„œ {len(results['documents'][0])}ê°œ ê°€ì´ë“œë¼ì¸ ì¡°íšŒ ì™„ë£Œ")
            else:
                print("âš ï¸ VectorDBê°€ ë¹„ì–´ìˆìŒ, fallback ì‚¬ìš©")
                return fallback_analysis(request)
        except Exception as e:
            print(f"âš ï¸ VectorDB ê²€ìƒ‰ ì‹¤íŒ¨: {e}, fallback ì‚¬ìš©")
            return fallback_analysis(request)

        if not results['documents'] or len(results['documents'][0]) == 0:
            print("âš ï¸ ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ, fallback ì‚¬ìš©")
            return fallback_analysis(request)

        # ê²€ìƒ‰ëœ ê°€ì´ë“œë¼ì¸
        relevant_guides = []
        for i, doc in enumerate(results['documents'][0]):
            metadata = results['metadatas'][0][i] if results['metadatas'] else {}
            relevant_guides.append({
                'content': doc,
                'scenario': metadata.get('scenario', ''),
                'directive': metadata.get('actionable_directive', ''),
                'distance': results['distances'][0][i] if results['distances'] else 1.0
            })

        # LLMìœ¼ë¡œ ë§ˆìŠ¤í‚¹ ê²°ì •
        masking_decisions = await decide_masking_with_llm(
            request.email_body,
            request.detected_pii,
            request.context,
            relevant_guides
        )

        # AI ìš”ì•½ ìƒì„±
        summary = generate_summary(request.context, masking_decisions, relevant_guides)

        return JSONResponse({
            "success": True,
            "data": {
                "masking_decisions": masking_decisions,
                "summary": summary,
                "relevant_guides": relevant_guides[:3],  # ìƒìœ„ 3ê°œë§Œ
                "total_guides_found": len(relevant_guides)
            }
        })

    except Exception as e:
        print(f"RAG ë¶„ì„ ì˜¤ë¥˜: {e}")
        # ì˜¤ë¥˜ ì‹œ fallback
        return fallback_analysis(request)


async def decide_masking_with_llm(
    email_body: str,
    detected_pii: List[Dict[str, str]],
    context: Dict[str, Any],
    guides: List[Dict[str, Any]],
    use_llm: bool = False  # LLM ì‚¬ìš© ì—¬ë¶€ (ê¸°ë³¸ê°’: False, ê·œì¹™ ì—”ì§„ ì‚¬ìš©)
) -> Dict[str, Any]:
    """
    ê°€ì´ë“œë¼ì¸ ê¸°ë°˜ ë§ˆìŠ¤í‚¹ ê²°ì •

    Args:
        use_llm: Trueë©´ OpenAI LLM í˜¸ì¶œ, Falseë©´ ë¹ ë¥¸ ê·œì¹™ ì—”ì§„ ì‚¬ìš© (ê¸°ë³¸ê°’)
    """

    # LLM ì‚¬ìš© ëª¨ë“œ (ëŠë¦¬ì§€ë§Œ ì •í™•)
    if use_llm:
        try:
            from app.llm.masking_prompter import MaskingPrompter
            import asyncio

            # í”„ë¡¬í”„íŠ¸ ìƒì„±
            system_prompt, user_prompt = MaskingPrompter.build_prompt(
                email_subject=context.get('email_subject', ''),
                detected_pii=detected_pii,
                context=context,
                guidelines=guides
            )

            # OpenAI API í˜¸ì¶œ (íƒ€ì„ì•„ì›ƒ 5ì´ˆ)
            llm_task = asyncio.create_task(
                asyncio.to_thread(
                    lambda: openai_client.chat.completions.create(
                        model="gpt-4o-mini",
                        messages=[
                            {"role": "system", "content": system_prompt},
                            {"role": "user", "content": user_prompt}
                        ],
                        temperature=0.3,
                        max_tokens=2000,
                        response_format={"type": "json_object"}
                    )
                )
            )

            response = await asyncio.wait_for(llm_task, timeout=5.0)
            response_text = response.choices[0].message.content

            # ì‘ë‹µ íŒŒì‹±
            result = MaskingPrompter.parse_llm_response(response_text, detected_pii)
            return result["decisions"]

        except asyncio.TimeoutError:
            print("âš ï¸ LLM í˜¸ì¶œ íƒ€ì„ì•„ì›ƒ, ê·œì¹™ ì—”ì§„ìœ¼ë¡œ fallback")
        except Exception as e:
            print(f"âš ï¸ LLM í˜¸ì¶œ ì‹¤íŒ¨: {e}, ê·œì¹™ ì—”ì§„ìœ¼ë¡œ fallback")

    # ë¹ ë¥¸ ê·œì¹™ ì—”ì§„ (ê¸°ë³¸ê°’)
    decisions = {}
    receiver_type = context.get('receiver_type', 'unknown')

    # ê°€ì´ë“œë¼ì¸ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ
    guideline_keywords = set()
    for guide in guides[:3]:
        scenario = guide.get('scenario', '').lower()
        directive = guide.get('directive', '').lower()

        # ë§ˆìŠ¤í‚¹ ê´€ë ¨ í‚¤ì›Œë“œ
        if 'ë§ˆìŠ¤í‚¹' in directive or 'mask' in directive:
            guideline_keywords.add('mask_required')
        if 'ì™¸ë¶€' in scenario or 'external' in scenario:
            guideline_keywords.add('external_sensitive')
        if 'ë‚´ë¶€' in scenario or 'internal' in scenario:
            guideline_keywords.add('internal_allowed')

    for i, pii in enumerate(detected_pii):
        pii_type = pii.get('type', '')
        should_mask = False
        reason = ""
        masking_method = "none"
        reasoning_steps = []
        cited_guidelines = []

        # ê°€ì´ë“œë¼ì¸ ì¸ìš© ì •ë³´ ìˆ˜ì§‘
        relevant_guide_texts = []
        for guide in guides[:3]:
            scenario = guide.get('scenario', '')
            directive = guide.get('directive', '')
            if scenario or directive:
                relevant_guide_texts.append({
                    'scenario': scenario[:100],
                    'directive': directive[:100]
                })

        # Step 1: ì»¨í…ìŠ¤íŠ¸ ë¶„ì„
        reasoning_steps.append(f"1. ì»¨í…ìŠ¤íŠ¸ í™•ì¸: {receiver_type} ì „ì†¡")

        # Step 2: PII ìœ í˜• ë¶„ë¥˜
        pii_type_kr = {
            'email': 'ì´ë©”ì¼ ì£¼ì†Œ',
            'phone': 'ì „í™”ë²ˆí˜¸',
            'jumin': 'ì£¼ë¯¼ë“±ë¡ë²ˆí˜¸',
            'account': 'ê³„ì¢Œë²ˆí˜¸',
            'passport': 'ì—¬ê¶Œë²ˆí˜¸',
            'driver_license': 'ìš´ì „ë©´í—ˆë²ˆí˜¸'
        }.get(pii_type, pii_type)
        reasoning_steps.append(f"2. PII ìœ í˜•: {pii_type_kr}")

        # Step 3: ê°€ì´ë“œë¼ì¸ ê²€í† 
        if relevant_guide_texts:
            reasoning_steps.append(f"3. ê´€ë ¨ ê°€ì´ë“œë¼ì¸ {len(relevant_guide_texts)}ê°œ ê²€í† :")
            for idx, guide in enumerate(relevant_guide_texts, 1):
                reasoning_steps.append(f"   - ê°€ì´ë“œ {idx}: {guide['scenario'][:60]}...")
                cited_guidelines.append(guide['scenario'][:80])

        # ê·œì¹™ 1: ì™¸ë¶€ ì „ì†¡ì´ë©´ ëŒ€ë¶€ë¶„ ë§ˆìŠ¤í‚¹
        if receiver_type == 'external':
            should_mask = True
            reasoning_steps.append("4. íŒë‹¨ ê·¼ê±°:")

            # PII ìœ í˜•ë³„ ë§ˆìŠ¤í‚¹ ë°©ë²•
            if pii_type in ['jumin', 'account']:
                masking_method = "full"
                reasoning_steps.append(f"   - ê°œì¸ì •ë³´ë³´í˜¸ë²• ì œ24ì¡°: ê³ ìœ ì‹ë³„ì •ë³´({pii_type_kr})ëŠ” ì œ3ì ì œê³µ ì‹œ í•„ìˆ˜ì ìœ¼ë¡œ ì•”í˜¸í™”/ë§ˆìŠ¤í‚¹ í•„ìš”")
                reasoning_steps.append(f"   - PIPA ì œ24ì¡°ì˜2: ì™¸ë¶€ ì „ì†¡ ì‹œ ì£¼ë¯¼ë“±ë¡ë²ˆí˜¸, ê³„ì¢Œë²ˆí˜¸ ë“±ì€ ì™„ì „ ì‚­ì œ ë˜ëŠ” ëŒ€ì²´")
                reasoning_steps.append(f"   - ìœ„í—˜ë„: CRITICAL - ìœ ì¶œ ì‹œ ë²•ì  ì œì¬ ë° ë§‰ëŒ€í•œ ì†í•´ë°°ìƒ ê°€ëŠ¥")
                reason = "ê³ ìœ ì‹ë³„ì •ë³´ ì™¸ë¶€ ì „ì†¡ ê¸ˆì§€ (ê°œì¸ì •ë³´ë³´í˜¸ë²• ì œ24ì¡°)"
                cited_guidelines.append("ê°œì¸ì •ë³´ë³´í˜¸ë²• ì œ24ì¡°: ê³ ìœ ì‹ë³„ì •ë³´ ì²˜ë¦¬ ì œí•œ")
            elif pii_type == 'email':
                masking_method = "partial"
                reasoning_steps.append(f"   - ê°œì¸ì •ë³´ë³´í˜¸ë²• ì œ17ì¡°: ê°œì¸ì •ë³´ ì œ3ì ì œê³µ ì‹œ ìµœì†Œí•œì˜ ì •ë³´ë§Œ ì œê³µ")
                reasoning_steps.append(f"   - ì´ë©”ì¼ì€ ì—…ë¬´ ì—°ë½ì— í•„ìš”í•˜ë¯€ë¡œ ë¶€ë¶„ ë§ˆìŠ¤í‚¹ìœ¼ë¡œ íƒ€í˜‘")
                reasoning_steps.append(f"   - ë„ë©”ì¸ì€ ìœ ì§€í•˜ì—¬ ì†Œì† í™•ì¸ ê°€ëŠ¥í•˜ë„ë¡ ì²˜ë¦¬")
                reason = "ê°œì¸ì •ë³´ ìµœì†Œí™” ì›ì¹™ (ê°œì¸ì •ë³´ë³´í˜¸ë²• ì œ17ì¡°)"
                cited_guidelines.append("ê°œì¸ì •ë³´ë³´í˜¸ë²• ì œ17ì¡°: ê°œì¸ì •ë³´ ì œê³µ ì‹œ ìµœì†Œí™”")
            else:
                masking_method = "partial"
                reasoning_steps.append(f"   - ì™¸ë¶€ ì „ì†¡ ì‹œ {pii_type_kr} ë¶€ë¶„ ë§ˆìŠ¤í‚¹ ê¶Œì¥")
                reasoning_steps.append(f"   - ì—…ë¬´ ì—°ì†ì„±ì„ ìœ„í•´ ì¼ë¶€ ì •ë³´ëŠ” ë³´ì¡´")
                reason = "ì™¸ë¶€ ì „ì†¡ ì‹œ ê°œì¸ì •ë³´ ë§ˆìŠ¤í‚¹ í•„ìˆ˜"

            reasoning_steps.append(f"5. ìµœì¢… ê²°ì •: {masking_method.upper()} ë§ˆìŠ¤í‚¹ ì ìš©")

        # ê·œì¹™ 2: ë‚´ë¶€ ì „ì†¡ì´ì–´ë„ ë¯¼ê°ì •ë³´ëŠ” ë§ˆìŠ¤í‚¹
        elif pii_type in ['jumin', 'account']:
            should_mask = True
            masking_method = "full"
            reasoning_steps.append("4. íŒë‹¨ ê·¼ê±°:")
            reasoning_steps.append(f"   - ê°œì¸ì •ë³´ë³´í˜¸ë²• ì œ24ì¡°: ê³ ìœ ì‹ë³„ì •ë³´ëŠ” ë‚´ë¶€ ì „ì†¡ì´ë¼ë„ ìµœì†Œí•œìœ¼ë¡œë§Œ ì²˜ë¦¬")
            reasoning_steps.append(f"   - ë‚´ë¶€ ìœ ì¶œ ì‚¬ê³  ëŒ€ë¹„: ë¶ˆí•„ìš”í•œ {pii_type_kr} ë…¸ì¶œ ë°©ì§€")
            reasoning_steps.append(f"   - ì—…ë¬´ìƒ í•„ìˆ˜ê°€ ì•„ë‹Œ ê²½ìš° ì™„ì „ ë§ˆìŠ¤í‚¹ ê¶Œì¥")
            reasoning_steps.append(f"5. ìµœì¢… ê²°ì •: FULL ë§ˆìŠ¤í‚¹ ì ìš©")
            reason = "ê³ ìœ ì‹ë³„ì •ë³´ëŠ” ë‚´ë¶€ ì „ì†¡ì—ë„ ìµœì†Œ ì²˜ë¦¬ (ê°œì¸ì •ë³´ë³´í˜¸ë²• ì œ24ì¡°)"
            cited_guidelines.append("ê°œì¸ì •ë³´ë³´í˜¸ë²• ì œ24ì¡°: ê³ ìœ ì‹ë³„ì •ë³´ ì²˜ë¦¬ ì œí•œ")

        # ê·œì¹™ 3: ê°€ì´ë“œë¼ì¸ì— ëª…ì‹œì  ë§ˆìŠ¤í‚¹ ì§€ì‹œê°€ ìˆìœ¼ë©´ ì ìš©
        elif 'mask_required' in guideline_keywords:
            should_mask = True
            masking_method = "partial"
            reasoning_steps.append("4. íŒë‹¨ ê·¼ê±°:")
            reasoning_steps.append(f"   - ê²€ìƒ‰ëœ ê°€ì´ë“œë¼ì¸ì—ì„œ ë§ˆìŠ¤í‚¹ ì§€ì‹œ ë°œê²¬")
            if relevant_guide_texts:
                reasoning_steps.append(f"   - ê´€ë ¨ ì§€ì¹¨: {relevant_guide_texts[0]['directive'][:80]}...")
            reasoning_steps.append(f"5. ìµœì¢… ê²°ì •: PARTIAL ë§ˆìŠ¤í‚¹ ì ìš©")
            reason = "ì •ì±… ê°€ì´ë“œë¼ì¸ì— ë”°ë¼ ë§ˆìŠ¤í‚¹ í•„ìš”"

        else:
            should_mask = False
            masking_method = "none"
            reasoning_steps.append("4. íŒë‹¨ ê·¼ê±°:")
            reasoning_steps.append(f"   - ë‚´ë¶€ ì „ì†¡ì´ë©° ë¯¼ê°ì •ë³´ê°€ ì•„ë‹˜")
            reasoning_steps.append(f"   - ì—…ë¬´ìƒ {pii_type_kr} ê³µìœ ê°€ í•„ìš”í•œ ìƒí™©")
            reasoning_steps.append(f"   - ë§ˆìŠ¤í‚¹ ë¶ˆí•„ìš”í•˜ë‚˜ ì¶”í›„ ê²€í†  í•„ìš”")
            reasoning_steps.append(f"5. ìµœì¢… ê²°ì •: ë§ˆìŠ¤í‚¹ ë¯¸ì ìš©")
            reason = "ë‚´ë¶€ ì „ì†¡ìœ¼ë¡œ ë§ˆìŠ¤í‚¹ ë¶ˆí•„ìš”"

        # ë§ˆìŠ¤í‚¹ ë¯¸ë¦¬ë³´ê¸° ìƒì„±
        masked_value = None
        if should_mask:
            masked_value = _generate_masked_preview(pii.get('value', ''), pii_type, masking_method)

        # reasoningì„ ë¬¸ìì—´ë¡œ ë³€í™˜
        reasoning_text = "\n".join(reasoning_steps)

        decisions[f"pii_{i}"] = {
            "pii_id": f"pii_{i}",
            "type": pii_type,
            "value": pii['value'],
            "should_mask": should_mask,
            "masking_method": masking_method,
            "masked_value": masked_value,
            "reason": reason,
            "reasoning": reasoning_text,  # ìƒì„¸ ì¶”ë¡  ê³¼ì •
            "cited_guidelines": cited_guidelines,  # ì¸ìš©ëœ ê°€ì´ë“œë¼ì¸
            "guideline_matched": len(guideline_keywords) > 0,
            "confidence": 0.85,
            "risk_level": "high" if pii_type in ['jumin', 'account'] else "medium" if should_mask else "low"
        }

    return decisions


def _generate_masked_preview(value: str, pii_type: str, method: str) -> str:
    """ë§ˆìŠ¤í‚¹ ë¯¸ë¦¬ë³´ê¸° ìƒì„±"""
    if method == "full":
        return "***"
    elif method == "partial":
        if pii_type == "email":
            parts = value.split("@")
            if len(parts) == 2:
                return parts[0][:2] + "***@" + parts[1]
        elif pii_type == "phone":
            if "-" in value:
                return value[:3] + "-***-" + value[-4:]
            else:
                return value[:3] + "***" + value[-4:]
        elif pii_type == "jumin":
            return value[:6] + "-*******"
        elif pii_type == "account":
            parts = value.split("-")
            if len(parts) == 3:
                return parts[0] + "-***-" + parts[2]
        return value[:3] + "***"
    elif method == "redact":
        return "[REDACTED]"
    elif method == "hash":
        return "[HASHED]"
    else:
        return value


def generate_summary(context: Dict, decisions: Dict, guides: List[Dict]) -> str:
    """AI ë¶„ì„ ìš”ì•½ ìƒì„±"""

    masked_count = sum(1 for d in decisions.values() if d.get('should_mask', False))
    total_count = len(decisions)

    receiver_type = context.get('receiver_type', 'unknown')
    receiver_text = "ì™¸ë¶€" if receiver_type == "external" else "ë‚´ë¶€"

    summary = f"{receiver_text} ì „ì†¡ìœ¼ë¡œ ë¶„ë¥˜ë˜ì–´, "

    if masked_count > 0:
        summary += f"{total_count}ê°œ ê°œì¸ì •ë³´ ì¤‘ {masked_count}ê°œë¥¼ ë§ˆìŠ¤í‚¹í•˜ë„ë¡ ê¶Œì¥í•©ë‹ˆë‹¤. "
    else:
        summary += "ë§ˆìŠ¤í‚¹ì´ í•„ìš”í•œ ê°œì¸ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤. "

    if guides:
        summary += f"\n\nê´€ë ¨ ê·œì • {len(guides)}ê°œë¥¼ ì°¸ê³ í–ˆìŠµë‹ˆë‹¤."

    return summary


def fallback_analysis(request: RAGAnalysisRequest) -> JSONResponse:
    """VectorDB ì‚¬ìš© ë¶ˆê°€ ì‹œ ê¸°ë³¸ ê·œì¹™ ê¸°ë°˜ ë¶„ì„"""

    decisions = {}
    context = request.context
    receiver_type = context.get('receiver_type', 'external')

    for i, pii in enumerate(request.detected_pii):
        pii_type = pii['type']
        pii_value = pii['value']
        masking_method = "none"
        reasoning_steps = []
        cited_guidelines = []

        # PII ìœ í˜• í•œê¸€ëª…
        pii_type_kr = {
            'email': 'ì´ë©”ì¼ ì£¼ì†Œ',
            'phone': 'ì „í™”ë²ˆí˜¸',
            'jumin': 'ì£¼ë¯¼ë“±ë¡ë²ˆí˜¸',
            'account': 'ê³„ì¢Œë²ˆí˜¸',
            'passport': 'ì—¬ê¶Œë²ˆí˜¸',
            'driver_license': 'ìš´ì „ë©´í—ˆë²ˆí˜¸'
        }.get(pii_type, pii_type)

        # Step 1: ì»¨í…ìŠ¤íŠ¸ ë¶„ì„
        reasoning_steps.append(f"1. ì»¨í…ìŠ¤íŠ¸ í™•ì¸: {receiver_type} ì „ì†¡")
        reasoning_steps.append(f"2. PII ìœ í˜•: {pii_type_kr}")
        reasoning_steps.append("3. VectorDB ì‚¬ìš© ë¶ˆê°€ â†’ ê¸°ë³¸ ê·œì¹™ ì ìš©")

        # ì™¸ë¶€ ì „ì†¡ì´ë©´ ëª¨ë‘ ë§ˆìŠ¤í‚¹
        if receiver_type == 'external':
            should_mask = True
            reasoning_steps.append("4. íŒë‹¨ ê·¼ê±°:")

            # PII ìœ í˜•ë³„ ë§ˆìŠ¤í‚¹ ë°©ë²•
            if pii_type in ['jumin', 'account']:
                masking_method = "full"
                reasoning_steps.append(f"   - ê°œì¸ì •ë³´ë³´í˜¸ë²• ì œ24ì¡°: ê³ ìœ ì‹ë³„ì •ë³´({pii_type_kr})ëŠ” ì œ3ì ì œê³µ ì‹œ ì›ì¹™ì  ê¸ˆì§€")
                reasoning_steps.append(f"   - ë¶ˆê°€í”¼í•œ ê²½ìš° ì™„ì „ ì•”í˜¸í™”/ë§ˆìŠ¤í‚¹ í•„ìˆ˜")
                reasoning_steps.append(f"   - ìœ„í—˜ë„: CRITICAL - ë²•ì  ì œì¬ ëŒ€ìƒ")
                reason = "ê³ ìœ ì‹ë³„ì •ë³´ ì™¸ë¶€ ì „ì†¡ ê¸ˆì§€ (ê°œì¸ì •ë³´ë³´í˜¸ë²• ì œ24ì¡°)"
                cited_guidelines.append("ê°œì¸ì •ë³´ë³´í˜¸ë²• ì œ24ì¡°: ê³ ìœ ì‹ë³„ì •ë³´ ì²˜ë¦¬ ì œí•œ")
            else:
                masking_method = "partial"
                reasoning_steps.append(f"   - ê°œì¸ì •ë³´ë³´í˜¸ë²• ì œ17ì¡°: ì œ3ì ì œê³µ ì‹œ ìµœì†Œí•œì˜ ì •ë³´ë§Œ ì „ë‹¬")
                reasoning_steps.append(f"   - {pii_type_kr}ëŠ” ì—…ë¬´ìƒ í•„ìš”í•˜ë¯€ë¡œ ë¶€ë¶„ ë§ˆìŠ¤í‚¹ ì ìš©")
                reasoning_steps.append(f"   - ì‹ë³„ ê°€ëŠ¥ì„±ì„ ë‚®ì¶”ë˜ ì—…ë¬´ ì—°ì†ì„± ìœ ì§€")
                reason = "ê°œì¸ì •ë³´ ìµœì†Œí™” ì›ì¹™ (ê°œì¸ì •ë³´ë³´í˜¸ë²• ì œ17ì¡°)"
                cited_guidelines.append("ê°œì¸ì •ë³´ë³´í˜¸ë²• ì œ17ì¡°: ê°œì¸ì •ë³´ ì œê³µ ì‹œ ìµœì†Œí™”")

            reasoning_steps.append(f"5. ìµœì¢… ê²°ì •: {masking_method.upper()} ë§ˆìŠ¤í‚¹ ì ìš©")
        else:
            # ì£¼ë¯¼ë²ˆí˜¸, ê³„ì¢Œë²ˆí˜¸ëŠ” í•­ìƒ ë§ˆìŠ¤í‚¹
            if pii_type in ['jumin', 'account']:
                should_mask = True
                masking_method = "full"
                reasoning_steps.append("4. íŒë‹¨ ê·¼ê±°:")
                reasoning_steps.append(f"   - ë‚´ë¶€ ì „ì†¡ì´ë‚˜ ê³ ìœ ì‹ë³„ì •ë³´ëŠ” ìµœì†Œ ì²˜ë¦¬ ì›ì¹™ ì ìš©")
                reasoning_steps.append(f"   - ê°œì¸ì •ë³´ë³´í˜¸ë²• ì œ24ì¡°: ì—…ë¬´ìƒ ë¶ˆê°€í”¼í•œ ê²½ìš°ì—ë§Œ ì²˜ë¦¬")
                reasoning_steps.append(f"   - ë‚´ë¶€ ìœ ì¶œ ì‚¬ê³  ëŒ€ë¹„ í•„ìš”")
                reasoning_steps.append(f"5. ìµœì¢… ê²°ì •: FULL ë§ˆìŠ¤í‚¹ ì ìš©")
                reason = "ë¯¼ê°ì •ë³´ ìµœì†Œ ì²˜ë¦¬ (ê°œì¸ì •ë³´ë³´í˜¸ë²• ì œ24ì¡°)"
                cited_guidelines.append("ê°œì¸ì •ë³´ë³´í˜¸ë²• ì œ24ì¡°: ê³ ìœ ì‹ë³„ì •ë³´ ìµœì†Œ ì²˜ë¦¬")
            else:
                should_mask = False
                masking_method = "none"
                reasoning_steps.append("4. íŒë‹¨ ê·¼ê±°:")
                reasoning_steps.append(f"   - ë‚´ë¶€ ì „ì†¡ì´ë©° ì¼ë°˜ ê°œì¸ì •ë³´")
                reasoning_steps.append(f"   - ì—…ë¬´ìƒ {pii_type_kr} ê³µìœ ê°€ í•„ìš”")
                reasoning_steps.append(f"   - ì ‘ê·¼ ê¶Œí•œ ê´€ë¦¬ë¡œ ë³´ì•ˆ ìœ ì§€")
                reasoning_steps.append(f"5. ìµœì¢… ê²°ì •: ë§ˆìŠ¤í‚¹ ë¯¸ì ìš©")
                reason = "ë‚´ë¶€ ì „ì†¡ìœ¼ë¡œ ë§ˆìŠ¤í‚¹ ë¶ˆí•„ìš”"

        # ë§ˆìŠ¤í‚¹ ë¯¸ë¦¬ë³´ê¸° ìƒì„±
        masked_value = None
        if should_mask:
            masked_value = _generate_masked_preview(pii_value, pii_type, masking_method)

        # reasoningì„ ë¬¸ìì—´ë¡œ ë³€í™˜
        reasoning_text = "\n".join(reasoning_steps)

        decisions[f"pii_{i}"] = {
            "pii_id": f"pii_{i}",
            "type": pii_type,
            "value": pii_value,
            "should_mask": should_mask,
            "masking_method": masking_method,
            "masked_value": masked_value,
            "reason": reason,
            "reasoning": reasoning_text,  # ìƒì„¸ ì¶”ë¡  ê³¼ì •
            "cited_guidelines": cited_guidelines,  # ì¸ìš©ëœ ë²•ë ¹
            "confidence": 0.8,
            "risk_level": "high" if pii_type in ['jumin', 'account'] else "medium" if should_mask else "low"
        }

    masked_count = sum(1 for d in decisions.values() if d['should_mask'])

    summary = f"ê¸°ë³¸ ê·œì¹™ì— ë”°ë¼ {len(decisions)}ê°œ ê°œì¸ì •ë³´ ì¤‘ {masked_count}ê°œ ë§ˆìŠ¤í‚¹ì„ ê¶Œì¥í•©ë‹ˆë‹¤."

    return JSONResponse({
        "success": True,
        "data": {
            "masking_decisions": decisions,
            "summary": summary,
            "relevant_guides": [],
            "total_guides_found": 0,
            "fallback": True
        }
    })
