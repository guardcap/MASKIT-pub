"""
VectorDB ë° ì •ì±… ìŠ¤í‚¤ë§ˆ ê´€ë¦¬ ë¼ìš°í„°
- JSONL íŒŒì¼ ê´€ë¦¬ (CRUD)
- OpenAI Vector Store ë™ê¸°í™”
- source_document ê¸°ë°˜ ê·¸ë£¹í™”
"""

from fastapi import APIRouter, HTTPException, Depends, Request
from fastapi.responses import JSONResponse, StreamingResponse
from typing import List, Optional, Dict, Any
import asyncio
from pathlib import Path
from datetime import datetime
import json
from openai import OpenAI
import os
from dotenv import load_dotenv
import hashlib
from pydantic import BaseModel

from app.audit.logger import AuditLogger
from app.auth.auth_utils import get_current_user
from app.vectordb.rag_masking import decide_all_pii_with_rag
from app.utils.masking_rules import MaskingRules

load_dotenv()

router = APIRouter(prefix="/api/vectordb", tags=["VectorDB Management"])

# ê²½ë¡œ ì„¤ì • - ì ˆëŒ€ ê²½ë¡œë¡œ ë³€í™˜
BASE_DIR = Path(__file__).resolve().parent.parent.parent.parent
STAGING_DIR = BASE_DIR / "app" / "rag" / "data" / "staging"

# ë””ë ‰í† ë¦¬ ìƒì„±
STAGING_DIR.mkdir(parents=True, exist_ok=True)

# OpenAI í´ë¼ì´ì–¸íŠ¸
openai_client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# OpenAI Vector Store ì„¤ì •
VECTOR_STORE_ID = os.getenv("OPENAI_VECTOR_STORE_ID")


# Pydantic ëª¨ë¸
class PolicyGuide(BaseModel):
    guide_id: str
    source_authority: str
    source_document: str
    scenario: str
    context: Dict[str, Any]
    interpretation: str
    actionable_directive: str
    keywords: List[str]
    related_law_ids: List[str]
    examples: List[Dict[str, Any]]
    confidence_score: float
    reviewed: bool


class PolicyGuideCreate(BaseModel):
    source_authority: str
    source_document: str
    scenario: str
    context: Dict[str, Any]
    interpretation: str
    actionable_directive: str
    keywords: List[str]
    related_law_ids: List[str]
    examples: List[Dict[str, Any]]
    confidence_score: Optional[float] = 0.8
    reviewed: Optional[bool] = False


class PolicyGuideUpdate(BaseModel):
    source_authority: Optional[str] = None
    scenario: Optional[str] = None
    context: Optional[Dict[str, Any]] = None
    interpretation: Optional[str] = None
    actionable_directive: Optional[str] = None
    keywords: Optional[List[str]] = None
    related_law_ids: Optional[List[str]] = None
    examples: Optional[List[Dict[str, Any]]] = None
    confidence_score: Optional[float] = None
    reviewed: Optional[bool] = None


def build_search_text(guide: Dict) -> str:
    """ê²€ìƒ‰ìš© í…ìŠ¤íŠ¸ êµ¬ì„±"""
    parts = [
        f"Scenario: {guide.get('scenario', '')}",
        f"Directive: {guide.get('actionable_directive', '')}",
        f"Interpretation: {guide.get('interpretation', '')}",
        f"Keywords: {', '.join(guide.get('keywords', []))}",
    ]

    for example in guide.get('examples', []):
        parts.append(f"Example: {example.get('case_description', '')}")

    return "\n".join(parts)


def load_all_guides() -> Dict[str, List[Dict]]:
    """
    ëª¨ë“  JSONL íŒŒì¼ì„ ë¡œë“œí•˜ê³  source_documentë¡œ ê·¸ë£¹í™”
    Returns: {source_document: [guides...]}
    """
    if not STAGING_DIR.exists():
        return {}

    grouped_guides = {}
    jsonl_files = list(STAGING_DIR.glob("*.jsonl"))

    for jsonl_file in jsonl_files:
        try:
            with open(jsonl_file, "r", encoding="utf-8") as f:
                for line in f:
                    if line.strip():
                        guide = json.loads(line)
                        source_doc = guide.get("source_document", "Unknown")

                        if source_doc not in grouped_guides:
                            grouped_guides[source_doc] = []

                        guide["_jsonl_file"] = jsonl_file.name
                        grouped_guides[source_doc].append(guide)
        except Exception as e:
            print(f"íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨ {jsonl_file.name}: {e}")

    return grouped_guides


def load_guides_from_file(filename: str) -> List[Dict]:
    """íŠ¹ì • JSONL íŒŒì¼ì—ì„œ ê°€ì´ë“œ ë¡œë“œ"""
    file_path = STAGING_DIR / filename
    if not file_path.exists():
        return []

    guides = []
    with open(file_path, "r", encoding="utf-8") as f:
        for line in f:
            if line.strip():
                guides.append(json.loads(line))

    return guides


def save_guides_to_file(filename: str, guides: List[Dict]) -> bool:
    """ê°€ì´ë“œë¥¼ JSONL íŒŒì¼ì— ì €ì¥"""
    try:
        file_path = STAGING_DIR / filename
        with open(file_path, "w", encoding="utf-8") as f:
            for guide in guides:
                # _jsonl_file í•„ë“œ ì œê±°
                guide_copy = guide.copy()
                guide_copy.pop("_jsonl_file", None)
                f.write(json.dumps(guide_copy, ensure_ascii=False) + "\n")
        return True
    except Exception as e:
        print(f"íŒŒì¼ ì €ì¥ ì‹¤íŒ¨: {e}")
        return False


def search_openai_vector_store(query: str, top_k: int = 5) -> List[Dict]:
    """
    OpenAI Vector Storeì—ì„œ ê²€ìƒ‰
    """
    try:
        # File Searchë¥¼ ì‚¬ìš©í•˜ì—¬ Vector Store ê²€ìƒ‰
        response = openai_client.responses.create(
            model="gpt-4o-mini",
            input=query,
            tools=[{
                "type": "file_search",
                "vector_store_ids": [VECTOR_STORE_ID]
            }],
            tool_choice={"type": "file_search"}
        )

        # ê²€ìƒ‰ ê²°ê³¼ ì¶”ì¶œ
        results = []
        if hasattr(response, 'output') and response.output:
            for item in response.output:
                if hasattr(item, 'content'):
                    for content in item.content:
                        if hasattr(content, 'text'):
                            results.append({
                                'content': content.text,
                                'score': 0.9
                            })

        return results[:top_k]

    except Exception as e:
        print(f"OpenAI Vector Store ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
        return []


async def search_with_assistant(query: str, context: Dict = None) -> List[Dict]:
    """
    OpenAI Assistants APIì˜ File Search ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ì—¬ Vector Store ê²€ìƒ‰
    """
    try:
        # ì»¨í…ìŠ¤íŠ¸ ì •ë³´ë¥¼ ì¿¼ë¦¬ì— ì¶”ê°€
        receiver_type = context.get('receiver_type', 'external') if context else 'external'
        enhanced_query = f"ì´ë©”ì¼ {receiver_type} ì „ì†¡ ì‹œ ê°œì¸ì •ë³´ ë§ˆìŠ¤í‚¹ ê°€ì´ë“œë¼ì¸: {query}"

        # Responses APIë¡œ File Search ìˆ˜í–‰
        response = openai_client.responses.create(
            model="gpt-4o-mini",
            input=enhanced_query,
            tools=[{
                "type": "file_search",
                "vector_store_ids": [VECTOR_STORE_ID]
            }]
        )

        # ê²€ìƒ‰ ê²°ê³¼ íŒŒì‹±
        results = []

        # outputì—ì„œ file_search ê²°ê³¼ ì¶”ì¶œ
        if hasattr(response, 'output'):
            for output_item in response.output:
                # file_search_call íƒ€ì… ì²˜ë¦¬
                if hasattr(output_item, 'type') and output_item.type == 'file_search_call':
                    if hasattr(output_item, 'results') and output_item.results is not None:
                        for result in output_item.results:
                            results.append({
                                'content': result.get('text', ''),
                                'filename': result.get('filename', ''),
                                'score': result.get('score', 0.5)
                            })
                # message íƒ€ì… ì²˜ë¦¬ (í…ìŠ¤íŠ¸ ì‘ë‹µ)
                elif hasattr(output_item, 'content'):
                    for content in output_item.content:
                        if hasattr(content, 'text'):
                            # ì£¼ì„(annotations)ì—ì„œ íŒŒì¼ ì •ë³´ ì¶”ì¶œ
                            text = content.text
                            annotations = getattr(text, 'annotations', [])
                            for ann in annotations:
                                if hasattr(ann, 'file_citation'):
                                    results.append({
                                        'content': text.value if hasattr(text, 'value') else str(text),
                                        'file_id': ann.file_citation.file_id if hasattr(ann.file_citation, 'file_id') else '',
                                        'score': 0.8
                                    })

        # ê²°ê³¼ê°€ ì—†ìœ¼ë©´ ê¸°ë³¸ ì‘ë‹µ í…ìŠ¤íŠ¸ ì‚¬ìš©
        if not results and hasattr(response, 'output_text'):
            results.append({
                'content': response.output_text,
                'score': 0.7
            })

        print(f"âœ… OpenAI Vector Store ê²€ìƒ‰ ì™„ë£Œ: {len(results)}ê°œ ê²°ê³¼")
        return results

    except Exception as e:
        print(f"âš ï¸ OpenAI Vector Store ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return []


@router.get("/guides/grouped")
async def get_guides_grouped():
    """source_documentë¡œ ê·¸ë£¹í™”ëœ ëª¨ë“  ê°€ì´ë“œ ì¡°íšŒ"""
    try:
        grouped = load_all_guides()

        # í†µê³„ ì •ë³´ ì¶”ê°€
        result = []
        for source_doc, guides in grouped.items():
            result.append({
                "source_document": source_doc,
                "count": len(guides),
                "authorities": list(set(g.get("source_authority", "") for g in guides)),
                "jsonl_files": list(set(g.get("_jsonl_file", "") for g in guides)),
                "guides": guides
            })

        # source_document ì´ë¦„ìœ¼ë¡œ ì •ë ¬
        result.sort(key=lambda x: x["source_document"])

        return JSONResponse({
            "success": True,
            "data": {
                "total_source_documents": len(result),
                "total_guides": sum(item["count"] for item in result),
                "groups": result
            }
        })

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ê°€ì´ë“œ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")


@router.get("/guides/by-source/{source_document}")
async def get_guides_by_source(source_document: str):
    """íŠ¹ì • source_documentì˜ ê°€ì´ë“œ ì¡°íšŒ"""
    try:
        grouped = load_all_guides()
        guides = grouped.get(source_document, [])

        return JSONResponse({
            "success": True,
            "data": {
                "source_document": source_document,
                "count": len(guides),
                "guides": guides
            }
        })

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ê°€ì´ë“œ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")


@router.get("/guides/{guide_id}")
async def get_guide_by_id(guide_id: str):
    """íŠ¹ì • ê°€ì´ë“œ ì¡°íšŒ"""
    try:
        grouped = load_all_guides()

        for source_doc, guides in grouped.items():
            for guide in guides:
                if guide.get("guide_id") == guide_id:
                    return JSONResponse({
                        "success": True,
                        "data": guide
                    })

        raise HTTPException(status_code=404, detail="ê°€ì´ë“œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")

    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ê°€ì´ë“œ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")


@router.post("/guides")
async def create_guide(guide_data: PolicyGuideCreate):
    """ìƒˆ ê°€ì´ë“œ ìƒì„±"""
    try:
        # guide_id ìƒì„±
        timestamp = datetime.now().strftime("%Y%m")
        random_str = hashlib.md5(str(datetime.now().timestamp()).encode()).hexdigest()[:6]

        # í•´ë‹¹ source_documentì˜ ê¸°ì¡´ ê°€ì´ë“œ ê°œìˆ˜ í™•ì¸
        grouped = load_all_guides()
        existing_guides = grouped.get(guide_data.source_document, [])
        guide_index = len(existing_guides)

        authority_code = "UNK"
        if "ê°œì¸ì •ë³´ë³´í˜¸ìœ„ì›íšŒ" in guide_data.source_authority:
            authority_code = "PIPC"
        elif "ê¸ˆìœµë³´ì•ˆì›" in guide_data.source_authority:
            authority_code = "FSI"

        guide_id = f"GUIDE-{authority_code}-{timestamp}-{random_str}-{guide_index:03d}"

        # ìƒˆ ê°€ì´ë“œ ìƒì„±
        new_guide = {
            "guide_id": guide_id,
            **guide_data.model_dump()
        }

        # JSONL íŒŒì¼ëª… ê²°ì • (source_document ê¸°ë°˜)
        safe_filename = guide_data.source_document.replace(" ", "_").replace("/", "_")[:50]
        jsonl_filename = f"application_guides_{datetime.now().strftime('%Y%m%d_%H%M%S')}_{safe_filename}.jsonl"

        # ê¸°ì¡´ íŒŒì¼ì— ì¶”ê°€ ë˜ëŠ” ìƒˆ íŒŒì¼ ìƒì„±
        target_file = None
        if existing_guides:
            # ê¸°ì¡´ íŒŒì¼ ì¤‘ í•˜ë‚˜ ì„ íƒ
            target_file = existing_guides[0].get("_jsonl_file")

        if not target_file:
            target_file = jsonl_filename

        # íŒŒì¼ì—ì„œ ê¸°ì¡´ ê°€ì´ë“œ ë¡œë“œ
        all_guides = load_guides_from_file(target_file) if target_file else []
        all_guides.append(new_guide)

        # íŒŒì¼ ì €ì¥
        if not save_guides_to_file(target_file, all_guides):
            raise HTTPException(status_code=500, detail="íŒŒì¼ ì €ì¥ ì‹¤íŒ¨")

        return JSONResponse({
            "success": True,
            "message": "ê°€ì´ë“œê°€ ì„±ê³µì ìœ¼ë¡œ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤",
            "data": {
                "guide_id": guide_id,
                "jsonl_file": target_file
            }
        })

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ê°€ì´ë“œ ìƒì„± ì‹¤íŒ¨: {str(e)}")


@router.put("/guides/{guide_id}")
async def update_guide(guide_id: str, guide_data: PolicyGuideUpdate):
    """ê°€ì´ë“œ ì—…ë°ì´íŠ¸"""
    try:
        grouped = load_all_guides()

        target_file = None
        updated_guide = None

        # ê°€ì´ë“œ ì°¾ê¸°
        for source_doc, guides in grouped.items():
            for guide in guides:
                if guide.get("guide_id") == guide_id:
                    target_file = guide.get("_jsonl_file")
                    break
            if target_file:
                break

        if not target_file:
            raise HTTPException(status_code=404, detail="ê°€ì´ë“œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")

        # íŒŒì¼ì—ì„œ ëª¨ë“  ê°€ì´ë“œ ë¡œë“œ
        all_guides = load_guides_from_file(target_file)

        # ì—…ë°ì´íŠ¸ëœ ê°€ì´ë“œ ì°¾ì•„ì„œ ìˆ˜ì •
        for i, g in enumerate(all_guides):
            if g.get("guide_id") == guide_id:
                update_dict = guide_data.model_dump(exclude_unset=True)
                all_guides[i].update(update_dict)
                updated_guide = all_guides[i]
                break

        # íŒŒì¼ ì €ì¥
        if not save_guides_to_file(target_file, all_guides):
            raise HTTPException(status_code=500, detail="íŒŒì¼ ì €ì¥ ì‹¤íŒ¨")

        return JSONResponse({
            "success": True,
            "message": "ê°€ì´ë“œê°€ ì„±ê³µì ìœ¼ë¡œ ì—…ë°ì´íŠ¸ë˜ì—ˆìŠµë‹ˆë‹¤",
            "data": updated_guide
        })

    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ê°€ì´ë“œ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {str(e)}")


@router.delete("/guides/{guide_id}")
async def delete_guide(guide_id: str):
    """ê°€ì´ë“œ ì‚­ì œ"""
    try:
        grouped = load_all_guides()

        target_file = None

        # ê°€ì´ë“œ ì°¾ê¸°
        for source_doc, guides in grouped.items():
            for guide in guides:
                if guide.get("guide_id") == guide_id:
                    target_file = guide.get("_jsonl_file")
                    break
            if target_file:
                break

        if not target_file:
            raise HTTPException(status_code=404, detail="ê°€ì´ë“œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")

        # íŒŒì¼ì—ì„œ ê°€ì´ë“œ ì œê±°
        all_guides = load_guides_from_file(target_file)
        all_guides = [g for g in all_guides if g.get("guide_id") != guide_id]

        # íŒŒì¼ ì €ì¥
        if not save_guides_to_file(target_file, all_guides):
            raise HTTPException(status_code=500, detail="íŒŒì¼ ì €ì¥ ì‹¤íŒ¨")

        return JSONResponse({
            "success": True,
            "message": "ê°€ì´ë“œê°€ ì„±ê³µì ìœ¼ë¡œ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤"
        })

    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ê°€ì´ë“œ ì‚­ì œ ì‹¤íŒ¨: {str(e)}")


@router.get("/stats")
async def get_vectordb_stats():
    """VectorDB í†µê³„"""
    try:
        grouped = load_all_guides()

        total_guides = sum(len(guides) for guides in grouped.values())
        authorities = set()
        jsonl_files = set()

        for guides in grouped.values():
            for guide in guides:
                authorities.add(guide.get("source_authority", ""))
                jsonl_files.add(guide.get("_jsonl_file", ""))

        # OpenAI Vector Store ì •ë³´ í™•ì¸
        vector_store_status = "unknown"
        vector_store_file_count = 0
        try:
            vs = openai_client.vector_stores.retrieve(VECTOR_STORE_ID)
            vector_store_status = vs.status if hasattr(vs, 'status') else "active"
            vector_store_file_count = vs.file_counts.total if hasattr(vs, 'file_counts') else 0
        except Exception as e:
            print(f"Vector Store ì¡°íšŒ ì‹¤íŒ¨: {e}")
            vector_store_status = "error"

        return JSONResponse({
            "success": True,
            "data": {
                "total_guides": total_guides,
                "total_source_documents": len(grouped),
                "total_jsonl_files": len(jsonl_files),
                "authorities": list(authorities),
                "vector_store_id": VECTOR_STORE_ID,
                "vector_store_status": vector_store_status,
                "vector_store_file_count": vector_store_file_count,
                "sync_status": "openai_vector_store"
            }
        })

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"í†µê³„ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")


# ===== RAG ë¶„ì„ ì—”ë“œí¬ì¸íŠ¸ =====

class RAGAnalysisRequest(BaseModel):
    email_body: str
    email_subject: str
    context: Dict[str, Any]
    detected_pii: List[Dict[str, str]]
    query: str


@router.post("/analyze-stream")
async def analyze_email_with_rag_stream(
    request: RAGAnalysisRequest,
    http_request: Request,
    current_user: dict = Depends(get_current_user)
):
    """
    OpenAI Vector Store ê¸°ë°˜ ì´ë©”ì¼ ë¶„ì„ (ìŠ¤íŠ¸ë¦¬ë°)
    """
    async def generate():
        progress_logs = []

        def log_progress(message: str):
            progress_logs.append(message)
            print(message)

        try:
            # Vector Store ê²€ìƒ‰
            search_query = f"{request.context.get('receiver_type', 'external')} ì „ì†¡ ê°œì¸ì •ë³´ ë§ˆìŠ¤í‚¹"

            relevant_guides = await search_with_assistant(search_query, request.context)

            if not relevant_guides:
                yield f"data: {json.dumps({'type': 'error', 'message': 'Vector Store ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ'})}\n\n"
                return

            # PII ë¶„ì„ ì‹œì‘
            total_pii = len(request.detected_pii)
            yield f"data: {json.dumps({'type': 'total', 'count': total_pii})}\n\n"

            # ê° PII ë¶„ì„ (ì§„í–‰ ìƒí™© ìŠ¤íŠ¸ë¦¬ë°)
            from app.vectordb.rag_masking import decide_masking_with_rag
            from app.utils.masking_rules import MaskingRules

            decisions = {}
            for i, pii in enumerate(request.detected_pii):
                pii_type = pii.get('type', '')
                pii_value = pii.get('value', '')

                # í„°ë¯¸ë„ ë¡œê·¸ ì¶œë ¥ (ê¸°ì¡´ ë°©ì‹)
                log_progress(f"[RAG] PII #{i+1}/{total_pii}: type={pii_type}, value={pii_value[:10]}...")

                # UIì—ëŠ” ì§„í–‰ë¥ ë§Œ ì „ì†¡
                yield f"data: {json.dumps({'type': 'progress', 'current': i + 1, 'total': total_pii})}\n\n"

                # RAG ë¶„ì„
                decision = await decide_masking_with_rag(pii_type, pii_value, request.context, relevant_guides)

                masked_value = None
                if decision['should_mask']:
                    try:
                        masked_value = MaskingRules.apply_masking(pii_value, pii_type.lower(), 'full')
                    except Exception as e:
                        print(f"âŒ ë§ˆìŠ¤í‚¹ ë¯¸ë¦¬ë³´ê¸° ì‹¤íŒ¨: {e}")
                        masked_value = "***"

                decisions[f"pii_{i}"] = {
                    "type": pii_type,
                    "value": pii_value,
                    "should_mask": decision["should_mask"],
                    "reason": decision.get("reason", ""),
                    "masked_value": masked_value,
                    "legal_basis": decision.get("legal_basis", ""),
                    "cited_guidelines": decision.get("cited_guidelines", []),
                    "masking_method": decision.get("masking_method", "none"),
                    "risk_level": (
                        "high" if pii_type.lower() in ['jumin', 'resident_id', 'account', 'bank_account', 'card_number', 'passport', 'driver_license']
                        else "medium" if pii_type.lower() in ['person', 'email', 'phone', 'address'] and decision['should_mask']
                        else "low"
                    )
                }

                # í„°ë¯¸ë„ì— íŒë‹¨ ì™„ë£Œ ë¡œê·¸ ì¶œë ¥
                log_progress(f"âœ… PII #{i} íŒë‹¨ ì™„ë£Œ: {decision.get('masking_method', 'none')}, ê·¼ê±°: {decision.get('legal_basis', 'N/A')}")

            # ìµœì¢… ê²°ê³¼ ì „ì†¡ (generate_summaryëŠ” ì´ë¯¸ ê°™ì€ íŒŒì¼ì— ìˆìŒ)
            summary = generate_summary(request.context, decisions, relevant_guides)

            cited_guide_texts = set()
            for decision in decisions.values():
                if decision.get('cited_guidelines'):
                    cited_guide_texts.update(decision['cited_guidelines'])

            masked_count = sum(1 for d in decisions.values() if d.get('should_mask', False))

            result = {
                "type": "complete",
                "data": {
                    "masking_decisions": decisions,
                    "summary": summary,
                    "relevant_guides": relevant_guides[:5],
                    "cited_guidelines": list(cited_guide_texts),
                    "total_guides_found": len(relevant_guides),
                    "total_cited": len(cited_guide_texts),
                }
            }

            yield f"data: {json.dumps(result)}\n\n"

        except Exception as e:
            print(f"ìŠ¤íŠ¸ë¦¬ë° ì˜¤ë¥˜: {e}")
            import traceback
            traceback.print_exc()
            yield f"data: {json.dumps({'type': 'error', 'message': str(e)})}\n\n"

    return StreamingResponse(generate(), media_type="text/event-stream")


@router.post("/analyze")
async def analyze_email_with_rag(
    request: RAGAnalysisRequest,
    http_request: Request,
    current_user: dict = Depends(get_current_user)
):
    """
    OpenAI Vector Store ê¸°ë°˜ ì´ë©”ì¼ ë¶„ì„ ë° ë§ˆìŠ¤í‚¹ ê²°ì • (ê¸°ì¡´ ë°©ì‹)
    """
    # ì§„í–‰ ìƒí™© ë¡œê·¸ ìˆ˜ì§‘
    progress_logs = []

    def log_progress(message: str):
        progress_logs.append(message)
        print(message)

    try:
        # OpenAI Vector Storeì—ì„œ ê´€ë ¨ ê°€ì´ë“œë¼ì¸ ê²€ìƒ‰
        search_query = f"{request.context.get('receiver_type', 'external')} ì „ì†¡ ê°œì¸ì •ë³´ ë§ˆìŠ¤í‚¹"

        log_progress(f"ğŸ“ Vector Store ê²€ìƒ‰ ì¿¼ë¦¬: {search_query}")

        relevant_guides = await search_with_assistant(search_query, request.context)

        if not relevant_guides:
            log_progress("âš ï¸ Vector Store ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ, fallback ì‚¬ìš©")
            return fallback_analysis(request)

        log_progress(f"âœ… {len(relevant_guides)}ê°œ ê°€ì´ë“œë¼ì¸ ê²€ìƒ‰ë¨")

        # ê°€ì´ë“œë¼ì¸ ì¶œì²˜ ë¡œê¹…
        guide_sources = set()
        for guide in relevant_guides[:3]:
            filename = guide.get('filename', 'ì •ì±… ë¬¸ì„œ')
            guide_sources.add(filename)

        if guide_sources:
            log_progress(f"ğŸ“š ì°¸ì¡° ë¬¸ì„œ: {', '.join(list(guide_sources)[:3])}")

        log_progress(f"ğŸ¤– ì´ {len(request.detected_pii)}ê°œ PII ë¶„ì„ ì‹œì‘...")

        # RAG ê¸°ë°˜ ë§ˆìŠ¤í‚¹ ê²°ì •
        masking_decisions = await decide_all_pii_with_rag(
            request.detected_pii,
            request.context,
            relevant_guides,
            progress_callback=log_progress
        )

        # AI ìš”ì•½ ìƒì„±
        summary = generate_summary(request.context, masking_decisions, relevant_guides)

        # ì‹¤ì œ ì¸ìš©ëœ ê°€ì´ë“œë¼ì¸ë§Œ ì¶”ì¶œ
        cited_guide_texts = set()
        for decision in masking_decisions.values():
            if decision.get('cited_guidelines'):
                cited_guide_texts.update(decision['cited_guidelines'])

        # ë§ˆìŠ¤í‚¹ëœ PII ê°œìˆ˜ ê³„ì‚°
        masked_count = sum(1 for d in masking_decisions.values() if d.get('should_mask', False))

        log_progress(f"âœ… ë¶„ì„ ì™„ë£Œ: {masked_count}/{len(request.detected_pii)}ê°œ PII ë§ˆìŠ¤í‚¹ ê¶Œì¥")

        print(f"ğŸ“Š ì´ ìˆ˜ì§‘ëœ ë¡œê·¸: {len(progress_logs)}ê°œ")
        print(f"ğŸ“‹ ë¡œê·¸ ë‚´ìš©: {progress_logs[:3]}...")  # ì²˜ìŒ 3ê°œë§Œ ì¶œë ¥

        # ê°ì‚¬ ë¡œê·¸ ê¸°ë¡
        await AuditLogger.log_masking_decision(
            user_email=current_user["email"],
            user_role=current_user.get("role", "user"),
            pii_count=len(request.detected_pii),
            masked_count=masked_count,
            receiver_type=request.context.get('receiver_type', 'unknown'),
            cited_guidelines=list(cited_guide_texts),
            request=http_request,
        )

        return JSONResponse({
            "success": True,
            "data": {
                "masking_decisions": masking_decisions,
                "summary": summary,
                "relevant_guides": relevant_guides[:5],  # ìƒìœ„ 5ê°œ í‘œì‹œ
                "cited_guidelines": list(cited_guide_texts),  # ì‹¤ì œ ì¸ìš©ëœ ê·œì • ëª©ë¡
                "total_guides_found": len(relevant_guides),
                "total_cited": len(cited_guide_texts),
                "vector_store_id": VECTOR_STORE_ID,
                "progress_logs": progress_logs  # ì§„í–‰ ìƒí™© ë¡œê·¸ ì¶”ê°€
            }
        })

    except Exception as e:
        print(f"RAG ë¶„ì„ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
        return fallback_analysis(request)


async def decide_masking_with_llm(
    email_body: str,
    detected_pii: List[Dict[str, str]],
    context: Dict[str, Any],
    guides: List[Dict[str, Any]],
) -> Dict[str, Any]:
    """
    ê°€ì´ë“œë¼ì¸ ê¸°ë°˜ ë§ˆìŠ¤í‚¹ ê²°ì • (ê·œì¹™ ì—”ì§„)
    """
    decisions = {}
    receiver_type = context.get('receiver_type', 'unknown')

    # ê°€ì´ë“œë¼ì¸ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ (ìƒìœ„ 5ê°œ ì‚¬ìš©)
    guideline_keywords = set()
    guideline_texts = []
    guideline_sources = []  # ì¶œì²˜ ì •ë³´ ì €ì¥

    for guide in guides[:5]:  # 3ê°œ -> 5ê°œë¡œ ì¦ê°€
        content = guide.get('content', '')
        filename = guide.get('filename', 'ì •ì±… ë¬¸ì„œ')

        # íŒŒì¼ëª…ì—ì„œ ì •ì±…ëª… ì¶”ì¶œ
        policy_name = filename.replace('.pdf', '').replace('.jsonl', '')
        guideline_texts.append(content[:300])  # 200 -> 300ìë¡œ ì¦ê°€
        guideline_sources.append(policy_name)

        if 'ë§ˆìŠ¤í‚¹' in content or 'mask' in content.lower():
            guideline_keywords.add('mask_required')
        if 'ì™¸ë¶€' in content or 'external' in content.lower():
            guideline_keywords.add('external_sensitive')
        if 'ë‚´ë¶€' in content or 'internal' in content.lower():
            guideline_keywords.add('internal_allowed')
        if 'ì œ3ì' in content or 'ì œê³µ' in content:
            guideline_keywords.add('third_party')
        if 'ê³ ìœ ì‹ë³„' in content:
            guideline_keywords.add('unique_identifier')

    for i, pii in enumerate(detected_pii):
        pii_type = pii.get('type', '')
        should_mask = False
        reason = ""
        masking_method = "none"
        reasoning_steps = []
        cited_guidelines = []

        print(f"[DEBUG] PII #{i}: type={pii_type}, receiver={receiver_type}, keywords={guideline_keywords}")

        # PII ìœ í˜• í•œê¸€ëª…
        pii_type_kr = {
            'email': 'ì´ë©”ì¼ ì£¼ì†Œ',
            'phone': 'ì „í™”ë²ˆí˜¸',
            'jumin': 'ì£¼ë¯¼ë“±ë¡ë²ˆí˜¸',
            'account': 'ê³„ì¢Œë²ˆí˜¸',
            'passport': 'ì—¬ê¶Œë²ˆí˜¸',
            'driver_license': 'ìš´ì „ë©´í—ˆë²ˆí˜¸'
        }.get(pii_type, pii_type)

        # Step 1: ì»¨í…ìŠ¤íŠ¸ ë¶„ì„
        reasoning_steps.append(f"1. ì»¨í…ìŠ¤íŠ¸ í™•ì¸: {receiver_type} ì „ì†¡")
        reasoning_steps.append(f"2. PII ìœ í˜•: {pii_type_kr}")

        # Step 3: ê°€ì´ë“œë¼ì¸ ê²€í† 
        if guideline_texts:
            reasoning_steps.append(f"3. OpenAI Vector Storeì—ì„œ {len(guideline_texts)}ê°œ ê°€ì´ë“œë¼ì¸ ê²€í† :")
            for idx, (text, source) in enumerate(zip(guideline_texts[:3], guideline_sources[:3]), 1):
                reasoning_steps.append(f"   - [{source}]: {text[:80]}...")
                # ì‹¤ì œ ì •ì±…ëª…ì„ ì¸ìš© ëª©ë¡ì— ì¶”ê°€
                cited_guidelines.append(f"{source}")

        # ==================== ì‚¬ì™¸ ì „ì†¡ ê·œì¹™ ====================
        if receiver_type == 'external':
            should_mask = True
            reasoning_steps.append("4. íŒë‹¨ ê·¼ê±°:")
            reasoning_steps.append(f"   âš ï¸ ì‚¬ì™¸ ì „ì†¡ - ê°œì¸ì •ë³´ë¥¼ ë”ìš± ì‹ ì¤‘í•˜ê²Œ ë³´í˜¸í•©ë‹ˆë‹¤")

            # ê³ ìœ ì‹ë³„ì •ë³´: ì™„ì „ ë§ˆìŠ¤í‚¹
            if pii_type in ['jumin', 'account', 'passport', 'driver_license', 'card_number']:
                masking_method = "full"
                reasoning_steps.append(f"   - ê³ ìœ ì‹ë³„ì •ë³´({pii_type_kr})ëŠ” ì™¸ë¶€ ì „ì†¡ ì‹œ ì™„ì „ ë§ˆìŠ¤í‚¹ì´ ë°”ëŒì§í•©ë‹ˆë‹¤")
                reason = f"ì™¸ë¶€ ì „ì†¡ìœ¼ë¡œ ê³ ìœ ì‹ë³„ì •ë³´ ì™„ì „ ë§ˆìŠ¤í‚¹ì„ ê¶Œì¥í•©ë‹ˆë‹¤ (ê°œì¸ì •ë³´ë³´í˜¸ë²• ì œ24ì¡°)"
                cited_guidelines.append("ê°œì¸ì •ë³´ë³´í˜¸ë²• ì œ24ì¡° (ê³ ìœ ì‹ë³„ì •ë³´ ì²˜ë¦¬ ì œí•œ)")

            # ì´ë¦„: ì‚¬ì™¸ëŠ” ì™„ì „ ë§ˆìŠ¤í‚¹
            elif pii_type in ['name', 'person']:
                masking_method = "full"
                reasoning_steps.append(f"   - ì™¸ë¶€ ì „ì†¡ ì‹œ ê°œì¸ ì‹ë³„ì„ ìµœì†Œí™”í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤")
                reason = "ì™¸ë¶€ ì „ì†¡ìœ¼ë¡œ ì´ë¦„ ì™„ì „ ë§ˆìŠ¤í‚¹ì„ ê¶Œì¥í•©ë‹ˆë‹¤ (ê°œì¸ì •ë³´ë³´í˜¸ë²• ì œ17ì¡°)"
                cited_guidelines.append("ê°œì¸ì •ë³´ë³´í˜¸ë²• ì œ17ì¡° (ê°œì¸ì •ë³´ ì œ3ì ì œê³µ)")

            # ì—°ë½ì²˜: ë¶€ë¶„ ë§ˆìŠ¤í‚¹
            elif pii_type in ['email', 'phone']:
                masking_method = "partial"
                reasoning_steps.append(f"   - ì™¸ë¶€ ì œê³µ ì‹œ {pii_type_kr} ì¼ë¶€ë¥¼ ë³´í˜¸í•˜ëŠ” ê²ƒì´ ì•ˆì „í•©ë‹ˆë‹¤")
                reason = f"ì™¸ë¶€ ì „ì†¡ìœ¼ë¡œ {pii_type_kr} ë¶€ë¶„ ë§ˆìŠ¤í‚¹ì„ ê¶Œì¥í•©ë‹ˆë‹¤ (ê°œì¸ì •ë³´ë³´í˜¸ë²• ì œ17ì¡°)"
                cited_guidelines.append("ê°œì¸ì •ë³´ë³´í˜¸ë²• ì œ17ì¡° (ê°œì¸ì •ë³´ ì œ3ì ì œê³µ)")

            # ì£¼ì†Œ: ì™„ì „ ë§ˆìŠ¤í‚¹
            elif pii_type in ['address']:
                masking_method = "full"
                reasoning_steps.append(f"   - ìœ„ì¹˜ì •ë³´ëŠ” ì™¸ë¶€ ì „ì†¡ ì‹œ ì™„ì „íˆ ë³´í˜¸í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤")
                reason = "ì™¸ë¶€ ì „ì†¡ìœ¼ë¡œ ì£¼ì†Œ ì™„ì „ ë§ˆìŠ¤í‚¹ì„ ê¶Œì¥í•©ë‹ˆë‹¤ (ìœ„ì¹˜ì •ë³´ë²•)"
                cited_guidelines.append("ìœ„ì¹˜ì •ë³´ì˜ ë³´í˜¸ ë° ì´ìš© ë“±ì— ê´€í•œ ë²•ë¥ ")

            # ê¸°íƒ€: ê¸°ë³¸ì ìœ¼ë¡œ ë¶€ë¶„ ë§ˆìŠ¤í‚¹
            else:
                masking_method = "partial"
                reasoning_steps.append(f"   - ì™¸ë¶€ ì „ì†¡ ì‹œ {pii_type_kr}ë¥¼ ë³´í˜¸í•˜ëŠ” ê²ƒì´ ë°”ëŒì§í•©ë‹ˆë‹¤")
                reason = f"ì™¸ë¶€ ì „ì†¡ìœ¼ë¡œ {pii_type_kr} ë¶€ë¶„ ë§ˆìŠ¤í‚¹ì„ ê¶Œì¥í•©ë‹ˆë‹¤"
                cited_guidelines.append("ê°œì¸ì •ë³´ë³´í˜¸ë²• ì œ17ì¡° (ê°œì¸ì •ë³´ ì œ3ì ì œê³µ)")

            reasoning_steps.append(f"5. ê¶Œì¥ì‚¬í•­: {masking_method.upper()} ë§ˆìŠ¤í‚¹ (ì‚¬ì™¸ ì „ì†¡)")

        # ==================== ì‚¬ë‚´ ì „ì†¡ ê·œì¹™ ====================
        elif receiver_type == 'internal':
            reasoning_steps.append("4. íŒë‹¨ ê·¼ê±°:")
            reasoning_steps.append(f"   âœ“ ì‚¬ë‚´ ì „ì†¡ - ì—…ë¬´ íš¨ìœ¨ì„ ê³ ë ¤í•˜ì—¬ ìµœì†Œí•œì˜ ë³´í˜¸ë¥¼ ì ìš©í•©ë‹ˆë‹¤")

            # ê³ ìœ ì‹ë³„ì •ë³´: ì‚¬ë‚´ì—ì„œë„ ì™„ì „ ë§ˆìŠ¤í‚¹
            if pii_type in ['jumin', 'account', 'passport', 'driver_license', 'card_number']:
                should_mask = True
                masking_method = "full"
                reasoning_steps.append(f"   - ê³ ìœ ì‹ë³„ì •ë³´ëŠ” ì¡°ì§ ë‚´ë¶€ì—ì„œë„ ë³´í˜¸ê°€ í•„ìš”í•©ë‹ˆë‹¤")
                reason = "ì‚¬ë‚´ ì „ì†¡ì´ì§€ë§Œ ê³ ìœ ì‹ë³„ì •ë³´ ì™„ì „ ë§ˆìŠ¤í‚¹ì„ ê¶Œì¥í•©ë‹ˆë‹¤ (ê°œì¸ì •ë³´ë³´í˜¸ë²• ì œ24ì¡°)"
                cited_guidelines.append("ê°œì¸ì •ë³´ë³´í˜¸ë²• ì œ24ì¡° (ê³ ìœ ì‹ë³„ì •ë³´ ì²˜ë¦¬ ì œí•œ)")
                reasoning_steps.append(f"5. ê¶Œì¥ì‚¬í•­: FULL ë§ˆìŠ¤í‚¹ (ì‚¬ë‚´ ì „ì†¡)")

            # ì´ë¦„: ì‚¬ë‚´ëŠ” ë¶€ë¶„ ë§ˆìŠ¤í‚¹ (ê°€ë…ì„± ìœ ì§€)
            elif pii_type in ['name', 'person']:
                should_mask = True
                masking_method = "partial"
                reasoning_steps.append(f"   - ì—…ë¬´ ê°€ë…ì„±ì„ ìœ ì§€í•˜ë©´ì„œ ì´ë¦„ì„ ë¶€ë¶„ì ìœ¼ë¡œ ë³´í˜¸í•©ë‹ˆë‹¤")
                reason = "ì‚¬ë‚´ ì „ì†¡ìœ¼ë¡œ ì´ë¦„ ë¶€ë¶„ ë§ˆìŠ¤í‚¹ì„ ê¶Œì¥í•©ë‹ˆë‹¤ (ê°€ë…ì„± ìœ ì§€)"
                cited_guidelines.append("ê°œì¸ì •ë³´ë³´í˜¸ë²• ì œ29ì¡° (ì•ˆì „ì¡°ì¹˜ ì˜ë¬´)")
                reasoning_steps.append(f"5. ê¶Œì¥ì‚¬í•­: PARTIAL ë§ˆìŠ¤í‚¹ (ì‚¬ë‚´ ì „ì†¡)")

            # ì—°ë½ì²˜, ì£¼ì†Œ: ì‚¬ë‚´ëŠ” ë§ˆìŠ¤í‚¹ ì•ˆ í•¨ (ì—…ë¬´ ì—°ì†ì„±)
            elif pii_type in ['email', 'phone', 'address', 'company']:
                should_mask = False
                masking_method = "none"
                reasoning_steps.append(f"   - ì¡°ì§ ë‚´ ì›í™œí•œ í˜‘ì—…ì„ ìœ„í•´ ì—°ë½ì²˜ ì •ë³´ë¥¼ ìœ ì§€í•©ë‹ˆë‹¤")
                reasoning_steps.append(f"   - ì—…ë¬´ ì—°ì†ì„± í™•ë³´ë¥¼ ìœ„í•œ ì¡°ì¹˜ì…ë‹ˆë‹¤")
                reason = "ì‚¬ë‚´ ì „ì†¡ìœ¼ë¡œ ë§ˆìŠ¤í‚¹í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤ (ì—…ë¬´ ì—°ì†ì„±)"
                reasoning_steps.append(f"5. ê¶Œì¥ì‚¬í•­: ë§ˆìŠ¤í‚¹ ë¯¸ì ìš© (ì‚¬ë‚´ ì „ì†¡)")

            # ê¸°íƒ€: ê°€ì´ë“œë¼ì¸ í™•ì¸
            else:
                if 'mask_required' in guideline_keywords:
                    should_mask = True
                    masking_method = "partial"
                    reasoning_steps.append(f"   - ì •ì±…ìƒ ë¶€ë¶„ ë§ˆìŠ¤í‚¹ì´ ê¶Œì¥ë©ë‹ˆë‹¤")
                    reason = f"ì‚¬ë‚´ ì „ì†¡ì´ì§€ë§Œ {pii_type_kr} ë¶€ë¶„ ë§ˆìŠ¤í‚¹ì„ ê¶Œì¥í•©ë‹ˆë‹¤"
                    cited_guidelines.append("ê°œì¸ì •ë³´ë³´í˜¸ë²• ì œ29ì¡° (ì•ˆì „ì¡°ì¹˜ ì˜ë¬´)")
                    reasoning_steps.append(f"5. ê¶Œì¥ì‚¬í•­: PARTIAL ë§ˆìŠ¤í‚¹")
                else:
                    should_mask = False
                    masking_method = "none"
                    reasoning_steps.append(f"   - ë¯¼ê°ì •ë³´ê°€ ì•„ë‹Œ ê²ƒìœ¼ë¡œ íŒë‹¨ë©ë‹ˆë‹¤")
                    reason = "ì‚¬ë‚´ ì „ì†¡ìœ¼ë¡œ ë§ˆìŠ¤í‚¹í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤"
                    reasoning_steps.append(f"5. ê¶Œì¥ì‚¬í•­: ë§ˆìŠ¤í‚¹ ë¯¸ì ìš©")

        # ==================== ì•Œ ìˆ˜ ì—†ëŠ” ê²½ìš° (ì•ˆì „í•˜ê²Œ ì™¸ë¶€ë¡œ ì²˜ë¦¬) ====================
        else:
            should_mask = True
            masking_method = "partial"
            reasoning_steps.append("4. íŒë‹¨ ê·¼ê±°:")
            reasoning_steps.append(f"   âš ï¸ ìˆ˜ì‹ ì íƒ€ì… ë¶ˆëª… - ì•ˆì „ì„ ìœ„í•´ ë¶€ë¶„ ë§ˆìŠ¤í‚¹ì„ ì ìš©í•©ë‹ˆë‹¤")
            reason = f"ìˆ˜ì‹ ì íƒ€ì…ì´ ë¶ˆë¶„ëª…í•˜ì—¬ {pii_type_kr} ë¶€ë¶„ ë§ˆìŠ¤í‚¹ì„ ê¶Œì¥í•©ë‹ˆë‹¤"
            cited_guidelines.append("ê°œì¸ì •ë³´ë³´í˜¸ë²• ì œ29ì¡° (ì•ˆì „ì¡°ì¹˜ ì˜ë¬´)")
            reasoning_steps.append(f"5. ê¶Œì¥ì‚¬í•­: PARTIAL ë§ˆìŠ¤í‚¹ (ì•ˆì „ ëª¨ë“œ)")

        # ë§ˆìŠ¤í‚¹ ë¯¸ë¦¬ë³´ê¸° ìƒì„±
        masked_value = None
        if should_mask:
            masked_value = _generate_masked_preview(pii.get('value', ''), pii_type, masking_method)

        reasoning_text = "\n".join(reasoning_steps)

        decisions[f"pii_{i}"] = {
            "pii_id": f"pii_{i}",
            "type": pii_type,
            "value": pii['value'],
            "should_mask": should_mask,
            "masking_method": masking_method,
            "masked_value": masked_value,
            "reason": reason,
            "reasoning": reasoning_text,
            "cited_guidelines": cited_guidelines,
            "guideline_matched": len(guideline_keywords) > 0,
            "confidence": 0.85,
            "risk_level": "high" if pii_type in ['jumin', 'account'] else "medium" if should_mask else "low"
        }

    return decisions


def _generate_masked_preview(value: str, pii_type: str, method: str) -> str:
    """ë§ˆìŠ¤í‚¹ ë¯¸ë¦¬ë³´ê¸° ìƒì„± - MaskingRules ì‚¬ìš©"""
    from app.utils.masking_rules import MaskingRules

    try:
        # methodë¥¼ masking_levelë¡œ ë³€í™˜
        masking_level = 'full' if method == 'full' else 'partial'
        return MaskingRules.apply_masking(value, pii_type, masking_level)
    except Exception as e:
        print(f"âŒ ë§ˆìŠ¤í‚¹ ë¯¸ë¦¬ë³´ê¸° ìƒì„± ì‹¤íŒ¨: {e}, ê¸°ë³¸ ë§ˆìŠ¤í‚¹ ì ìš©")
        # í´ë°±: ê¸°ë³¸ ë§ˆìŠ¤í‚¹
        if method == "full":
            return "***"
        else:
            return value[:2] + "***" if len(value) > 2 else "***"


def generate_summary(context: Dict, decisions: Dict, guides: List[Dict]) -> str:
    """AI ë¶„ì„ ìš”ì•½ ìƒì„±"""
    from app.vectordb.rag_masking import normalize_receiver_type

    masked_count = sum(1 for d in decisions.values() if d.get('should_mask', False))
    total_count = len(decisions)

    # receiver_type ì •ê·œí™” (í•œê¸€ â†’ ì˜ì–´)
    receiver_type = normalize_receiver_type(context)
    receiver_text = "ì™¸ë¶€" if receiver_type == "external" else "ë‚´ë¶€"

    summary = f"{receiver_text} ì „ì†¡ìœ¼ë¡œ ë¶„ë¥˜ë˜ì–´, "

    if masked_count > 0:
        summary += f"{total_count}ê°œ ê°œì¸ì •ë³´ ì¤‘ {masked_count}ê°œë¥¼ ë§ˆìŠ¤í‚¹í•˜ë„ë¡ ê¶Œì¥í•©ë‹ˆë‹¤. "
    else:
        summary += "ë§ˆìŠ¤í‚¹ì´ í•„ìš”í•œ ê°œì¸ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤. "

    if guides:
        summary += f"\n\nOpenAI Vector Storeì—ì„œ ê´€ë ¨ ê·œì • {len(guides)}ê°œë¥¼ ì°¸ê³ í–ˆìŠµë‹ˆë‹¤."

    return summary


def fallback_analysis(request: RAGAnalysisRequest) -> JSONResponse:
    """Vector Store ì‚¬ìš© ë¶ˆê°€ ì‹œ ê¸°ë³¸ ê·œì¹™ ê¸°ë°˜ ë¶„ì„"""

    decisions = {}
    context = request.context
    receiver_type = context.get('receiver_type', 'external')

    for i, pii in enumerate(request.detected_pii):
        pii_type = pii['type']
        pii_value = pii['value']
        masking_method = "none"
        reasoning_steps = []
        cited_guidelines = []

        pii_type_kr = {
            'email': 'ì´ë©”ì¼ ì£¼ì†Œ',
            'phone': 'ì „í™”ë²ˆí˜¸',
            'jumin': 'ì£¼ë¯¼ë“±ë¡ë²ˆí˜¸',
            'account': 'ê³„ì¢Œë²ˆí˜¸',
            'passport': 'ì—¬ê¶Œë²ˆí˜¸',
            'driver_license': 'ìš´ì „ë©´í—ˆë²ˆí˜¸'
        }.get(pii_type, pii_type)

        reasoning_steps.append(f"1. ì»¨í…ìŠ¤íŠ¸ í™•ì¸: {receiver_type} ì „ì†¡")
        reasoning_steps.append(f"2. PII ìœ í˜•: {pii_type_kr}")
        reasoning_steps.append("3. Vector Store ì‚¬ìš© ë¶ˆê°€ â†’ ê¸°ë³¸ ê·œì¹™ ì ìš©")

        if receiver_type == 'external':
            should_mask = True
            reasoning_steps.append("4. íŒë‹¨ ê·¼ê±°:")

            if pii_type in ['jumin', 'account']:
                masking_method = "full"
                reasoning_steps.append(f"   - ê°œì¸ì •ë³´ë³´í˜¸ë²• ì œ24ì¡°: ê³ ìœ ì‹ë³„ì •ë³´ëŠ” ì™¸ë¶€ ì „ì†¡ ì‹œ ì›ì¹™ì  ê¸ˆì§€")
                reason = "ê³ ìœ ì‹ë³„ì •ë³´ ì™¸ë¶€ ì „ì†¡ ê¸ˆì§€ (ê°œì¸ì •ë³´ë³´í˜¸ë²• ì œ24ì¡°)"
                cited_guidelines.append("ê°œì¸ì •ë³´ë³´í˜¸ë²• ì œ24ì¡° (ê³ ìœ ì‹ë³„ì •ë³´ ì²˜ë¦¬ ì œí•œ)")
            else:
                masking_method = "partial"
                reasoning_steps.append(f"   - ê°œì¸ì •ë³´ë³´í˜¸ë²• ì œ17ì¡°: ì œ3ì ì œê³µ ì‹œ ìµœì†Œí™”")
                reason = "ê°œì¸ì •ë³´ ìµœì†Œí™” ì›ì¹™ (ê°œì¸ì •ë³´ë³´í˜¸ë²• ì œ17ì¡°)"
                cited_guidelines.append("ê°œì¸ì •ë³´ë³´í˜¸ë²• ì œ17ì¡° (ê°œì¸ì •ë³´ ì œ3ì ì œê³µ)")

            reasoning_steps.append(f"5. ìµœì¢… ê²°ì •: {masking_method.upper()} ë§ˆìŠ¤í‚¹ ì ìš©")
        else:
            if pii_type in ['jumin', 'account']:
                should_mask = True
                masking_method = "full"
                reasoning_steps.append("4. íŒë‹¨ ê·¼ê±°:")
                reasoning_steps.append(f"   - ë‚´ë¶€ ì „ì†¡ì´ë‚˜ ê³ ìœ ì‹ë³„ì •ë³´ëŠ” ìµœì†Œ ì²˜ë¦¬")
                reasoning_steps.append(f"5. ìµœì¢… ê²°ì •: FULL ë§ˆìŠ¤í‚¹ ì ìš©")
                reason = "ë¯¼ê°ì •ë³´ ìµœì†Œ ì²˜ë¦¬ (ê°œì¸ì •ë³´ë³´í˜¸ë²• ì œ24ì¡°)"
                cited_guidelines.append("ê°œì¸ì •ë³´ë³´í˜¸ë²• ì œ24ì¡° (ê³ ìœ ì‹ë³„ì •ë³´ ìµœì†Œ ì²˜ë¦¬)")
            else:
                should_mask = False
                masking_method = "none"
                reasoning_steps.append("4. íŒë‹¨ ê·¼ê±°:")
                reasoning_steps.append(f"   - ë‚´ë¶€ ì „ì†¡ì´ë©° ì¼ë°˜ ê°œì¸ì •ë³´")
                reasoning_steps.append(f"5. ìµœì¢… ê²°ì •: ë§ˆìŠ¤í‚¹ ë¯¸ì ìš©")
                reason = "ë‚´ë¶€ ì „ì†¡ìœ¼ë¡œ ë§ˆìŠ¤í‚¹ ë¶ˆí•„ìš”"

        masked_value = None
        if should_mask:
            masked_value = _generate_masked_preview(pii_value, pii_type, masking_method)

        reasoning_text = "\n".join(reasoning_steps)

        decisions[f"pii_{i}"] = {
            "pii_id": f"pii_{i}",
            "type": pii_type,
            "value": pii_value,
            "should_mask": should_mask,
            "masking_method": masking_method,
            "masked_value": masked_value,
            "reason": reason,
            "reasoning": reasoning_text,
            "cited_guidelines": cited_guidelines,
            "confidence": 0.8,
            "risk_level": "high" if pii_type in ['jumin', 'account'] else "medium" if should_mask else "low"
        }

    masked_count = sum(1 for d in decisions.values() if d['should_mask'])

    summary = f"ê¸°ë³¸ ê·œì¹™ì— ë”°ë¼ {len(decisions)}ê°œ ê°œì¸ì •ë³´ ì¤‘ {masked_count}ê°œ ë§ˆìŠ¤í‚¹ì„ ê¶Œì¥í•©ë‹ˆë‹¤."

    return JSONResponse({
        "success": True,
        "data": {
            "masking_decisions": decisions,
            "summary": summary,
            "relevant_guides": [],
            "total_guides_found": 0,
            "fallback": True
        }
    })
